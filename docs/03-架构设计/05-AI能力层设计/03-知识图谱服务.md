---
æ–‡æ¡£ç±»å‹: æ¶æ„æ–‡æ¡£
éœ€æ±‚ç¼–å·: DOC-2025-11-001
created_at: 2025-11-29
author: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
updated_at: 2025-11-30 00:25
updater: gemini-pro
status: å·²æ‰¹å‡†
---

# AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å° - çŸ¥è¯†å›¾è°±æœåŠ¡

> **å›¾æ•°æ®åº“**: Neo4j
> **åº”ç”¨åœºæ™¯**: çŸ¥è¯†å›¾è°±æ„å»ºã€æ™ºèƒ½åŒ¹é…ã€å…³ç³»æ¨ç†

## ğŸ“‹ æ–‡æ¡£å¯¼èˆª

æœ¬æ–‡æ¡£æ˜¯AIèƒ½åŠ›å±‚è®¾è®¡çš„ä¸€éƒ¨åˆ†ï¼Œå…¶ä»–ç›¸å…³æ–‡æ¡£ï¼š

1. [00-AIèƒ½åŠ›å±‚æ€»è§ˆ.md](./00-AIèƒ½åŠ›å±‚æ€»è§ˆ.md) - AIèƒ½åŠ›çŸ©é˜µå’ŒæŠ€æœ¯æ ˆæ¦‚è§ˆ
2. [01-LLMæœåŠ¡æ¶æ„.md](./01-LLMæœåŠ¡æ¶æ„.md) - LLMå®¢æˆ·ç«¯ã€Promptç®¡ç†ã€ä»»åŠ¡é˜Ÿåˆ—
3. [02-å‘é‡æ£€ç´¢æœåŠ¡.md](./02-å‘é‡æ£€ç´¢æœåŠ¡.md) - å‘é‡åµŒå…¥æœåŠ¡ã€Elasticsearchã€Pineconeå­˜å‚¨
4. **03-çŸ¥è¯†å›¾è°±æœåŠ¡.md**ï¼ˆæœ¬æ–‡æ¡£ï¼‰- çŸ¥è¯†å›¾è°±ç®¡ç†ã€æ™ºèƒ½åŒ¹é…å¼•æ“
5. [04-å·¥ä½œæµä¸ä¼˜åŒ–.md](./04-å·¥ä½œæµä¸ä¼˜åŒ–.md) - å·¥ä½œæµç¼–æ’ã€æˆæœ¬ä¼˜åŒ–ã€æ€§èƒ½ä¼˜åŒ–

## ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±æœåŠ¡

### 1. çŸ¥è¯†å›¾è°±ç®¡ç†

```python
# app/services/ai/knowledge_graph.py
from typing import List, Dict, Any, Optional
from neo4j import AsyncGraphDatabase
from app.core.config import settings

class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°±æœåŠ¡"""

    def __init__(self):
        self.driver = AsyncGraphDatabase.driver(
            settings.NEO4J_URI,
            auth=(settings.NEO4J_USER, settings.NEO4J_PASSWORD)
        )

    async def close(self):
        """å…³é—­è¿æ¥"""
        await self.driver.close()

    async def create_entity(
        self,
        entity_type: str,
        properties: Dict[str, Any]
    ) -> str:
        """
        åˆ›å»ºå®ä½“èŠ‚ç‚¹

        Args:
            entity_type: å®ä½“ç±»å‹ï¼ˆRequirement, Capability, Project, Person, Caseï¼‰
            properties: å®ä½“å±æ€§

        Returns:
            å®ä½“ID
        """
        async with self.driver.session() as session:
            result = await session.run(
                f"""
                CREATE (n:{entity_type} $properties)
                RETURN id(n) as entity_id
                """,
                properties=properties
            )
            record = await result.single()
            return record["entity_id"]

    async def create_relationship(
        self,
        from_id: str,
        to_id: str,
        relationship_type: str,
        properties: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        åˆ›å»ºå…³ç³»

        Args:
            from_id: èµ·å§‹èŠ‚ç‚¹ID
            to_id: ç›®æ ‡èŠ‚ç‚¹ID
            relationship_type: å…³ç³»ç±»å‹
            properties: å…³ç³»å±æ€§
        """
        async with self.driver.session() as session:
            await session.run(
                f"""
                MATCH (a), (b)
                WHERE id(a) = $from_id AND id(b) = $to_id
                CREATE (a)-[r:{relationship_type} $properties]->(b)
                """,
                from_id=from_id,
                to_id=to_id,
                properties=properties or {}
            )

    async def find_matching_capabilities(
        self,
        requirement_id: str,
        min_score: float = 0.7
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥æ‰¾åŒ¹é…çš„èƒ½åŠ›

        Args:
            requirement_id: éœ€æ±‚ID
            min_score: æœ€å°åŒ¹é…åˆ†æ•°

        Returns:
            åŒ¹é…çš„èƒ½åŠ›åˆ—è¡¨
        """
        async with self.driver.session() as session:
            result = await session.run(
                """
                MATCH (req:Requirement)-[r:MATCHES]->(cap:Capability)
                WHERE id(req) = $requirement_id AND r.score >= $min_score
                RETURN cap, r.score as score
                ORDER BY r.score DESC
                """,
                requirement_id=requirement_id,
                min_score=min_score
            )

            capabilities = []
            async for record in result:
                cap_node = record["cap"]
                capabilities.append({
                    "id": cap_node.id,
                    "name": cap_node.get("name"),
                    "description": cap_node.get("description"),
                    "type": cap_node.get("type"),
                    "score": record["score"]
                })

            return capabilities

    async def find_similar_cases(
        self,
        requirement_text: str,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹

        Args:
            requirement_text: éœ€æ±‚æ–‡æœ¬
            top_k: è¿”å›æ•°é‡

        Returns:
            ç›¸ä¼¼æ¡ˆä¾‹åˆ—è¡¨
        """
        # 1. ä½¿ç”¨å‘é‡æ£€ç´¢æ‰¾åˆ°ç›¸ä¼¼æ¡ˆä¾‹
        vector_store = VectorStore()
        similar_cases = await vector_store.semantic_search(
            query_text=requirement_text,
            top_k=top_k,
            namespace="cases"
        )

        # 2. ä»çŸ¥è¯†å›¾è°±è·å–æ¡ˆä¾‹è¯¦ç»†ä¿¡æ¯å’Œå…³è”å®ä½“
        case_ids = [case["id"] for case in similar_cases]

        async with self.driver.session() as session:
            result = await session.run(
                """
                MATCH (c:Case)
                WHERE c.case_id IN $case_ids
                OPTIONAL MATCH (c)-[:USES_TECHNOLOGY]->(tech:Technology)
                OPTIONAL MATCH (c)-[:BELONGS_TO_INDUSTRY]->(ind:Industry)
                OPTIONAL MATCH (c)-[:INVOLVES_PERSON]->(per:Person)
                RETURN c,
                       collect(DISTINCT tech.name) as technologies,
                       collect(DISTINCT ind.name) as industries,
                       collect(DISTINCT per.name) as persons
                """,
                case_ids=case_ids
            )

            cases = []
            async for record in result:
                case_node = record["c"]
                cases.append({
                    "id": case_node.get("case_id"),
                    "name": case_node.get("name"),
                    "description": case_node.get("description"),
                    "client": case_node.get("client"),
                    "technologies": record["technologies"],
                    "industries": record["industries"],
                    "persons": record["persons"]
                })

            return cases
```

### 2. æ™ºèƒ½åŒ¹é…å¼•æ“

```python
# app/services/ai/matching_engine.py
from typing import List, Dict, Any
from app.services.ai.embedding_service import EmbeddingService
from app.services.ai/vector_store import VectorStore
from app.services.ai.knowledge_graph import KnowledgeGraph

class MatchingEngine:
    """æ™ºèƒ½åŒ¹é…å¼•æ“"""

    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.vector_store = VectorStore()
        self.knowledge_graph = KnowledgeGraph()

    async def match_requirements_to_capabilities(
        self,
        requirements: List[Dict[str, Any]],
        organization_id: str
    ) -> Dict[str, Any]:
        """
        éœ€æ±‚ä¸èƒ½åŠ›åŒ¹é…

        Args:
            requirements: éœ€æ±‚åˆ—è¡¨
            organization_id: ç»„ç»‡ID

        Returns:
            åŒ¹é…ç»“æœ
        """
        matches = []

        for req in requirements:
            # 1. å‘é‡ç›¸ä¼¼åº¦æœç´¢
            vector_results = await self.vector_store.semantic_search(
                query_text=req["description"],
                top_k=10,
                namespace=f"capabilities_{organization_id}"
            )

            # 2. çŸ¥è¯†å›¾è°±å…³ç³»æ¨ç†
            graph_results = await self.knowledge_graph.find_matching_capabilities(
                requirement_id=req["id"],
                min_score=0.6
            )

            # 3. ç»¼åˆè¯„åˆ†
            combined_results = self._combine_match_results(
                vector_results=vector_results,
                graph_results=graph_results
            )

            matches.append({
                "requirement": req,
                "matched_capabilities": combined_results[:5],
                "match_score": combined_results[0]["score"] if combined_results else 0
            })

        return {
            "matches": matches,
            "overall_match_rate": sum(m["match_score"] for m in matches) / len(matches) if matches else 0
        }

    def _combine_match_results(
        self,
        vector_results: List[Dict[str, Any]],
        graph_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ç»¼åˆå‘é‡æœç´¢å’Œå›¾è°±æ¨ç†çš„ç»“æœ

        Args:
            vector_results: å‘é‡æœç´¢ç»“æœ
            graph_results: å›¾è°±æ¨ç†ç»“æœ

        Returns:
            ç»¼åˆç»“æœ
        """
        # åˆ›å»ºIDåˆ°ç»“æœçš„æ˜ å°„
        vector_map = {r["id"]: r for r in vector_results}
        graph_map = {r["id"]: r for r in graph_results}

        # åˆå¹¶ç»“æœ
        combined = {}
        all_ids = set(vector_map.keys()) | set(graph_map.keys())

        for cap_id in all_ids:
            vector_score = vector_map.get(cap_id, {}).get("score", 0)
            graph_score = graph_map.get(cap_id, {}).get("score", 0)

            # åŠ æƒå¹³å‡ï¼ˆå‘é‡60%ï¼Œå›¾è°±40%ï¼‰
            final_score = vector_score * 0.6 + graph_score * 0.4

            combined[cap_id] = {
                "id": cap_id,
                "score": final_score,
                "vector_score": vector_score,
                "graph_score": graph_score,
                "metadata": vector_map.get(cap_id, {}).get("metadata", {})
            }

        # æŒ‰åˆ†æ•°æ’åº
        sorted_results = sorted(
            combined.values(),
            key=lambda x: x["score"],
            reverse=True
        )

        return sorted_results
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- **AIèƒ½åŠ›å±‚æ€»è§ˆ**: [00-AIèƒ½åŠ›å±‚æ€»è§ˆ.md](./00-AIèƒ½åŠ›å±‚æ€»è§ˆ.md)
- **LLMæœåŠ¡æ¶æ„**: [01-LLMæœåŠ¡æ¶æ„.md](./01-LLMæœåŠ¡æ¶æ„.md)
- **å‘é‡æ£€ç´¢æœåŠ¡**: [02-å‘é‡æ£€ç´¢æœåŠ¡.md](./02-å‘é‡æ£€ç´¢æœåŠ¡.md)
- **å·¥ä½œæµä¸ä¼˜åŒ–**: [04-å·¥ä½œæµä¸ä¼˜åŒ–.md](./04-å·¥ä½œæµä¸ä¼˜åŒ–.md)

---

## ä¿®æ”¹å†å²

| æ—¥æœŸ | ç‰ˆæœ¬ | ä¿®æ”¹è€… | ä¿®æ”¹å†…å®¹æ¦‚è¦ |
|------|------|--------|-------------|
| 2025-11-30 00:25 | 1.1 | gemini-pro | YAMLå¤´éƒ¨æ—¶é—´æˆ³æ›´æ–°ã€‚ |
| 2025-11-29 | 1.0 | claude-sonnet-4-5 (claude-sonnet-4-5-20250929) | ä»05-AIèƒ½åŠ›å±‚è®¾è®¡.mdæ‹†åˆ†åˆ›å»ºçŸ¥è¯†å›¾è°±æœåŠ¡æ–‡æ¡£ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´11æœˆ29æ—¥
**æ–‡æ¡£çŠ¶æ€**: âœ… å·²æ‰¹å‡†
