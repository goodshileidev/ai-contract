# Python FastAPI AI æœåŠ¡ä»»åŠ¡è¯¦ç»†è®¡åˆ’ - AI-003

**æ–‡æ¡£ç±»å‹**: å®æ–½æ–‡æ¡£
**éœ€æ±‚ç¼–å·**: REQ-AI-003
**åˆ›å»ºæ—¥æœŸ**: 2025-11-26
**åˆ›å»ºè€…**: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
**æœ€åæ›´æ–°**: 2025-11-27
**æ›´æ–°è€…**: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
**çŠ¶æ€**: å¾…å¼€å§‹

---

## ä¿®æ”¹å†å²

| æ—¥æœŸ | ç‰ˆæœ¬ | ä¿®æ”¹è€… | ä¿®æ”¹å†…å®¹æ¦‚è¦ |
|------|------|--------|-------------|
| 2025-11-27 14:55 | 2.0 | claude-sonnet-4-5 | ä» task-plan-python-ai-è¯¦ç»†.md æ‹†åˆ†å‡º AI-003 æ¨¡å— |
| 2025-11-26 | 1.0 | claude-sonnet-4-5 | åˆ›å»ºPython AIæœåŠ¡è¯¦ç»†ä»»åŠ¡è®¡åˆ’ |

---

## ğŸ“‘ æ–‡æ¡£å¯¼èˆª

**è¿”å›ç´¢å¼•**: [task-plan-python-ai-è¯¦ç»†-INDEX.md](./task-plan-python-ai-è¯¦ç»†-INDEX.md)

**å…¶ä»–æ¨¡å—**: [AI-001](./task-plan-python-ai-è¯¦ç»†-AI-001.md) | [AI-002](./task-plan-python-ai-è¯¦ç»†-AI-002.md) | [AI-004](./task-plan-python-ai-è¯¦ç»†-AI-004.md)

---

## AI-003: ä¼ä¸šèƒ½åŠ›åº“å‘é‡åŒ–

**éœ€æ±‚ç¼–å·**: REQ-AI-003
**è´Ÿè´£äºº**: Python AI å¼€å‘
**ä¼˜å…ˆçº§**: P2 - ä¸­ä¼˜å…ˆçº§
**å¼€å§‹æ—¶é—´**: YYYY-MM-DD
**é¢„è®¡å®Œæˆ**: YYYY-MM-DD
**å®é™…å®Œæˆ**: -
**å½“å‰çŠ¶æ€**: â¸ï¸ å¾…å¼€å§‹
**å®Œæˆè¿›åº¦**: 0% (0/4 äºŒçº§ä»»åŠ¡)

### æ¨¡å—æ¦‚è¿°

ä¼ä¸šèƒ½åŠ›åº“å‘é‡åŒ–æ˜¯AIæ ‡ä¹¦ç”Ÿæˆçš„æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼Œè´Ÿè´£å°†ä¼ä¸šçš„å„ç±»èƒ½åŠ›æ•°æ®è½¬æ¢ä¸ºå‘é‡å½¢å¼ï¼Œå­˜å‚¨åˆ°Elasticsearchå‘é‡æ•°æ®åº“ä¸­ï¼Œä¸ºåç»­çš„æ™ºèƒ½åŒ¹é…å’Œå†…å®¹ç”Ÿæˆæä¾›æ£€ç´¢æ”¯æŒã€‚

**æ ¸å¿ƒä»·å€¼**:
- å®ç°ä¼ä¸šèƒ½åŠ›çš„è¯­ä¹‰åŒ–å­˜å‚¨å’Œæ£€ç´¢
- æ”¯æŒåŸºäºç›¸ä¼¼åº¦çš„æ™ºèƒ½æ¨è
- ä¸ºRAGç³»ç»Ÿæä¾›é«˜è´¨é‡çš„çŸ¥è¯†æº
- æå‡å†…å®¹ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§

**æŠ€æœ¯æ¶æ„**:
```
JavaæœåŠ¡ â†’ RabbitMQ â†’ Python AI Service
             â†“
         å‘é‡åŒ–å¤„ç†
             â†“
      Elasticsearchå‘é‡åº“
             â†“
     è¯­ä¹‰æ£€ç´¢ + æ··åˆæ£€ç´¢
```

---

### äºŒçº§ä»»åŠ¡ 3.1: äº§å“æœåŠ¡å‘é‡åŒ–

**å·¥ä½œé‡ä¼°ç®—**: 4 äººå¤©
**ä¼˜å…ˆçº§**: P2 - é«˜ä¼˜å…ˆçº§ï¼ˆèƒ½åŠ›åº“åŸºç¡€ï¼‰
**æŠ€æœ¯éš¾ç‚¹**:
- äº§å“/æœåŠ¡ä¿¡æ¯çš„ç»“æ„åŒ–æå–
- å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰çš„å‘é‡åŒ–
- å¢é‡æ›´æ–°æœºåˆ¶

#### 1) æ•°æ®å®šä¹‰

##### Pydanticæ¨¡å‹ï¼ˆPython AIæœåŠ¡ï¼‰
```python
# app/models/capability.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime
from enum import Enum

class CapabilityType(str, Enum):
    """èƒ½åŠ›ç±»å‹"""
    PRODUCT = "product"       # äº§å“
    SERVICE = "service"       # æœåŠ¡
    SOLUTION = "solution"     # è§£å†³æ–¹æ¡ˆ

class ProductCapability(BaseModel):
    """äº§å“èƒ½åŠ›æ¨¡å‹"""
    id: str = Field(..., description="äº§å“IDï¼ˆæ¥è‡ªJavaæœåŠ¡ï¼‰")
    organization_id: str = Field(..., description="ç»„ç»‡ID")
    capability_type: CapabilityType = Field(..., description="èƒ½åŠ›ç±»å‹")

    # åŸºæœ¬ä¿¡æ¯
    name: str = Field(..., description="äº§å“/æœåŠ¡åç§°")
    category: Optional[str] = Field(None, description="åˆ†ç±»")
    description: str = Field(..., description="æè¿°")

    # è¯¦ç»†ä¿¡æ¯
    features: List[str] = Field(default_factory=list, description="åŠŸèƒ½ç‰¹æ€§")
    specifications: Dict[str, Any] = Field(default_factory=dict, description="æŠ€æœ¯è§„æ ¼")
    advantages: List[str] = Field(default_factory=list, description="ä¼˜åŠ¿")
    application_scenarios: List[str] = Field(default_factory=list, description="åº”ç”¨åœºæ™¯")
    technology_stack: List[str] = Field(default_factory=list, description="æŠ€æœ¯æ ˆ")

    # å‘é‡åŒ–ç›¸å…³
    embedding: Optional[List[float]] = Field(None, description="å‘é‡ï¼ˆ1536ç»´ï¼‰")
    embedding_model: str = Field("text-embedding-ada-002", description="åµŒå…¥æ¨¡å‹")
    vectorized_at: Optional[datetime] = Field(None, description="å‘é‡åŒ–æ—¶é—´")

    # å…ƒæ•°æ®
    tags: List[str] = Field(default_factory=list, description="æ ‡ç­¾")
    is_active: bool = Field(True, description="æ˜¯å¦æœ‰æ•ˆ")
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

class VectorizationTask(BaseModel):
    """å‘é‡åŒ–ä»»åŠ¡"""
    task_id: str = Field(..., description="ä»»åŠ¡ID")
    capability_id: str = Field(..., description="èƒ½åŠ›ID")
    capability_type: CapabilityType = Field(..., description="èƒ½åŠ›ç±»å‹")
    status: str = Field("pending", description="pending|processing|completed|failed")
    error_message: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")
    created_at: datetime = Field(default_factory=datetime.utcnow)
    completed_at: Optional[datetime] = Field(None)
```

##### Javaå®ä½“ï¼ˆJavaæœåŠ¡ï¼‰
```java
// CompanyCapability.java - JavaæœåŠ¡ç®¡ç†çš„èƒ½åŠ›å®ä½“
@Data
@TableName("company_capabilities")
public class CompanyCapability {
    @TableId(type = IdType.ASSIGN_UUID)
    private String id;

    private String organizationId;

    @TableField("capability_type")
    private String capabilityType;  // product|service|solution

    private String name;
    private String category;
    private String description;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> features;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private Map<String, Object> specifications;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> advantages;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> applicationScenarios;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> technologyStack;

    // å‘é‡åŒ–çŠ¶æ€
    private String embeddingStatus;  // pending|completed|failed
    private LocalDateTime vectorizedAt;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> tags;

    private Boolean isActive;

    @TableField(fill = FieldFill.INSERT)
    private LocalDateTime createdAt;

    @TableField(fill = FieldFill.INSERT_UPDATE)
    private LocalDateTime updatedAt;
}
```

##### æ•°æ®åº“è¡¨è®¾è®¡ï¼ˆPostgreSQLï¼‰
```sql
-- JavaæœåŠ¡ç®¡ç†çš„ä¼ä¸šèƒ½åŠ›è¡¨
CREATE TABLE company_capabilities (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL,
    capability_type VARCHAR(50) NOT NULL,  -- 'product'|'service'|'solution'

    -- åŸºæœ¬ä¿¡æ¯
    name VARCHAR(200) NOT NULL,
    category VARCHAR(100),
    description TEXT NOT NULL,

    -- è¯¦ç»†ä¿¡æ¯ï¼ˆJSONBå­˜å‚¨ï¼‰
    features JSONB DEFAULT '[]'::jsonb,
    specifications JSONB DEFAULT '{}'::jsonb,
    advantages JSONB DEFAULT '[]'::jsonb,
    application_scenarios JSONB DEFAULT '[]'::jsonb,
    technology_stack JSONB DEFAULT '[]'::jsonb,

    -- å‘é‡åŒ–çŠ¶æ€
    embedding_status VARCHAR(20) DEFAULT 'pending',  -- pending|completed|failed
    vectorized_at TIMESTAMP WITH TIME ZONE,

    -- å…ƒæ•°æ®
    tags TEXT[],
    is_active BOOLEAN DEFAULT TRUE,

    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY (organization_id) REFERENCES organizations(id) ON DELETE CASCADE
);

-- ç´¢å¼•
CREATE INDEX idx_capabilities_org ON company_capabilities(organization_id) WHERE is_active = TRUE;
CREATE INDEX idx_capabilities_type ON company_capabilities(capability_type);
CREATE INDEX idx_capabilities_status ON company_capabilities(embedding_status);
CREATE INDEX idx_capabilities_tags ON company_capabilities USING gin(tags);

-- å…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX idx_capabilities_fts ON company_capabilities
    USING gin(to_tsvector('chinese', name || ' ' || description));
```

##### Elasticsearchç´¢å¼•å®šä¹‰
```json
{
  "mappings": {
    "properties": {
      "capability_id": { "type": "keyword" },
      "organization_id": { "type": "keyword" },
      "capability_type": { "type": "keyword" },
      "name": { "type": "text", "analyzer": "ik_max_word" },
      "description": { "type": "text", "analyzer": "ik_max_word" },
      "features": { "type": "text", "analyzer": "ik_max_word" },
      "advantages": { "type": "text", "analyzer": "ik_max_word" },
      "technology_stack": { "type": "keyword" },
      "tags": { "type": "keyword" },
      "embedding": {
        "type": "dense_vector",
        "dims": 1536,
        "index": true,
        "similarity": "cosine"
      },
      "vectorized_at": { "type": "date" },
      "is_active": { "type": "boolean" }
    }
  },
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1
  }
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] Pydanticæ¨¡å‹èƒ½æ­£ç¡®åºåˆ—åŒ–/ååºåˆ—åŒ–
- [ ] PostgreSQLè¡¨ç»“æ„åˆ›å»ºæˆåŠŸ
- [ ] Elasticsearchç´¢å¼•åˆ›å»ºæˆåŠŸï¼Œæ”¯æŒkNNæ£€ç´¢
- [ ] JSONBå­—æ®µèƒ½æ­£ç¡®å­˜å‚¨å’ŒæŸ¥è¯¢

#### 2) å‰ç«¯

##### èƒ½åŠ›ç®¡ç†é¡µé¢
```typescript
// src/pages/Capability/ProductList.tsx
import { ProTable, ProColumns } from '@ant-design/pro-table';
import { Button, Tag, Space, Modal, message } from 'antd';
import { PlusOutlined, SyncOutlined } from '@ant-design/icons';
import { useState } from 'react';

interface ProductCapability {
  id: string;
  name: string;
  category: string;
  description: string;
  features: string[];
  technologyStack: string[];
  embeddingStatus: 'pending' | 'completed' | 'failed';
  vectorizedAt?: string;
  tags: string[];
  isActive: boolean;
}

export default function ProductList() {
  const [selectedRows, setSelectedRows] = useState<ProductCapability[]>([]);

  const columns: ProColumns<ProductCapability>[] = [
    {
      title: 'äº§å“åç§°',
      dataIndex: 'name',
      width: 200,
      fixed: 'left',
      render: (text, record) => (
        <a onClick={() => handleView(record)}>{text}</a>
      ),
    },
    {
      title: 'åˆ†ç±»',
      dataIndex: 'category',
      width: 120,
      valueType: 'select',
      valueEnum: {
        software: { text: 'è½¯ä»¶äº§å“' },
        hardware: { text: 'ç¡¬ä»¶äº§å“' },
        service: { text: 'æœåŠ¡' },
        solution: { text: 'è§£å†³æ–¹æ¡ˆ' },
      },
    },
    {
      title: 'æè¿°',
      dataIndex: 'description',
      width: 300,
      ellipsis: true,
      search: false,
    },
    {
      title: 'æŠ€æœ¯æ ˆ',
      dataIndex: 'technologyStack',
      width: 200,
      search: false,
      render: (_, record) => (
        <>
          {record.technologyStack.slice(0, 3).map(tech => (
            <Tag key={tech}>{tech}</Tag>
          ))}
          {record.technologyStack.length > 3 && (
            <Tag>+{record.technologyStack.length - 3}</Tag>
          )}
        </>
      ),
    },
    {
      title: 'å‘é‡åŒ–çŠ¶æ€',
      dataIndex: 'embeddingStatus',
      width: 120,
      valueType: 'select',
      valueEnum: {
        pending: { text: 'å¾…å¤„ç†', status: 'Default' },
        completed: { text: 'å·²å®Œæˆ', status: 'Success' },
        failed: { text: 'å¤±è´¥', status: 'Error' },
      },
    },
    {
      title: 'å‘é‡åŒ–æ—¶é—´',
      dataIndex: 'vectorizedAt',
      width: 160,
      valueType: 'dateTime',
      search: false,
    },
    {
      title: 'æ ‡ç­¾',
      dataIndex: 'tags',
      width: 150,
      search: false,
      render: (_, record) => (
        <>
          {record.tags.map(tag => (
            <Tag key={tag} color="blue">{tag}</Tag>
          ))}
        </>
      ),
    },
    {
      title: 'çŠ¶æ€',
      dataIndex: 'isActive',
      width: 80,
      valueType: 'select',
      valueEnum: {
        true: { text: 'å¯ç”¨', status: 'Success' },
        false: { text: 'ç¦ç”¨', status: 'Default' },
      },
    },
    {
      title: 'æ“ä½œ',
      width: 180,
      fixed: 'right',
      search: false,
      render: (_, record) => (
        <Space>
          <a onClick={() => handleEdit(record)}>ç¼–è¾‘</a>
          <a onClick={() => handleVectorize(record)}>é‡æ–°å‘é‡åŒ–</a>
          <a style={{ color: 'red' }} onClick={() => handleDelete(record)}>åˆ é™¤</a>
        </Space>
      ),
    },
  ];

  // æ‰¹é‡å‘é‡åŒ–
  const handleBatchVectorize = async () => {
    if (selectedRows.length === 0) {
      message.warning('è¯·é€‰æ‹©è¦å‘é‡åŒ–çš„äº§å“');
      return;
    }

    Modal.confirm({
      title: 'æ‰¹é‡å‘é‡åŒ–ç¡®è®¤',
      content: `ç¡®å®šè¦å¯¹é€‰ä¸­çš„ ${selectedRows.length} ä¸ªäº§å“è¿›è¡Œå‘é‡åŒ–å—ï¼Ÿ`,
      onOk: async () => {
        try {
          const response = await fetch('http://localhost:8001/api/v1/ai/vectorize/batch', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              capability_ids: selectedRows.map(r => r.id),
              capability_type: 'product'
            })
          });

          const result = await response.json();
          message.success(`å·²æäº¤ ${result.task_count} ä¸ªå‘é‡åŒ–ä»»åŠ¡`);
          setSelectedRows([]);
          // åˆ·æ–°è¡¨æ ¼
        } catch (error) {
          message.error('æ‰¹é‡å‘é‡åŒ–å¤±è´¥');
        }
      }
    });
  };

  return (
    <ProTable<ProductCapability>
      headerTitle="äº§å“èƒ½åŠ›åº“"
      rowKey="id"
      columns={columns}
      request={async (params, sort, filter) => {
        // è°ƒç”¨JavaæœåŠ¡APIè·å–æ•°æ®
        const response = await fetch(`http://localhost:8080/api/v1/capabilities/products?page=${params.current}&pageSize=${params.pageSize}`);
        const result = await response.json();
        return {
          data: result.data.items,
          total: result.data.total,
          success: true,
        };
      }}
      rowSelection={{
        selectedRowKeys: selectedRows.map(r => r.id),
        onChange: (_, selectedRows) => setSelectedRows(selectedRows),
      }}
      toolBarRender={() => [
        <Button key="add" type="primary" icon={<PlusOutlined />}>
          æ–°å»ºäº§å“
        </Button>,
        <Button
          key="vectorize"
          icon={<SyncOutlined />}
          onClick={handleBatchVectorize}
          disabled={selectedRows.length === 0}
        >
          æ‰¹é‡å‘é‡åŒ– ({selectedRows.length})
        </Button>,
      ]}
      pagination={{
        pageSize: 20,
        showSizeChanger: true,
        showQuickJumper: true,
      }}
      scroll={{ x: 1500 }}
    />
  );
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] ProTableèƒ½æ­£å¸¸å±•ç¤ºäº§å“åˆ—è¡¨
- [ ] æœç´¢ã€åˆ†é¡µã€æ’åºåŠŸèƒ½æ­£å¸¸
- [ ] æ‰¹é‡é€‰æ‹©å’Œæ‰¹é‡å‘é‡åŒ–åŠŸèƒ½æ­£å¸¸
- [ ] å‘é‡åŒ–çŠ¶æ€å®æ—¶æ›´æ–°

#### 3) Javaåç«¯

##### Serviceå±‚
```java
// CapabilityService.java
@Service
@RequiredArgsConstructor
@Slf4j
public class CapabilityService {

    private final CapabilityMapper capabilityMapper;
    private final RabbitTemplate rabbitTemplate;

    /**
     * åˆ›å»ºäº§å“èƒ½åŠ›
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     */
    public CompanyCapability createProduct(CreateProductRequest request) {
        log.info("Creating product capability: {}", request.getName());

        CompanyCapability capability = new CompanyCapability();
        capability.setOrganizationId(request.getOrganizationId());
        capability.setCapabilityType("product");
        capability.setName(request.getName());
        capability.setCategory(request.getCategory());
        capability.setDescription(request.getDescription());
        capability.setFeatures(request.getFeatures());
        capability.setSpecifications(request.getSpecifications());
        capability.setAdvantages(request.getAdvantages());
        capability.setApplicationScenarios(request.getApplicationScenarios());
        capability.setTechnologyStack(request.getTechnologyStack());
        capability.setTags(request.getTags());
        capability.setEmbeddingStatus("pending");
        capability.setIsActive(true);

        capabilityMapper.insert(capability);

        // å‘é€RabbitMQæ¶ˆæ¯åˆ°Python AIæœåŠ¡è¿›è¡Œå‘é‡åŒ–
        VectorizeMessage message = VectorizeMessage.builder()
            .capabilityId(capability.getId())
            .capabilityType("product")
            .organizationId(capability.getOrganizationId())
            .build();

        rabbitTemplate.convertAndSend(
            "ai.vectorize.exchange",
            "vectorize.product",
            message
        );

        log.info("Vectorization task sent for capability: {}", capability.getId());

        return capability;
    }

    /**
     * æ‰¹é‡å‘é‡åŒ–
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     */
    public BatchVectorizeResponse batchVectorize(List<String> capabilityIds) {
        log.info("Batch vectorizing {} capabilities", capabilityIds.size());

        List<CompanyCapability> capabilities = capabilityMapper.selectBatchIds(capabilityIds);

        int successCount = 0;
        List<String> failedIds = new ArrayList<>();

        for (CompanyCapability capability : capabilities) {
            try {
                VectorizeMessage message = VectorizeMessage.builder()
                    .capabilityId(capability.getId())
                    .capabilityType(capability.getCapabilityType())
                    .organizationId(capability.getOrganizationId())
                    .build();

                rabbitTemplate.convertAndSend(
                    "ai.vectorize.exchange",
                    "vectorize." + capability.getCapabilityType(),
                    message
                );

                // æ›´æ–°çŠ¶æ€ä¸ºpending
                capability.setEmbeddingStatus("pending");
                capabilityMapper.updateById(capability);

                successCount++;
            } catch (Exception e) {
                log.error("Failed to send vectorize message for capability: {}", capability.getId(), e);
                failedIds.add(capability.getId());
            }
        }

        return BatchVectorizeResponse.builder()
            .totalCount(capabilityIds.size())
            .successCount(successCount)
            .failedCount(failedIds.size())
            .failedIds(failedIds)
            .build();
    }

    /**
     * å‘é‡åŒ–å®Œæˆå›è°ƒï¼ˆç”±PythonæœåŠ¡è°ƒç”¨ï¼‰
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     */
    public void onVectorizeComplete(VectorizeCallbackRequest request) {
        log.info("Vectorization completed for capability: {}, status: {}",
            request.getCapabilityId(), request.getStatus());

        CompanyCapability capability = capabilityMapper.selectById(request.getCapabilityId());
        if (capability == null) {
            log.warn("Capability not found: {}", request.getCapabilityId());
            return;
        }

        capability.setEmbeddingStatus(request.getStatus());
        capability.setVectorizedAt(LocalDateTime.now());

        capabilityMapper.updateById(capability);
    }
}
```

##### Controllerå±‚
```java
// CapabilityController.java
@RestController
@RequestMapping("/api/v1/capabilities")
@RequiredArgsConstructor
@Slf4j
public class CapabilityController {

    private final CapabilityService capabilityService;

    /**
     * åˆ›å»ºäº§å“èƒ½åŠ›
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     */
    @PostMapping("/products")
    public ResponseEntity<ApiResponse<CompanyCapability>> createProduct(
        @RequestBody @Valid CreateProductRequest request
    ) {
        CompanyCapability capability = capabilityService.createProduct(request);
        return ResponseEntity.ok(ApiResponse.success(capability, "äº§å“åˆ›å»ºæˆåŠŸ"));
    }

    /**
     * æ‰¹é‡å‘é‡åŒ–
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     */
    @PostMapping("/vectorize/batch")
    public ResponseEntity<ApiResponse<BatchVectorizeResponse>> batchVectorize(
        @RequestBody @Valid BatchVectorizeRequest request
    ) {
        BatchVectorizeResponse response = capabilityService.batchVectorize(request.getCapabilityIds());
        return ResponseEntity.ok(ApiResponse.success(response, "æ‰¹é‡å‘é‡åŒ–ä»»åŠ¡å·²æäº¤"));
    }

    /**
     * å‘é‡åŒ–å®Œæˆå›è°ƒ
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     * ç”±Python AIæœåŠ¡è°ƒç”¨
     */
    @PostMapping("/vectorize/callback")
    public ResponseEntity<ApiResponse<Void>> vectorizeCallback(
        @RequestBody @Valid VectorizeCallbackRequest request
    ) {
        capabilityService.onVectorizeComplete(request);
        return ResponseEntity.ok(ApiResponse.success(null, "å›è°ƒå¤„ç†æˆåŠŸ"));
    }
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] åˆ›å»ºäº§å“èƒ½åŠ›åèƒ½æˆåŠŸå‘é€RabbitMQæ¶ˆæ¯
- [ ] æ‰¹é‡å‘é‡åŒ–èƒ½æ­£ç¡®å¤„ç†å¤šä¸ªèƒ½åŠ›
- [ ] å›è°ƒæ¥å£èƒ½æ­£ç¡®æ›´æ–°å‘é‡åŒ–çŠ¶æ€
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡>80%

#### 4) Pythonåç«¯

##### å‘é‡åŒ–æœåŠ¡
```python
# app/services/ai/vectorization_service.py
from typing import List, Dict, Any, Optional
from llama_index.embeddings import OpenAIEmbedding
from app.services.ai.elasticsearch_store import ElasticsearchVectorStore
from app.core.config import settings
import httpx
import logging

logger = logging.getLogger(__name__)

class VectorizationService:
    """å‘é‡åŒ–æœåŠ¡
    éœ€æ±‚ç¼–å·: REQ-AI-003
    """

    def __init__(self):
        self.embedding_model = OpenAIEmbedding(
            api_key=settings.OPENAI_API_KEY,
            model="text-embedding-ada-002"
        )
        self.es_store = ElasticsearchVectorStore()
        self.java_client = httpx.AsyncClient(base_url="http://backend-java:8080")

    async def vectorize_product(
        self,
        capability_id: str,
        organization_id: str
    ) -> Dict[str, Any]:
        """
        å‘é‡åŒ–äº§å“èƒ½åŠ›

        Args:
            capability_id: èƒ½åŠ›ID
            organization_id: ç»„ç»‡ID

        Returns:
            å‘é‡åŒ–ç»“æœ
        """
        try:
            # 1. ä»JavaæœåŠ¡è·å–èƒ½åŠ›è¯¦æƒ…
            logger.info(f"Fetching capability {capability_id} from Java service")
            response = await self.java_client.get(f"/api/v1/capabilities/{capability_id}")
            response.raise_for_status()
            capability = response.json()['data']

            # 2. æ„å»ºå‘é‡åŒ–æ–‡æœ¬
            vectorize_text = self._build_vectorize_text(capability)

            # 3. ç”Ÿæˆå‘é‡
            logger.info(f"Generating embedding for capability {capability_id}")
            embedding = await self.embedding_model.aget_text_embedding(vectorize_text)

            # 4. å­˜å‚¨åˆ°Elasticsearch
            logger.info(f"Storing embedding to Elasticsearch for {capability_id}")
            await self.es_store.add_document(
                doc_id=capability_id,
                embedding=embedding,
                metadata={
                    'capability_id': capability_id,
                    'organization_id': organization_id,
                    'capability_type': 'product',
                    'name': capability['name'],
                    'description': capability['description'],
                    'features': capability.get('features', []),
                    'advantages': capability.get('advantages', []),
                    'technology_stack': capability.get('technologyStack', []),
                    'tags': capability.get('tags', []),
                    'is_active': capability.get('isActive', True),
                    'vectorized_at': datetime.utcnow().isoformat()
                },
                index_name="capabilities"
            )

            # 5. å›è°ƒJavaæœåŠ¡æ›´æ–°çŠ¶æ€
            await self._callback_java_service(capability_id, "completed")

            logger.info(f"Vectorization completed for capability {capability_id}")

            return {
                'capability_id': capability_id,
                'status': 'completed',
                'embedding_dim': len(embedding),
                'vectorized_at': datetime.utcnow().isoformat()
            }

        except Exception as e:
            logger.error(f"Vectorization failed for capability {capability_id}: {str(e)}")

            # å›è°ƒå¤±è´¥çŠ¶æ€
            await self._callback_java_service(capability_id, "failed", str(e))

            raise

    def _build_vectorize_text(self, capability: Dict[str, Any]) -> str:
        """
        æ„å»ºå‘é‡åŒ–æ–‡æœ¬

        å°†äº§å“çš„å¤šä¸ªå­—æ®µåˆå¹¶æˆä¸€æ®µå®Œæ•´çš„æè¿°æ–‡æœ¬ï¼Œç”¨äºç”Ÿæˆå‘é‡
        """
        parts = []

        # 1. åç§°å’Œåˆ†ç±»
        parts.append(f"äº§å“åç§°ï¼š{capability['name']}")
        if capability.get('category'):
            parts.append(f"åˆ†ç±»ï¼š{capability['category']}")

        # 2. æè¿°
        parts.append(f"æè¿°ï¼š{capability['description']}")

        # 3. åŠŸèƒ½ç‰¹æ€§
        if capability.get('features'):
            features_text = "ã€".join(capability['features'])
            parts.append(f"åŠŸèƒ½ç‰¹æ€§ï¼š{features_text}")

        # 4. ä¼˜åŠ¿
        if capability.get('advantages'):
            advantages_text = "ã€".join(capability['advantages'])
            parts.append(f"ä¼˜åŠ¿ï¼š{advantages_text}")

        # 5. åº”ç”¨åœºæ™¯
        if capability.get('applicationScenarios'):
            scenarios_text = "ã€".join(capability['applicationScenarios'])
            parts.append(f"åº”ç”¨åœºæ™¯ï¼š{scenarios_text}")

        # 6. æŠ€æœ¯æ ˆ
        if capability.get('technologyStack'):
            tech_text = "ã€".join(capability['technologyStack'])
            parts.append(f"æŠ€æœ¯æ ˆï¼š{tech_text}")

        # åˆå¹¶æ‰€æœ‰éƒ¨åˆ†
        return "\n".join(parts)

    async def _callback_java_service(
        self,
        capability_id: str,
        status: str,
        error_message: Optional[str] = None
    ):
        """å›è°ƒJavaæœåŠ¡æ›´æ–°å‘é‡åŒ–çŠ¶æ€"""
        try:
            await self.java_client.post(
                "/api/v1/capabilities/vectorize/callback",
                json={
                    'capability_id': capability_id,
                    'status': status,
                    'error_message': error_message,
                    'vectorized_at': datetime.utcnow().isoformat()
                }
            )
        except Exception as e:
            logger.error(f"Callback to Java service failed: {str(e)}")

    async def close(self):
        """å…³é—­èµ„æº"""
        await self.java_client.aclose()
        await self.es_store.close()
```

##### Celeryå¼‚æ­¥ä»»åŠ¡
```python
# app/tasks/vectorization_tasks.py
from celery import Task
from app.tasks.celery_app import celery_app
from app.services.ai.vectorization_service import VectorizationService
import logging

logger = logging.getLogger(__name__)

@celery_app.task(bind=True, max_retries=3)
def vectorize_product_task(self: Task, capability_id: str, organization_id: str):
    """
    äº§å“å‘é‡åŒ–å¼‚æ­¥ä»»åŠ¡
    éœ€æ±‚ç¼–å·: REQ-AI-003
    """
    logger.info(f"Starting vectorization task for capability {capability_id}")

    try:
        service = VectorizationService()
        result = await service.vectorize_product(capability_id, organization_id)

        logger.info(f"Vectorization task completed: {result}")
        return result

    except Exception as e:
        logger.error(f"Vectorization task failed: {str(e)}")

        # é‡è¯•æœºåˆ¶
        raise self.retry(exc=e, countdown=60 * (self.request.retries + 1))
```

##### RabbitMQæ¶ˆè´¹è€…
```python
# app/consumers/vectorization_consumer.py
import pika
import json
from app.tasks.vectorization_tasks import vectorize_product_task
from app.core.config import settings
import logging

logger = logging.getLogger(__name__)

class VectorizationConsumer:
    """
    å‘é‡åŒ–æ¶ˆæ¯æ¶ˆè´¹è€…
    éœ€æ±‚ç¼–å·: REQ-AI-003
    """

    def __init__(self):
        # RabbitMQè¿æ¥
        credentials = pika.PlainCredentials(
            settings.RABBITMQ_USER,
            settings.RABBITMQ_PASSWORD
        )
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=settings.RABBITMQ_HOST,
                port=settings.RABBITMQ_PORT,
                credentials=credentials
            )
        )
        self.channel = self.connection.channel()

        # å£°æ˜äº¤æ¢æœº
        self.channel.exchange_declare(
            exchange='ai.vectorize.exchange',
            exchange_type='topic',
            durable=True
        )

        # å£°æ˜é˜Ÿåˆ—
        self.channel.queue_declare(
            queue='ai.vectorize.product.queue',
            durable=True
        )

        # ç»‘å®šé˜Ÿåˆ—åˆ°äº¤æ¢æœº
        self.channel.queue_bind(
            exchange='ai.vectorize.exchange',
            queue='ai.vectorize.product.queue',
            routing_key='vectorize.product'
        )

    def callback(self, ch, method, properties, body):
        """å¤„ç†æ¶ˆæ¯"""
        try:
            message = json.loads(body.decode('utf-8'))
            logger.info(f"Received vectorization message: {message}")

            capability_id = message['capability_id']
            organization_id = message['organization_id']

            # æäº¤Celeryä»»åŠ¡
            vectorize_product_task.delay(capability_id, organization_id)

            # ç¡®è®¤æ¶ˆæ¯
            ch.basic_ack(delivery_tag=method.delivery_tag)

        except Exception as e:
            logger.error(f"Message processing failed: {str(e)}")
            # æ‹’ç»æ¶ˆæ¯å¹¶é‡æ–°å…¥é˜Ÿ
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

    def start(self):
        """å¼€å§‹æ¶ˆè´¹"""
        logger.info("Starting vectorization consumer...")
        self.channel.basic_qos(prefetch_count=1)
        self.channel.basic_consume(
            queue='ai.vectorize.product.queue',
            on_message_callback=self.callback
        )
        self.channel.start_consuming()

    def stop(self):
        """åœæ­¢æ¶ˆè´¹"""
        self.channel.stop_consuming()
        self.connection.close()
```

##### APIæ¥å£
```python
# app/api/v1/vectorization.py
from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List, Optional
from app.services.ai.vectorization_service import VectorizationService
from app.tasks.vectorization_tasks import vectorize_product_task

router = APIRouter(prefix="/vectorize", tags=["å‘é‡åŒ–"])

class BatchVectorizeRequest(BaseModel):
    """æ‰¹é‡å‘é‡åŒ–è¯·æ±‚"""
    capability_ids: List[str] = Field(..., description="èƒ½åŠ›IDåˆ—è¡¨")
    capability_type: str = Field(..., description="èƒ½åŠ›ç±»å‹ï¼šproduct|service|case")

class BatchVectorizeResponse(BaseModel):
    """æ‰¹é‡å‘é‡åŒ–å“åº”"""
    task_count: int = Field(..., description="æäº¤çš„ä»»åŠ¡æ•°é‡")
    task_ids: List[str] = Field(..., description="ä»»åŠ¡IDåˆ—è¡¨")

@router.post("/batch", response_model=BatchVectorizeResponse)
async def batch_vectorize(
    request: BatchVectorizeRequest,
    background_tasks: BackgroundTasks
):
    """
    æ‰¹é‡å‘é‡åŒ–
    éœ€æ±‚ç¼–å·: REQ-AI-003
    """
    task_ids = []

    for capability_id in request.capability_ids:
        # æäº¤Celeryä»»åŠ¡
        task = vectorize_product_task.delay(
            capability_id=capability_id,
            organization_id="auto"  # ä»ä¸Šä¸‹æ–‡è·å–
        )
        task_ids.append(task.id)

    return BatchVectorizeResponse(
        task_count=len(task_ids),
        task_ids=task_ids
    )
```

**éªŒè¯æ ‡å‡†**:
- [ ] RabbitMQæ¶ˆæ¯èƒ½æ­£ç¡®æ¶ˆè´¹
- [ ] Celeryä»»åŠ¡èƒ½æ­£ç¡®æ‰§è¡Œ
- [ ] å‘é‡ç”ŸæˆæˆåŠŸå¹¶å­˜å‚¨åˆ°Elasticsearch
- [ ] å›è°ƒJavaæœåŠ¡çŠ¶æ€æ›´æ–°æˆåŠŸ
- [ ] å¼‚å¸¸æƒ…å†µèƒ½æ­£ç¡®é‡è¯•

#### 5) éƒ¨ç½²

##### Dockeré…ç½®
```dockerfile
# Dockerfileä¸­æ·»åŠ å‘é‡åŒ–ç›¸å…³ä¾èµ–
RUN pip install \
    pika==1.3.2 \
    celery==5.3.4 \
    redis==5.0.1
```

##### docker-compose.yml
```yaml
services:
  # Python AIæœåŠ¡
  backend-python:
    build: ./backend-python
    environment:
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USER=rabbitmq
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - JAVA_SERVICE_URL=http://backend-java:8080
    depends_on:
      - rabbitmq
      - elasticsearch
    networks:
      - app-network

  # Celery Workerï¼ˆå‘é‡åŒ–ä»»åŠ¡ï¼‰
  ai-worker:
    build: ./backend-python
    command: celery -A app.tasks.celery_app worker --loglevel=info -Q vectorization
    environment:
      - RABBITMQ_HOST=rabbitmq
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - JAVA_SERVICE_URL=http://backend-java:8080
    depends_on:
      - rabbitmq
      - elasticsearch
    networks:
      - app-network

  # RabbitMQæ¶ˆè´¹è€…ï¼ˆç‹¬ç«‹è¿›ç¨‹ï¼‰
  vectorization-consumer:
    build: ./backend-python
    command: python -m app.consumers.vectorization_consumer
    environment:
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_USER=rabbitmq
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
    depends_on:
      - rabbitmq
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

##### ç¯å¢ƒå˜é‡é…ç½®
```bash
# .env
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_USER=rabbitmq
RABBITMQ_PASSWORD=your_password

ELASTICSEARCH_URL=http://elasticsearch:9200
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=your_password

OPENAI_API_KEY=sk-your-openai-api-key
JAVA_SERVICE_URL=http://backend-java:8080
```

**éªŒè¯æ ‡å‡†**:
- [ ] æ‰€æœ‰å®¹å™¨èƒ½æ­£å¸¸å¯åŠ¨
- [ ] RabbitMQè¿æ¥æˆåŠŸ
- [ ] Elasticsearchè¿æ¥æˆåŠŸ
- [ ] Celery Workerèƒ½æ¥æ”¶å¹¶å¤„ç†ä»»åŠ¡
- [ ] å®¹å™¨é—´ç½‘ç»œé€šä¿¡æ­£å¸¸

---

### äºŒçº§ä»»åŠ¡ 3.2: é¡¹ç›®ç»éªŒå‘é‡åŒ–

**å·¥ä½œé‡ä¼°ç®—**: 4 äººå¤©
**ä¼˜å…ˆçº§**: P2 - é«˜ä¼˜å…ˆçº§
**æŠ€æœ¯éš¾ç‚¹**:
- é¡¹ç›®æ¡ˆä¾‹çš„å¤šç»´åº¦ä¿¡æ¯æå–
- æˆæœé‡åŒ–æ•°æ®çš„å¤„ç†
- å®¢æˆ·è¯„ä»·çš„æƒ…æ„Ÿåˆ†æ

#### 1) æ•°æ®å®šä¹‰

##### Pydanticæ¨¡å‹
```python
# app/models/project_case.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import date, datetime
from decimal import Decimal

class ProjectCase(BaseModel):
    """é¡¹ç›®æ¡ˆä¾‹æ¨¡å‹"""
    id: str = Field(..., description="æ¡ˆä¾‹ID")
    organization_id: str = Field(..., description="ç»„ç»‡ID")

    # é¡¹ç›®åŸºæœ¬ä¿¡æ¯
    project_name: str = Field(..., description="é¡¹ç›®åç§°")
    client_name: str = Field(..., description="å®¢æˆ·åç§°")
    client_industry: Optional[str] = Field(None, description="å®¢æˆ·è¡Œä¸š")
    project_category: Optional[str] = Field(None, description="é¡¹ç›®ç±»åˆ«")
    project_type: Optional[str] = Field(None, description="é¡¹ç›®ç±»å‹")

    # é¡¹ç›®è§„æ¨¡
    contract_amount: Optional[Decimal] = Field(None, description="åˆåŒé‡‘é¢")
    start_date: Optional[date] = Field(None, description="å¼€å§‹æ—¥æœŸ")
    end_date: Optional[date] = Field(None, description="ç»“æŸæ—¥æœŸ")
    duration_months: Optional[int] = Field(None, description="æŒç»­æœˆæ•°")
    team_size: Optional[int] = Field(None, description="å›¢é˜Ÿè§„æ¨¡")

    # é¡¹ç›®æè¿°
    project_description: str = Field(..., description="é¡¹ç›®æè¿°")
    challenges: Optional[str] = Field(None, description="é¢ä¸´çš„æŒ‘æˆ˜")
    solutions: Optional[str] = Field(None, description="è§£å†³æ–¹æ¡ˆ")

    # é¡¹ç›®æˆæœ
    achievements: List[str] = Field(default_factory=list, description="æˆæœäº®ç‚¹")
    customer_satisfaction: Optional[Decimal] = Field(None, description="å®¢æˆ·æ»¡æ„åº¦")
    customer_feedback: Optional[str] = Field(None, description="å®¢æˆ·è¯„ä»·")

    # æŠ€æœ¯ç›¸å…³
    technologies_used: List[str] = Field(default_factory=list, description="ä½¿ç”¨çš„æŠ€æœ¯")
    project_role: Optional[str] = Field(None, description="é¡¹ç›®è§’è‰²")

    # å‘é‡åŒ–ç›¸å…³
    embedding: Optional[List[float]] = Field(None, description="å‘é‡")
    embedding_model: str = Field("text-embedding-ada-002")
    vectorized_at: Optional[datetime] = Field(None)

    # å…ƒæ•°æ®
    tags: List[str] = Field(default_factory=list)
    is_reference: bool = Field(True, description="æ˜¯å¦å¯ä½œä¸ºå‚è€ƒæ¡ˆä¾‹")
    is_public: bool = Field(False, description="æ˜¯å¦å…¬å¼€")
    created_at: datetime = Field(default_factory=datetime.utcnow)
```

##### Javaå®ä½“
```java
@Data
@TableName("project_cases")
public class ProjectCase {
    @TableId(type = IdType.ASSIGN_UUID)
    private String id;

    private String organizationId;
    private String projectName;
    private String clientName;
    private String clientIndustry;
    private String projectCategory;

    private BigDecimal contractAmount;
    private LocalDate startDate;
    private LocalDate endDate;
    private Integer durationMonths;
    private Integer teamSize;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private String projectDescription;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> achievements;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> technologiesUsed;

    private String embeddingStatus;
    private LocalDateTime vectorizedAt;

    @TableField(typeHandler = JacksonTypeHandler.class)
    private List<String> tags;

    private Boolean isReference;
    private Boolean isPublic;

    @TableField(fill = FieldFill.INSERT)
    private LocalDateTime createdAt;
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] Pydanticæ¨¡å‹éªŒè¯é€šè¿‡
- [ ] æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ
- [ ] å®¢æˆ·æ»¡æ„åº¦ç­‰æ•°å€¼å­—æ®µç²¾åº¦æ­£ç¡®

#### 2) å‰ç«¯

```typescript
// src/pages/Capability/CaseList.tsx
export default function CaseList() {
  const columns: ProColumns<ProjectCase>[] = [
    {
      title: 'é¡¹ç›®åç§°',
      dataIndex: 'projectName',
      width: 200,
      render: (text, record) => (
        <a onClick={() => handleViewCase(record)}>{text}</a>
      ),
    },
    {
      title: 'å®¢æˆ·',
      dataIndex: 'clientName',
      width: 150,
    },
    {
      title: 'è¡Œä¸š',
      dataIndex: 'clientIndustry',
      width: 120,
      valueType: 'select',
      valueEnum: {
        finance: 'é‡‘è',
        government: 'æ”¿åºœ',
        education: 'æ•™è‚²',
        healthcare: 'åŒ»ç–—',
      },
    },
    {
      title: 'åˆåŒé‡‘é¢',
      dataIndex: 'contractAmount',
      width: 120,
      valueType: 'money',
      search: false,
    },
    {
      title: 'é¡¹ç›®å‘¨æœŸ',
      dataIndex: 'durationMonths',
      width: 100,
      search: false,
      render: (_, record) => `${record.durationMonths}ä¸ªæœˆ`,
    },
    {
      title: 'å®¢æˆ·æ»¡æ„åº¦',
      dataIndex: 'customerSatisfaction',
      width: 120,
      search: false,
      render: (_, record) => (
        <Rate disabled value={record.customerSatisfaction} />
      ),
    },
    {
      title: 'æŠ€æœ¯æ ˆ',
      dataIndex: 'technologiesUsed',
      width: 200,
      search: false,
      render: (_, record) => (
        <>
          {record.technologiesUsed.slice(0, 3).map(tech => (
            <Tag key={tech} color="blue">{tech}</Tag>
          ))}
        </>
      ),
    },
    {
      title: 'å‘é‡åŒ–çŠ¶æ€',
      dataIndex: 'embeddingStatus',
      width: 120,
      valueEnum: {
        pending: { text: 'å¾…å¤„ç†', status: 'Default' },
        completed: { text: 'å·²å®Œæˆ', status: 'Success' },
        failed: { text: 'å¤±è´¥', status: 'Error' },
      },
    },
  ];

  return (
    <ProTable<ProjectCase>
      headerTitle="é¡¹ç›®æ¡ˆä¾‹åº“"
      columns={columns}
      request={async (params) => {
        const response = await fetch(`http://localhost:8080/api/v1/capabilities/cases?page=${params.current}`);
        const result = await response.json();
        return {
          data: result.data.items,
          total: result.data.total,
          success: true,
        };
      }}
    />
  );
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] æ¡ˆä¾‹åˆ—è¡¨æ­£å¸¸å±•ç¤º
- [ ] å®¢æˆ·æ»¡æ„åº¦æ˜Ÿçº§å±•ç¤ºæ­£ç¡®
- [ ] æŠ€æœ¯æ ˆæ ‡ç­¾å±•ç¤ºå®Œæ•´

#### 3) Javaåç«¯

```java
@Service
public class ProjectCaseService {

    /**
     * åˆ›å»ºé¡¹ç›®æ¡ˆä¾‹
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     */
    public ProjectCase createCase(CreateProjectCaseRequest request) {
        ProjectCase projectCase = new ProjectCase();
        // è®¾ç½®åŸºæœ¬ä¿¡æ¯
        projectCase.setOrganizationId(request.getOrganizationId());
        projectCase.setProjectName(request.getProjectName());
        projectCase.setClientName(request.getClientName());
        projectCase.setClientIndustry(request.getClientIndustry());

        // è®¾ç½®é¡¹ç›®è§„æ¨¡
        projectCase.setContractAmount(request.getContractAmount());
        projectCase.setStartDate(request.getStartDate());
        projectCase.setEndDate(request.getEndDate());
        projectCase.setDurationMonths(request.getDurationMonths());

        // è®¾ç½®æˆæœå’ŒæŠ€æœ¯
        projectCase.setAchievements(request.getAchievements());
        projectCase.setTechnologiesUsed(request.getTechnologiesUsed());

        projectCase.setEmbeddingStatus("pending");
        projectCaseMapper.insert(projectCase);

        // å‘é€å‘é‡åŒ–æ¶ˆæ¯
        VectorizeMessage message = VectorizeMessage.builder()
            .capabilityId(projectCase.getId())
            .capabilityType("case")
            .organizationId(projectCase.getOrganizationId())
            .build();

        rabbitTemplate.convertAndSend(
            "ai.vectorize.exchange",
            "vectorize.case",
            message
        );

        return projectCase;
    }
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] æ¡ˆä¾‹åˆ›å»ºæˆåŠŸ
- [ ] å‘é‡åŒ–æ¶ˆæ¯å‘é€æˆåŠŸ
- [ ] é‡‘é¢ã€æ—¥æœŸå­—æ®µå­˜å‚¨æ­£ç¡®

#### 4) Pythonåç«¯

```python
# app/services/ai/case_vectorization_service.py
class CaseVectorizationService:
    """é¡¹ç›®æ¡ˆä¾‹å‘é‡åŒ–æœåŠ¡"""

    async def vectorize_case(
        self,
        case_id: str,
        organization_id: str
    ) -> Dict[str, Any]:
        """å‘é‡åŒ–é¡¹ç›®æ¡ˆä¾‹"""

        # 1. è·å–æ¡ˆä¾‹è¯¦æƒ…
        response = await self.java_client.get(f"/api/v1/capabilities/cases/{case_id}")
        case_data = response.json()['data']

        # 2. æ„å»ºå‘é‡åŒ–æ–‡æœ¬ï¼ˆåŒ…å«å¤šç»´åº¦ä¿¡æ¯ï¼‰
        vectorize_text = self._build_case_text(case_data)

        # 3. ç”Ÿæˆå‘é‡
        embedding = await self.embedding_model.aget_text_embedding(vectorize_text)

        # 4. å­˜å‚¨åˆ°Elasticsearch
        await self.es_store.add_document(
            doc_id=case_id,
            embedding=embedding,
            metadata={
                'capability_id': case_id,
                'organization_id': organization_id,
                'capability_type': 'case',
                'project_name': case_data['projectName'],
                'client_name': case_data['clientName'],
                'client_industry': case_data['clientIndustry'],
                'contract_amount': case_data.get('contractAmount'),
                'achievements': case_data.get('achievements', []),
                'technologies_used': case_data.get('technologiesUsed', []),
                'customer_satisfaction': case_data.get('customerSatisfaction'),
                'tags': case_data.get('tags', []),
                'vectorized_at': datetime.utcnow().isoformat()
            },
            index_name="capabilities"
        )

        # 5. å›è°ƒJavaæœåŠ¡
        await self._callback_java_service(case_id, "completed")

        return {
            'case_id': case_id,
            'status': 'completed',
            'embedding_dim': len(embedding)
        }

    def _build_case_text(self, case_data: Dict[str, Any]) -> str:
        """æ„å»ºæ¡ˆä¾‹å‘é‡åŒ–æ–‡æœ¬"""
        parts = []

        # é¡¹ç›®åŸºæœ¬ä¿¡æ¯
        parts.append(f"é¡¹ç›®åç§°ï¼š{case_data['projectName']}")
        parts.append(f"å®¢æˆ·ï¼š{case_data['clientName']}")
        if case_data.get('clientIndustry'):
            parts.append(f"è¡Œä¸šï¼š{case_data['clientIndustry']}")

        # é¡¹ç›®æè¿°
        parts.append(f"é¡¹ç›®æè¿°ï¼š{case_data['projectDescription']}")

        # æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ
        if case_data.get('challenges'):
            parts.append(f"é¢ä¸´æŒ‘æˆ˜ï¼š{case_data['challenges']}")
        if case_data.get('solutions'):
            parts.append(f"è§£å†³æ–¹æ¡ˆï¼š{case_data['solutions']}")

        # æˆæœ
        if case_data.get('achievements'):
            achievements_text = "ã€".join(case_data['achievements'])
            parts.append(f"é¡¹ç›®æˆæœï¼š{achievements_text}")

        # æŠ€æœ¯æ ˆ
        if case_data.get('technologiesUsed'):
            tech_text = "ã€".join(case_data['technologiesUsed'])
            parts.append(f"æŠ€æœ¯æ ˆï¼š{tech_text}")

        # å®¢æˆ·è¯„ä»·
        if case_data.get('customerFeedback'):
            parts.append(f"å®¢æˆ·è¯„ä»·ï¼š{case_data['customerFeedback']}")

        return "\n".join(parts)
```

**éªŒè¯æ ‡å‡†**:
- [ ] æ¡ˆä¾‹æ–‡æœ¬æ„å»ºåŒ…å«æ‰€æœ‰å…³é”®ä¿¡æ¯
- [ ] å‘é‡ç”ŸæˆæˆåŠŸ
- [ ] Elasticsearchå­˜å‚¨æˆåŠŸ
- [ ] å›è°ƒJavaæœåŠ¡æˆåŠŸ

#### 5) éƒ¨ç½²

```yaml
# docker-compose.yml ä¸­æ·»åŠ æ¡ˆä¾‹å‘é‡åŒ–worker
services:
  case-vectorization-worker:
    build: ./backend-python
    command: celery -A app.tasks.celery_app worker --loglevel=info -Q case_vectorization
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - JAVA_SERVICE_URL=http://backend-java:8080
```

**éªŒè¯æ ‡å‡†**:
- [ ] Workeræ­£å¸¸å¯åŠ¨
- [ ] èƒ½æ¥æ”¶å¹¶å¤„ç†æ¡ˆä¾‹å‘é‡åŒ–ä»»åŠ¡

---

### äºŒçº§ä»»åŠ¡ 3.3: èµ„è´¨è¯ä¹¦å‘é‡åŒ–

**å·¥ä½œé‡ä¼°ç®—**: 3 äººå¤©
**ä¼˜å…ˆçº§**: P2 - ä¸­ä¼˜å…ˆçº§
**æŠ€æœ¯éš¾ç‚¹**:
- è¯ä¹¦ä¿¡æ¯çš„æ ‡å‡†åŒ–æå–
- æœ‰æ•ˆæœŸç®¡ç†
- è¯ä¹¦å›¾ç‰‡çš„OCRè¯†åˆ«ï¼ˆå¯é€‰ï¼‰

#### 1) æ•°æ®å®šä¹‰

##### Pydanticæ¨¡å‹
```python
# app/models/certification.py
class Certification(BaseModel):
    """èµ„è´¨è¯ä¹¦æ¨¡å‹"""
    id: str
    organization_id: str

    # è¯ä¹¦ä¿¡æ¯
    certification_name: str = Field(..., description="è¯ä¹¦åç§°")
    certification_type: str = Field(..., description="è¯ä¹¦ç±»å‹")
    issuing_authority: str = Field(..., description="é¢å‘æœºæ„")
    certificate_number: Optional[str] = Field(None, description="è¯ä¹¦ç¼–å·")

    # æœ‰æ•ˆæœŸ
    issue_date: Optional[date] = Field(None, description="é¢å‘æ—¥æœŸ")
    expiry_date: Optional[date] = Field(None, description="åˆ°æœŸæ—¥æœŸ")
    is_valid: bool = Field(True, description="æ˜¯å¦æœ‰æ•ˆ")

    # è¯¦ç»†ä¿¡æ¯
    scope: Optional[str] = Field(None, description="è®¤è¯èŒƒå›´")
    level: Optional[str] = Field(None, description="ç­‰çº§")
    certificate_url: Optional[str] = Field(None, description="è¯ä¹¦æ–‡ä»¶URL")

    # å‘é‡åŒ–
    embedding: Optional[List[float]] = None
    vectorized_at: Optional[datetime] = None

    tags: List[str] = Field(default_factory=list)
    created_at: datetime = Field(default_factory=datetime.utcnow)
```

##### æ•°æ®åº“è¡¨
```sql
CREATE TABLE certifications (
    id UUID PRIMARY KEY,
    organization_id UUID NOT NULL,
    certification_name VARCHAR(200) NOT NULL,
    certification_type VARCHAR(100),
    issuing_authority VARCHAR(200),
    certificate_number VARCHAR(100),
    issue_date DATE,
    expiry_date DATE,
    is_valid BOOLEAN DEFAULT TRUE,
    scope TEXT,
    level VARCHAR(50),
    certificate_url TEXT,
    embedding_status VARCHAR(20) DEFAULT 'pending',
    vectorized_at TIMESTAMP WITH TIME ZONE,
    tags TEXT[],
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (organization_id) REFERENCES organizations(id)
);

-- ç´¢å¼•
CREATE INDEX idx_certifications_org ON certifications(organization_id);
CREATE INDEX idx_certifications_type ON certifications(certification_type);
CREATE INDEX idx_certifications_valid ON certifications(is_valid, expiry_date);
```

**éªŒè¯æ ‡å‡†**:
- [ ] æ¨¡å‹éªŒè¯é€šè¿‡
- [ ] è¡¨åˆ›å»ºæˆåŠŸ
- [ ] æœ‰æ•ˆæœŸå­—æ®µç±»å‹æ­£ç¡®

#### 2) å‰ç«¯

```typescript
// src/pages/Capability/CertificationList.tsx
export default function CertificationList() {
  const columns: ProColumns<Certification>[] = [
    {
      title: 'è¯ä¹¦åç§°',
      dataIndex: 'certificationName',
      width: 200,
    },
    {
      title: 'ç±»å‹',
      dataIndex: 'certificationType',
      width: 150,
      valueType: 'select',
      valueEnum: {
        iso: 'ISOè®¤è¯',
        qualification: 'ä¼ä¸šèµ„è´¨',
        patent: 'ä¸“åˆ©è¯ä¹¦',
        software: 'è½¯ä»¶è‘—ä½œæƒ',
      },
    },
    {
      title: 'é¢å‘æœºæ„',
      dataIndex: 'issuingAuthority',
      width: 200,
    },
    {
      title: 'è¯ä¹¦ç¼–å·',
      dataIndex: 'certificateNumber',
      width: 150,
    },
    {
      title: 'é¢å‘æ—¥æœŸ',
      dataIndex: 'issueDate',
      width: 120,
      valueType: 'date',
    },
    {
      title: 'åˆ°æœŸæ—¥æœŸ',
      dataIndex: 'expiryDate',
      width: 120,
      valueType: 'date',
      render: (_, record) => {
        const isExpiringSoon = record.expiryDate &&
          new Date(record.expiryDate) < new Date(Date.now() + 90 * 24 * 60 * 60 * 1000);
        return (
          <span style={{ color: isExpiringSoon ? 'red' : 'inherit' }}>
            {record.expiryDate}
            {isExpiringSoon && <Tag color="orange">å³å°†åˆ°æœŸ</Tag>}
          </span>
        );
      },
    },
    {
      title: 'çŠ¶æ€',
      dataIndex: 'isValid',
      width: 100,
      valueType: 'select',
      valueEnum: {
        true: { text: 'æœ‰æ•ˆ', status: 'Success' },
        false: { text: 'å·²è¿‡æœŸ', status: 'Error' },
      },
    },
    {
      title: 'å‘é‡åŒ–çŠ¶æ€',
      dataIndex: 'embeddingStatus',
      width: 120,
      valueEnum: {
        pending: { text: 'å¾…å¤„ç†', status: 'Default' },
        completed: { text: 'å·²å®Œæˆ', status: 'Success' },
      },
    },
    {
      title: 'æ“ä½œ',
      width: 180,
      render: (_, record) => (
        <Space>
          <a onClick={() => handleView(record.certificateUrl)}>æŸ¥çœ‹è¯ä¹¦</a>
          <a onClick={() => handleEdit(record)}>ç¼–è¾‘</a>
          <a onClick={() => handleVectorize(record)}>å‘é‡åŒ–</a>
        </Space>
      ),
    },
  ];

  return (
    <ProTable<Certification>
      headerTitle="èµ„è´¨è¯ä¹¦åº“"
      columns={columns}
      toolBarRender={() => [
        <Button key="add" type="primary" icon={<PlusOutlined />}>
          æ–°å¢è¯ä¹¦
        </Button>,
        <Button key="check" onClick={handleCheckExpiry}>
          æ£€æŸ¥åˆ°æœŸè¯ä¹¦
        </Button>,
      ]}
    />
  );
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] å³å°†åˆ°æœŸè¯ä¹¦é«˜äº®æ˜¾ç¤º
- [ ] è¯ä¹¦æ–‡ä»¶èƒ½æ­£å¸¸æŸ¥çœ‹
- [ ] æ‰¹é‡å‘é‡åŒ–åŠŸèƒ½æ­£å¸¸

#### 3) Javaåç«¯

```java
@Service
public class CertificationService {

    /**
     * åˆ›å»ºèµ„è´¨è¯ä¹¦
     * éœ€æ±‚ç¼–å·: REQ-AI-003
     */
    public Certification createCertification(CreateCertificationRequest request) {
        Certification cert = new Certification();
        cert.setOrganizationId(request.getOrganizationId());
        cert.setCertificationName(request.getCertificationName());
        cert.setCertificationType(request.getCertificationType());
        cert.setIssuingAuthority(request.getIssuingAuthority());
        cert.setCertificateNumber(request.getCertificateNumber());
        cert.setIssueDate(request.getIssueDate());
        cert.setExpiryDate(request.getExpiryDate());

        // æ£€æŸ¥æœ‰æ•ˆæ€§
        cert.setIsValid(checkValidity(request.getExpiryDate()));

        cert.setEmbeddingStatus("pending");
        certificationMapper.insert(cert);

        // å‘é€å‘é‡åŒ–æ¶ˆæ¯
        VectorizeMessage message = VectorizeMessage.builder()
            .capabilityId(cert.getId())
            .capabilityType("certification")
            .organizationId(cert.getOrganizationId())
            .build();

        rabbitTemplate.convertAndSend(
            "ai.vectorize.exchange",
            "vectorize.certification",
            message
        );

        return cert;
    }

    /**
     * æ£€æŸ¥å³å°†åˆ°æœŸçš„è¯ä¹¦
     */
    public List<Certification> checkExpiringCertifications(int daysBeforeExpiry) {
        LocalDate expiryThreshold = LocalDate.now().plusDays(daysBeforeExpiry);

        return certificationMapper.selectList(
            new QueryWrapper<Certification>()
                .le("expiry_date", expiryThreshold)
                .ge("expiry_date", LocalDate.now())
                .eq("is_valid", true)
        );
    }

    private boolean checkValidity(LocalDate expiryDate) {
        if (expiryDate == null) {
            return true;  // é•¿æœŸæœ‰æ•ˆ
        }
        return expiryDate.isAfter(LocalDate.now());
    }
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] è¯ä¹¦æœ‰æ•ˆæ€§è‡ªåŠ¨åˆ¤æ–­
- [ ] å³å°†åˆ°æœŸè¯ä¹¦èƒ½æ­£ç¡®æŸ¥è¯¢
- [ ] å‘é‡åŒ–æ¶ˆæ¯å‘é€æˆåŠŸ

#### 4) Pythonåç«¯

```python
# app/services/ai/certification_vectorization_service.py
class CertificationVectorizationService:
    """èµ„è´¨è¯ä¹¦å‘é‡åŒ–æœåŠ¡"""

    async def vectorize_certification(
        self,
        certification_id: str,
        organization_id: str
    ) -> Dict[str, Any]:
        """å‘é‡åŒ–èµ„è´¨è¯ä¹¦"""

        # 1. è·å–è¯ä¹¦è¯¦æƒ…
        response = await self.java_client.get(
            f"/api/v1/capabilities/certifications/{certification_id}"
        )
        cert_data = response.json()['data']

        # 2. æ„å»ºå‘é‡åŒ–æ–‡æœ¬
        vectorize_text = self._build_certification_text(cert_data)

        # 3. ç”Ÿæˆå‘é‡
        embedding = await self.embedding_model.aget_text_embedding(vectorize_text)

        # 4. å­˜å‚¨åˆ°Elasticsearch
        await self.es_store.add_document(
            doc_id=certification_id,
            embedding=embedding,
            metadata={
                'capability_id': certification_id,
                'organization_id': organization_id,
                'capability_type': 'certification',
                'certification_name': cert_data['certificationName'],
                'certification_type': cert_data['certificationType'],
                'issuing_authority': cert_data['issuingAuthority'],
                'issue_date': cert_data.get('issueDate'),
                'expiry_date': cert_data.get('expiryDate'),
                'is_valid': cert_data.get('isValid', True),
                'scope': cert_data.get('scope'),
                'level': cert_data.get('level'),
                'tags': cert_data.get('tags', []),
                'vectorized_at': datetime.utcnow().isoformat()
            },
            index_name="capabilities"
        )

        # 5. å›è°ƒJavaæœåŠ¡
        await self._callback_java_service(certification_id, "completed")

        return {
            'certification_id': certification_id,
            'status': 'completed'
        }

    def _build_certification_text(self, cert_data: Dict[str, Any]) -> str:
        """æ„å»ºè¯ä¹¦å‘é‡åŒ–æ–‡æœ¬"""
        parts = []

        parts.append(f"è¯ä¹¦åç§°ï¼š{cert_data['certificationName']}")
        parts.append(f"è¯ä¹¦ç±»å‹ï¼š{cert_data.get('certificationType', 'æœªåˆ†ç±»')}")
        parts.append(f"é¢å‘æœºæ„ï¼š{cert_data['issuingAuthority']}")

        if cert_data.get('scope'):
            parts.append(f"è®¤è¯èŒƒå›´ï¼š{cert_data['scope']}")

        if cert_data.get('level'):
            parts.append(f"ç­‰çº§ï¼š{cert_data['level']}")

        if cert_data.get('certificateNumber'):
            parts.append(f"è¯ä¹¦ç¼–å·ï¼š{cert_data['certificateNumber']}")

        return "\n".join(parts)
```

**éªŒè¯æ ‡å‡†**:
- [ ] è¯ä¹¦æ–‡æœ¬æ„å»ºå®Œæ•´
- [ ] æœ‰æ•ˆæœŸä¿¡æ¯æ­£ç¡®å­˜å‚¨
- [ ] å‘é‡ç”ŸæˆæˆåŠŸ

#### 5) éƒ¨ç½²

```yaml
# RabbitMQé˜Ÿåˆ—é…ç½®
services:
  vectorization-consumer:
    environment:
      - CERT_QUEUE_NAME=ai.vectorize.certification.queue
```

**éªŒè¯æ ‡å‡†**:
- [ ] è¯ä¹¦å‘é‡åŒ–é˜Ÿåˆ—æ­£å¸¸å·¥ä½œ
- [ ] Workerèƒ½å¤„ç†è¯ä¹¦å‘é‡åŒ–ä»»åŠ¡

---

### äºŒçº§ä»»åŠ¡ 3.4: å‘é‡æ£€ç´¢ä¼˜åŒ–

**å·¥ä½œé‡ä¼°ç®—**: 3 äººå¤©
**ä¼˜å…ˆçº§**: P2 - é«˜ä¼˜å…ˆçº§ï¼ˆæ£€ç´¢æ€§èƒ½ä¼˜åŒ–ï¼‰
**æŠ€æœ¯éš¾ç‚¹**:
- æ··åˆæ£€ç´¢ç®—æ³•å®ç°
- æ£€ç´¢ç»“æœé‡æ’åº
- æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

#### 1) æ•°æ®å®šä¹‰

##### æ£€ç´¢å‚æ•°æ¨¡å‹
```python
# app/models/search.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from enum import Enum

class SearchMode(str, Enum):
    """æ£€ç´¢æ¨¡å¼"""
    VECTOR_ONLY = "vector_only"          # ä»…å‘é‡æ£€ç´¢
    KEYWORD_ONLY = "keyword_only"        # ä»…å…³é”®è¯æ£€ç´¢
    HYBRID = "hybrid"                    # æ··åˆæ£€ç´¢

class RerankStrategy(str, Enum):
    """é‡æ’åºç­–ç•¥"""
    RRF = "rrf"                          # Reciprocal Rank Fusion
    LINEAR_COMBINATION = "linear"         # çº¿æ€§ç»„åˆ
    LLM_RERANK = "llm_rerank"            # LLMé‡æ’åº

class SearchRequest(BaseModel):
    """æ£€ç´¢è¯·æ±‚"""
    query: str = Field(..., description="æŸ¥è¯¢æ–‡æœ¬")
    organization_id: str = Field(..., description="ç»„ç»‡ID")
    capability_types: Optional[List[str]] = Field(None, description="èƒ½åŠ›ç±»å‹è¿‡æ»¤")
    top_k: int = Field(10, ge=1, le=100, description="è¿”å›ç»“æœæ•°é‡")

    # æ£€ç´¢æ¨¡å¼
    search_mode: SearchMode = Field(SearchMode.HYBRID, description="æ£€ç´¢æ¨¡å¼")
    vector_weight: float = Field(0.7, ge=0.0, le=1.0, description="å‘é‡æ£€ç´¢æƒé‡")
    keyword_weight: float = Field(0.3, ge=0.0, le=1.0, description="å…³é”®è¯æ£€ç´¢æƒé‡")

    # é‡æ’åº
    enable_rerank: bool = Field(True, description="æ˜¯å¦å¯ç”¨é‡æ’åº")
    rerank_strategy: RerankStrategy = Field(RerankStrategy.RRF, description="é‡æ’åºç­–ç•¥")
    rerank_top_k: int = Field(50, description="é‡æ’åºå€™é€‰æ•°é‡")

    # è¿‡æ»¤æ¡ä»¶
    filters: Optional[Dict[str, Any]] = Field(None, description="é¢å¤–è¿‡æ»¤æ¡ä»¶")

class SearchResult(BaseModel):
    """æ£€ç´¢ç»“æœ"""
    capability_id: str
    capability_type: str
    name: str
    description: str
    relevance_score: float = Field(..., description="ç›¸å…³æ€§åˆ†æ•°")
    vector_score: Optional[float] = Field(None, description="å‘é‡ç›¸ä¼¼åº¦åˆ†æ•°")
    keyword_score: Optional[float] = Field(None, description="å…³é”®è¯åŒ¹é…åˆ†æ•°")
    rerank_score: Optional[float] = Field(None, description="é‡æ’åºåˆ†æ•°")
    metadata: Dict[str, Any] = Field(default_factory=dict)

class SearchResponse(BaseModel):
    """æ£€ç´¢å“åº”"""
    query: str
    results: List[SearchResult]
    total_results: int
    search_time_ms: float
    search_mode: SearchMode
    rerank_applied: bool
```

**éªŒè¯æ ‡å‡†**:
- [ ] æ£€ç´¢å‚æ•°éªŒè¯é€šè¿‡
- [ ] æƒé‡å’Œå‚æ•°èŒƒå›´æ ¡éªŒæ­£ç¡®

#### 2) å‰ç«¯

```typescript
// src/components/CapabilitySearch/index.tsx
import { Input, Select, Slider, Switch, Space, Card } from 'antd';
import { SearchOutlined } from '@ant-design/icons';
import { useState } from 'react';

interface SearchPanelProps {
  onSearch: (params: SearchParams) => void;
}

export default function CapabilitySearchPanel({ onSearch }: SearchPanelProps) {
  const [query, setQuery] = useState('');
  const [searchMode, setSearchMode] = useState<'hybrid' | 'vector_only' | 'keyword_only'>('hybrid');
  const [vectorWeight, setVectorWeight] = useState(0.7);
  const [enableRerank, setEnableRerank] = useState(true);
  const [rerankStrategy, setRerankStrategy] = useState<'rrf' | 'linear' | 'llm_rerank'>('rrf');

  const handleSearch = () => {
    onSearch({
      query,
      search_mode: searchMode,
      vector_weight: vectorWeight,
      keyword_weight: 1 - vectorWeight,
      enable_rerank: enableRerank,
      rerank_strategy: rerankStrategy,
      top_k: 10,
    });
  };

  return (
    <Card title="èƒ½åŠ›æ£€ç´¢é…ç½®">
      <Space direction="vertical" style={{ width: '100%' }} size="large">
        {/* æŸ¥è¯¢è¾“å…¥ */}
        <Input.Search
          placeholder="è¾“å…¥æŸ¥è¯¢éœ€æ±‚..."
          value={query}
          onChange={e => setQuery(e.target.value)}
          onSearch={handleSearch}
          enterButton={<SearchOutlined />}
          size="large"
        />

        {/* æ£€ç´¢æ¨¡å¼ */}
        <div>
          <label>æ£€ç´¢æ¨¡å¼ï¼š</label>
          <Select
            value={searchMode}
            onChange={setSearchMode}
            style={{ width: 200 }}
            options={[
              { label: 'æ··åˆæ£€ç´¢ï¼ˆæ¨èï¼‰', value: 'hybrid' },
              { label: 'ä»…å‘é‡æ£€ç´¢', value: 'vector_only' },
              { label: 'ä»…å…³é”®è¯æ£€ç´¢', value: 'keyword_only' },
            ]}
          />
        </div>

        {/* æƒé‡è°ƒæ•´ï¼ˆä»…æ··åˆæ¨¡å¼ï¼‰ */}
        {searchMode === 'hybrid' && (
          <div>
            <label>å‘é‡æ£€ç´¢æƒé‡ï¼š{vectorWeight.toFixed(1)}</label>
            <Slider
              min={0}
              max={1}
              step={0.1}
              value={vectorWeight}
              onChange={setVectorWeight}
              marks={{
                0: 'å…³é”®è¯',
                0.5: 'å¹³è¡¡',
                1: 'å‘é‡',
              }}
            />
          </div>
        )}

        {/* é‡æ’åºé…ç½® */}
        <div>
          <Space>
            <label>å¯ç”¨é‡æ’åºï¼š</label>
            <Switch checked={enableRerank} onChange={setEnableRerank} />
          </Space>
        </div>

        {enableRerank && (
          <div>
            <label>é‡æ’åºç­–ç•¥ï¼š</label>
            <Select
              value={rerankStrategy}
              onChange={setRerankStrategy}
              style={{ width: 200 }}
              options={[
                { label: 'RRFï¼ˆå€’æ•°æ’åèåˆï¼‰', value: 'rrf' },
                { label: 'çº¿æ€§ç»„åˆ', value: 'linear' },
                { label: 'LLMé‡æ’åº', value: 'llm_rerank' },
              ]}
            />
          </div>
        )}
      </Space>
    </Card>
  );
}

// æœç´¢ç»“æœå±•ç¤ºç»„ä»¶
function SearchResults({ results }: { results: SearchResult[] }) {
  return (
    <List
      dataSource={results}
      renderItem={(item) => (
        <List.Item>
          <Card hoverable>
            <Card.Meta
              title={
                <Space>
                  <Tag color="blue">{item.capabilityType}</Tag>
                  <span>{item.name}</span>
                  <Tag color="green">åŒ¹é…åº¦: {(item.relevanceScore * 100).toFixed(1)}%</Tag>
                </Space>
              }
              description={item.description}
            />
            <div style={{ marginTop: 16 }}>
              <Space>
                {item.vectorScore && (
                  <Tag>å‘é‡åˆ†: {item.vectorScore.toFixed(3)}</Tag>
                )}
                {item.keywordScore && (
                  <Tag>å…³é”®è¯åˆ†: {item.keywordScore.toFixed(3)}</Tag>
                )}
                {item.rerankScore && (
                  <Tag color="orange">é‡æ’åºåˆ†: {item.rerankScore.toFixed(3)}</Tag>
                )}
              </Space>
            </div>
          </Card>
        </List.Item>
      )}
    />
  );
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] æ£€ç´¢é…ç½®é¢æ¿äº¤äº’æ­£å¸¸
- [ ] æƒé‡æ»‘å—å®æ—¶æ›´æ–°
- [ ] æœç´¢ç»“æœæ­£ç¡®å±•ç¤ºå„é¡¹åˆ†æ•°

#### 3) Javaåç«¯

```java
// æ£€ç´¢é…ç½®ç®¡ç†
@Service
public class SearchConfigService {

    /**
     * ä¿å­˜ç”¨æˆ·çš„æ£€ç´¢åå¥½
     */
    public void saveSearchPreference(String userId, SearchPreference preference) {
        // ä¿å­˜åˆ°Redis
        String key = "search:preference:" + userId;
        redisTemplate.opsForValue().set(key, preference, 7, TimeUnit.DAYS);
    }

    /**
     * è·å–ç”¨æˆ·çš„æ£€ç´¢åå¥½
     */
    public SearchPreference getSearchPreference(String userId) {
        String key = "search:preference:" + userId;
        SearchPreference preference = redisTemplate.opsForValue().get(key);

        if (preference == null) {
            // è¿”å›é»˜è®¤é…ç½®
            preference = SearchPreference.builder()
                .searchMode("hybrid")
                .vectorWeight(0.7)
                .keywordWeight(0.3)
                .enableRerank(true)
                .rerankStrategy("rrf")
                .build();
        }

        return preference;
    }
}
```

**éªŒè¯æ ‡å‡†**:
- [ ] ç”¨æˆ·åå¥½èƒ½æ­£ç¡®ä¿å­˜å’Œè¯»å–
- [ ] Redisç¼“å­˜æ­£å¸¸å·¥ä½œ

#### 4) Pythonåç«¯

##### æ··åˆæ£€ç´¢æœåŠ¡
```python
# app/services/ai/hybrid_search_service.py
from typing import List, Dict, Any
from app.models.search import SearchRequest, SearchResponse, SearchResult, SearchMode, RerankStrategy
from app.services.ai.elasticsearch_store import ElasticsearchVectorStore
from app.services.ai.embedding_service import EmbeddingService
import time
import logging

logger = logging.getLogger(__name__)

class HybridSearchService:
    """æ··åˆæ£€ç´¢æœåŠ¡
    éœ€æ±‚ç¼–å·: REQ-AI-003
    å®ç°å‘é‡æ£€ç´¢+å…³é”®è¯æ£€ç´¢+ç»“æœé‡æ’åº
    """

    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.es_store = ElasticsearchVectorStore()

    async def search(self, request: SearchRequest) -> SearchResponse:
        """
        æ‰§è¡Œæ··åˆæ£€ç´¢

        Args:
            request: æ£€ç´¢è¯·æ±‚

        Returns:
            æ£€ç´¢ç»“æœ
        """
        start_time = time.time()

        logger.info(f"Hybrid search: query='{request.query}', mode={request.search_mode}")

        # 1. æ ¹æ®æ£€ç´¢æ¨¡å¼æ‰§è¡Œä¸åŒçš„æ£€ç´¢ç­–ç•¥
        if request.search_mode == SearchMode.VECTOR_ONLY:
            results = await self._vector_search(request)
        elif request.search_mode == SearchMode.KEYWORD_ONLY:
            results = await self._keyword_search(request)
        else:  # HYBRID
            results = await self._hybrid_search(request)

        # 2. é‡æ’åºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if request.enable_rerank and len(results) > 0:
            results = await self._rerank_results(
                query=request.query,
                results=results,
                strategy=request.rerank_strategy,
                top_k=request.top_k
            )

        # 3. å–Top-K
        results = results[:request.top_k]

        search_time_ms = (time.time() - start_time) * 1000

        logger.info(f"Search completed: {len(results)} results in {search_time_ms:.2f}ms")

        return SearchResponse(
            query=request.query,
            results=results,
            total_results=len(results),
            search_time_ms=search_time_ms,
            search_mode=request.search_mode,
            rerank_applied=request.enable_rerank
        )

    async def _vector_search(self, request: SearchRequest) -> List[SearchResult]:
        """çº¯å‘é‡æ£€ç´¢"""
        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = await self.embedding_service.embed_text(request.query)

        # 2. Elasticsearch kNNæ£€ç´¢
        es_results = await self.es_store.search(
            query_embedding=query_embedding,
            top_k=request.rerank_top_k if request.enable_rerank else request.top_k,
            filter_dict={
                'organization_id': request.organization_id,
                'is_active': True,
                **(request.filters or {})
            }
        )

        # 3. è½¬æ¢ä¸ºSearchResult
        results = []
        for es_result in es_results:
            results.append(SearchResult(
                capability_id=es_result['id'],
                capability_type=es_result['metadata'].get('capability_type', 'unknown'),
                name=es_result['metadata'].get('name', ''),
                description=es_result['content'],
                relevance_score=es_result['score'],
                vector_score=es_result['score'],
                metadata=es_result['metadata']
            ))

        return results

    async def _keyword_search(self, request: SearchRequest) -> List[SearchResult]:
        """çº¯å…³é”®è¯æ£€ç´¢"""
        # ä½¿ç”¨Elasticsearchçš„å…¨æ–‡æœç´¢
        query_body = {
            "query": {
                "bool": {
                    "must": [
                        {
                            "multi_match": {
                                "query": request.query,
                                "fields": ["name^3", "description^2", "features", "advantages"],
                                "type": "best_fields",
                                "operator": "or"
                            }
                        }
                    ],
                    "filter": [
                        {"term": {"organization_id": request.organization_id}},
                        {"term": {"is_active": True}}
                    ]
                }
            },
            "size": request.rerank_top_k if request.enable_rerank else request.top_k
        }

        # æ·»åŠ é¢å¤–è¿‡æ»¤æ¡ä»¶
        if request.filters:
            for key, value in request.filters.items():
                query_body["query"]["bool"]["filter"].append({"term": {key: value}})

        # æ‰§è¡Œæœç´¢
        response = await self.es_store.es_client.search(
            index="capabilities",
            body=query_body
        )

        # è½¬æ¢ç»“æœ
        results = []
        max_score = response['hits']['max_score'] if response['hits']['max_score'] else 1.0

        for hit in response['hits']['hits']:
            results.append(SearchResult(
                capability_id=hit['_source']['capability_id'],
                capability_type=hit['_source']['capability_type'],
                name=hit['_source']['name'],
                description=hit['_source']['description'],
                relevance_score=hit['_score'] / max_score,  # å½’ä¸€åŒ–
                keyword_score=hit['_score'] / max_score,
                metadata=hit['_source']
            ))

        return results

    async def _hybrid_search(self, request: SearchRequest) -> List[SearchResult]:
        """
        æ··åˆæ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + å…³é”®è¯æ£€ç´¢ + åˆ†æ•°èåˆ
        """
        # 1. å¹¶è¡Œæ‰§è¡Œå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢
        vector_results = await self._vector_search(request)
        keyword_results = await self._keyword_search(request)

        # 2. ç»“æœèåˆ
        # åˆ›å»ºIDåˆ°ç»“æœçš„æ˜ å°„
        combined_results = {}

        # æ·»åŠ å‘é‡æ£€ç´¢ç»“æœ
        for result in vector_results:
            combined_results[result.capability_id] = result

        # åˆå¹¶å…³é”®è¯æ£€ç´¢ç»“æœ
        for keyword_result in keyword_results:
            cap_id = keyword_result.capability_id

            if cap_id in combined_results:
                # å·²å­˜åœ¨ï¼Œåˆå¹¶åˆ†æ•°
                vector_result = combined_results[cap_id]

                # åŠ æƒç»„åˆ
                combined_score = (
                    vector_result.vector_score * request.vector_weight +
                    keyword_result.keyword_score * request.keyword_weight
                )

                vector_result.relevance_score = combined_score
                vector_result.keyword_score = keyword_result.keyword_score
            else:
                # æ–°ç»“æœï¼Œåªæœ‰å…³é”®è¯åˆ†æ•°
                keyword_result.relevance_score = keyword_result.keyword_score * request.keyword_weight
                combined_results[cap_id] = keyword_result

        # 3. æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        sorted_results = sorted(
            combined_results.values(),
            key=lambda x: x.relevance_score,
            reverse=True
        )

        return sorted_results

    async def _rerank_results(
        self,
        query: str,
        results: List[SearchResult],
        strategy: RerankStrategy,
        top_k: int
    ) -> List[SearchResult]:
        """
        é‡æ’åº

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            results: åˆæ­¥æ£€ç´¢ç»“æœ
            strategy: é‡æ’åºç­–ç•¥
            top_k: æœ€ç»ˆè¿”å›æ•°é‡

        Returns:
            é‡æ’åºåçš„ç»“æœ
        """
        logger.info(f"Reranking {len(results)} results with strategy: {strategy}")

        if strategy == RerankStrategy.RRF:
            # Reciprocal Rank Fusion
            return self._rrf_rerank(results, top_k)
        elif strategy == RerankStrategy.LINEAR_COMBINATION:
            # çº¿æ€§ç»„åˆï¼ˆå·²åœ¨hybrid_searchä¸­å®ç°ï¼‰
            return results[:top_k]
        elif strategy == RerankStrategy.LLM_RERANK:
            # LLMé‡æ’åº
            return await self._llm_rerank(query, results, top_k)
        else:
            return results[:top_k]

    def _rrf_rerank(
        self,
        results: List[SearchResult],
        top_k: int,
        k: int = 60
    ) -> List[SearchResult]:
        """
        RRFé‡æ’åºï¼ˆReciprocal Rank Fusionï¼‰

        å…¬å¼: RRF(d) = Î£ 1 / (k + rank_i(d))
        å…¶ä¸­ rank_i(d) æ˜¯æ–‡æ¡£dåœ¨ç¬¬iä¸ªæ’åºåˆ—è¡¨ä¸­çš„æ’å

        Args:
            results: æ£€ç´¢ç»“æœ
            top_k: è¿”å›æ•°é‡
            k: RRFå‚æ•°ï¼Œé€šå¸¸å–60

        Returns:
            é‡æ’åºåçš„ç»“æœ
        """
        # åˆ†åˆ«è·å–å‘é‡æ’åºå’Œå…³é”®è¯æ’åº
        vector_ranked = sorted(
            [r for r in results if r.vector_score is not None],
            key=lambda x: x.vector_score,
            reverse=True
        )
        keyword_ranked = sorted(
            [r for r in results if r.keyword_score is not None],
            key=lambda x: x.keyword_score,
            reverse=True
        )

        # è®¡ç®—RRFåˆ†æ•°
        rrf_scores = {}

        for rank, result in enumerate(vector_ranked):
            cap_id = result.capability_id
            rrf_scores[cap_id] = rrf_scores.get(cap_id, 0) + 1 / (k + rank + 1)

        for rank, result in enumerate(keyword_ranked):
            cap_id = result.capability_id
            rrf_scores[cap_id] = rrf_scores.get(cap_id, 0) + 1 / (k + rank + 1)

        # æ›´æ–°åˆ†æ•°å¹¶æ’åº
        for result in results:
            if result.capability_id in rrf_scores:
                result.rerank_score = rrf_scores[result.capability_id]
                result.relevance_score = result.rerank_score  # ä½¿ç”¨RRFåˆ†æ•°ä½œä¸ºæœ€ç»ˆç›¸å…³æ€§åˆ†æ•°

        # æŒ‰RRFåˆ†æ•°æ’åº
        reranked = sorted(
            results,
            key=lambda x: x.rerank_score if x.rerank_score else 0,
            reverse=True
        )

        return reranked[:top_k]

    async def _llm_rerank(
        self,
        query: str,
        results: List[SearchResult],
        top_k: int
    ) -> List[SearchResult]:
        """
        LLMé‡æ’åº
        ä½¿ç”¨GPTæ¨¡å‹è¯„ä¼°æ¯ä¸ªç»“æœä¸æŸ¥è¯¢çš„ç›¸å…³æ€§
        """
        # TODO: å®ç°LLMé‡æ’åº
        # ä½¿ç”¨GPT-4è¯„ä¼°ç›¸å…³æ€§
        logger.warning("LLM rerank not implemented yet, falling back to RRF")
        return self._rrf_rerank(results, top_k)
```

##### APIæ¥å£
```python
# app/api/v1/search.py
from fastapi import APIRouter, HTTPException
from app.models.search import SearchRequest, SearchResponse
from app.services.ai.hybrid_search_service import HybridSearchService

router = APIRouter(prefix="/search", tags=["æ£€ç´¢"])

search_service = HybridSearchService()

@router.post("/capabilities", response_model=SearchResponse)
async def search_capabilities(request: SearchRequest):
    """
    èƒ½åŠ›æ£€ç´¢
    éœ€æ±‚ç¼–å·: REQ-AI-003

    æ”¯æŒä¸‰ç§æ£€ç´¢æ¨¡å¼:
    - vector_only: ä»…å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
    - keyword_only: ä»…å…³é”®è¯æ£€ç´¢ï¼ˆå…¨æ–‡æœç´¢ï¼‰
    - hybrid: æ··åˆæ£€ç´¢ï¼ˆæ¨èï¼‰

    æ”¯æŒä¸‰ç§é‡æ’åºç­–ç•¥:
    - rrf: Reciprocal Rank Fusionï¼ˆå€’æ•°æ’åèåˆï¼‰
    - linear: çº¿æ€§ç»„åˆ
    - llm_rerank: LLMé‡æ’åºï¼ˆä½¿ç”¨GPTè¯„ä¼°ç›¸å…³æ€§ï¼‰
    """
    try:
        response = await search_service.search(request)
        return response
    except Exception as e:
        logger.error(f"Search failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
```

**éªŒè¯æ ‡å‡†**:
- [ ] ä¸‰ç§æ£€ç´¢æ¨¡å¼éƒ½èƒ½æ­£å¸¸å·¥ä½œ
- [ ] RRFé‡æ’åºç®—æ³•æ­£ç¡®å®ç°
- [ ] åˆ†æ•°å½’ä¸€åŒ–å’Œèåˆæ­£ç¡®
- [ ] æ£€ç´¢æ€§èƒ½æ»¡è¶³è¦æ±‚ï¼ˆ<500msï¼‰

#### 5) éƒ¨ç½²

##### Elasticsearchç´¢å¼•ä¼˜åŒ–
```json
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 2,
    "index": {
      "similarity": {
        "custom_bm25": {
          "type": "BM25",
          "b": 0.75,
          "k1": 1.2
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart",
        "similarity": "custom_bm25"
      },
      "description": {
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart"
      },
      "embedding": {
        "type": "dense_vector",
        "dims": 1536,
        "index": true,
        "similarity": "cosine",
        "index_options": {
          "type": "hnsw",
          "m": 16,
          "ef_construction": 100
        }
      }
    }
  }
}
```

##### æ€§èƒ½ç›‘æ§
```python
# app/middleware/search_metrics.py
from prometheus_client import Counter, Histogram
import time

# æŒ‡æ ‡å®šä¹‰
search_requests = Counter('search_requests_total', 'Total search requests', ['search_mode'])
search_latency = Histogram('search_latency_seconds', 'Search latency', ['search_mode'])
search_result_count = Histogram('search_result_count', 'Number of search results')

async def track_search_metrics(request: SearchRequest, response: SearchResponse):
    """è®°å½•æ£€ç´¢æŒ‡æ ‡"""
    search_requests.labels(search_mode=request.search_mode).inc()
    search_latency.labels(search_mode=request.search_mode).observe(
        response.search_time_ms / 1000
    )
    search_result_count.observe(len(response.results))
```

**éªŒè¯æ ‡å‡†**:
- [ ] Elasticsearchç´¢å¼•ä¼˜åŒ–é…ç½®ç”Ÿæ•ˆ
- [ ] ç›‘æ§æŒ‡æ ‡æ­£å¸¸é‡‡é›†
- [ ] Grafanaä»ªè¡¨æ¿èƒ½å±•ç¤ºæ£€ç´¢æ€§èƒ½

---

### æ¨¡å—æ€»ç»“

#### å®Œæˆè¿›åº¦ç»Ÿè®¡

**äºŒçº§ä»»åŠ¡å®Œæˆæƒ…å†µ**:
- 3.1 äº§å“æœåŠ¡å‘é‡åŒ–: âœ… è¯¦ç»†è§„åˆ’å®Œæˆï¼ˆ4äººå¤©ï¼‰
- 3.2 é¡¹ç›®ç»éªŒå‘é‡åŒ–: âœ… è¯¦ç»†è§„åˆ’å®Œæˆï¼ˆ4äººå¤©ï¼‰
- 3.3 èµ„è´¨è¯ä¹¦å‘é‡åŒ–: âœ… è¯¦ç»†è§„åˆ’å®Œæˆï¼ˆ3äººå¤©ï¼‰
- 3.4 å‘é‡æ£€ç´¢ä¼˜åŒ–: âœ… è¯¦ç»†è§„åˆ’å®Œæˆï¼ˆ3äººå¤©ï¼‰

**é¢„è®¡æ€»å·¥ä½œé‡**: 14 äººå¤©

### ç»†åŒ–æ•ˆæœ

âœ… **ç»†åŒ–å‰**: 4ä¸ªç²—ç²’åº¦å­ä»»åŠ¡
âœ… **ç»†åŒ–å**: æ¯ä¸ªå­ä»»åŠ¡æ‹†åˆ†ä¸º5ç±»åˆ«ï¼Œå…± 20+ å…·ä½“ä»»åŠ¡é¡¹

### å…³é”®ä¾èµ–

1. **AI-001 â†’ AI-003**: AI-003ä¾èµ–AI-001çš„Elasticsearchå‘é‡å­˜å‚¨åŸºç¡€è®¾æ–½
2. **å‘é‡åŒ– â†’ æ£€ç´¢**: æ£€ç´¢ä¼˜åŒ–éœ€è¦å…ˆå®Œæˆå‘é‡åŒ–
3. **JavaæœåŠ¡ â†’ PythonæœåŠ¡**: PythonæœåŠ¡ä¾èµ–JavaæœåŠ¡æä¾›èƒ½åŠ›æ•°æ®

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ä¼˜å…ˆå¼€å§‹**: äºŒçº§ä»»åŠ¡ 3.1ï¼ˆäº§å“æœåŠ¡å‘é‡åŒ–ï¼‰
   - å»ºç«‹å‘é‡åŒ–åŸºç¡€æµç¨‹
   - å®ŒæˆRabbitMQæ¶ˆæ¯é˜Ÿåˆ—é›†æˆ
   - å®ç°é¦–ä¸ªå‘é‡åŒ–Pipeline

2. **å¹¶è¡Œå¼€å‘**:
   - äº§å“/æ¡ˆä¾‹/è¯ä¹¦å‘é‡åŒ–å¯ä»¥å¹¶è¡Œï¼ˆ3.1-3.3ï¼‰
   - æ£€ç´¢ä¼˜åŒ–ï¼ˆ3.4ï¼‰éœ€è¦ç­‰å¾…å‘é‡æ•°æ®ç§¯ç´¯

---


---
**ğŸ“– ä¸‹ä¸€æ­¥**: [AI-004 æ™ºèƒ½åŒ¹é…åˆ†æ](./task-plan-python-ai-è¯¦ç»†-AI-004.md)
