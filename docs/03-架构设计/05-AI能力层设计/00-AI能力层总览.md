---
文档类型: 架构文档
需求编号: DOC-2025-11-001
创建日期: 2025-11-29
创建者: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
最后更新: 2025-11-29
更新者: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
状态: 已批准
---

# AI标书智能创作平台 - AI能力层总览

> **服务架构**: 独立的Python AI服务
> **技术栈**: Python 3.11 + FastAPI + LlamaIndex (主力) + LangChain (备用)
> **向量存储**: Elasticsearch (主力)，支持Pinecone作为云端备选方案
> **端口**: 8001

## 📋 文档导航

本目录包含AI能力层的详细设计文档，已按功能模块拆分为以下文件：

1. **00-AI能力层总览.md**（本文档）- AI能力矩阵和技术栈概览
2. **01-LLM服务架构.md** - LLM客户端、Prompt管理、任务队列
3. **02-向量检索服务.md** - 向量嵌入服务、Elasticsearch、Pinecone存储
4. **03-知识图谱服务.md** - 知识图谱管理、智能匹配引擎
5. **04-工作流与优化.md** - 工作流编排、成本优化、性能优化

## 📋 AI能力概览

### AI能力矩阵

```yaml
核心AI能力:
  文档理解:
    - 招标文件解析
    - 需求提取
    - 关键信息识别
    - 风险点分析

  智能匹配:
    - 需求-能力匹配
    - 案例推荐
    - 人员匹配
    - 解决方案推荐

  内容生成:
    - 技术方案生成
    - 商务方案生成
    - 项目计划生成
    - 响应文档生成

  质量保证:
    - 内容查重
    - 完整性检查
    - 合规性审核
    - 质量评分

  知识管理:
    - 知识抽取
    - 知识图谱构建
    - 语义检索
    - 知识推理
```

### AI技术栈

```yaml
Python AI服务技术栈:

  核心框架:
    - FastAPI: Web框架，异步支持
    - LlamaIndex: 主力RAG框架，数据索引和检索
    - LangChain: 备用AI应用框架
    - Pydantic: 数据验证
    - Uvicorn: ASGI服务器

  大语言模型:
    主模型:
      - GPT-4 Turbo: 复杂推理、创作
      - GPT-3.5 Turbo: 日常对话、简单生成
      - Claude 3 Opus: 长文本理解、深度分析

    国产模型:
      - 智谱ChatGLM: 中文理解、对话
      - 百度文心一言: 中文生成
      - 阿里通义千问: 企业场景

    开源模型:
      - Llama 2: 本地部署、隐私场景
      - Mistral: 轻量级推理
      - DeepSeek: 代码理解

  向量嵌入:
    - OpenAI text-embedding-ada-002
    - HuggingFace Sentence-BERT
    - 智谱GLM Embedding

  向量存储:
    主力方案:
      - Elasticsearch: 本地部署，全文检索+向量检索
        - 版本: 8.x+
        - 优势: 成熟稳定、功能强大、可本地部署
        - 功能: 支持向量检索(kNN)、全文检索、聚合分析

    备选方案:
      - Pinecone: 云端托管向量数据库
        - 优势: 性能优秀、免运维
        - 场景: 云端部署、快速原型

      - Chroma: 轻量级本地部署
        - 优势: 简单易用、适合开发测试
        - 场景: 开发环境

  图数据库:
    - Neo4j: 知识图谱存储
    - ArangoDB: 多模型数据库（备选）

  工作流编排:
    - LangGraph: 复杂AI工作流编排
    - Celery: 异步任务队列

  服务间通信:
    - HTTP REST API: 与Java服务通信
    - RabbitMQ: 消息队列集成
```

## 🎯 AI服务职责

### 核心职责

Python AI服务专注于以下AI能力，与Java服务形成清晰的职责分工：

**AI能力（Python服务负责）**:
- 调用大语言模型（GPT-4、Claude等）
- 文档智能解析和向量化
- 需求分析和智能提取
- 智能内容生成和优化
- 语义搜索和相似度匹配
- 知识图谱构建和推理
- AI质量审查和评分

**数据维护（Java服务负责）**:
- 用户认证和授权
- 组织和项目管理
- 文档CRUD操作
- 模板管理和版本控制
- 协作和审批流程
- 权限和角色管理

### 服务间通信

```
┌─────────────────┐                           ┌─────────────────┐
│   Java Service  │◄─────── HTTP REST ───────►│  Python Service │
│  (Spring Boot)  │                           │    (FastAPI)    │
│   Port: 8080    │                           │   Port: 8001    │
└────────┬────────┘                           └────────┬────────┘
         │                                              │
         └──────────► RabbitMQ ◄──────────────────────┘
                (异步任务、事件通知)
```

## 📊 性能指标

### AI服务性能目标

| 指标类型 | 指标 | 目标值 |
|---------|------|--------|
| 响应时间 | 文档解析 | < 5s |
| 响应时间 | 需求分析 | < 3s |
| 响应时间 | 内容生成 | < 10s |
| 响应时间 | 向量检索 | < 500ms |
| 并发能力 | AI请求 | 100 req/s |
| 准确率 | 需求提取 | > 90% |
| 准确率 | 能力匹配 | > 85% |
| 可用性 | 服务可用性 | 99.5% |

### Token使用优化

```yaml
Token优化策略:
  上下文压缩:
    - 智能截断长文本
    - 保留关键信息
    - 最大Token限制: 4000

  缓存策略:
    - 相似请求缓存
    - 缓存有效期: 1小时
    - 缓存命中率目标: > 30%

  模型选择:
    - 简单任务: GPT-3.5 Turbo
    - 复杂任务: GPT-4 Turbo
    - 本地部署: Llama 2
```

## 🔗 相关文档

- **LLM服务架构**: [01-LLM服务架构.md](./01-LLM服务架构.md)
- **向量检索服务**: [02-向量检索服务.md](./02-向量检索服务.md)
- **知识图谱服务**: [03-知识图谱服务.md](./03-知识图谱服务.md)
- **工作流与优化**: [04-工作流与优化.md](./04-工作流与优化.md)

---

## 修改历史

| 日期 | 版本 | 修改者 | 修改内容概要 |
|------|------|--------|-------------|
| 2025-11-29 | 1.0 | claude-sonnet-4-5 (claude-sonnet-4-5-20250929) | 从05-AI能力层设计.md拆分创建AI能力层总览文档 |

---

**文档版本**: v1.0
**创建时间**: 2025年11月29日
**文档状态**: ✅ 已批准
