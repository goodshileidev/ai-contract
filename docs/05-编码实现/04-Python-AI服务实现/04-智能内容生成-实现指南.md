---
文档类型: 实现文档
需求编号: REQ-2025-11-004
创建日期: 2025-11-30 11:25
创建者: claude-opus-4-1-20250805
最后更新: 2025-11-30 11:25
更新者: claude-opus-4-1-20250805
状态: 草稿
---

# 智能内容生成 - Python实现指南

## 1. 技术架构

### 1.1 技术栈
- Python 3.11+
- FastAPI 0.104+
- LlamaIndex 0.14.8
- OpenAI SDK 1.0+
- Anthropic SDK 0.7+
- asyncio（并发处理）

### 1.2 项目结构

```
backend/fastapi-ai-service/
├── app/
│   ├── services/
│   │   ├── content_generation/
│   │   │   ├── __init__.py
│   │   │   ├── planner.py         # 内容规划实现
│   │   │   ├── generator.py       # 生成引擎实现
│   │   │   ├── optimizer.py       # 优化器实现
│   │   │   └── models.py          # 数据模型
│   │   └── ...
│   ├── api/
│   │   └── v1/
│   │       └── content.py         # API接口
│   └── core/
│       └── llm_manager.py         # LLM管理
```

## 2. 核心类实现

### 2.1 内容规划器

```python
# app/services/content_generation/planner.py

from typing import Dict, List, Optional
from dataclasses import dataclass
from app.core.llm_manager import LLMManager

@dataclass
class ContentPlan:
    """内容规划数据结构"""
    structure: Dict[str, any]
    allocation: Dict[str, int]
    estimated_pages: int
    generation_strategy: str

class ContentPlanningEngine:
    """内容规划引擎实现"""

    def __init__(self):
        self.llm_manager = LLMManager()
        self.templates = self._load_templates()

    async def plan_content(
        self,
        requirements: Dict,
        company_profile: Dict
    ) -> ContentPlan:
        """
        异步生成内容规划

        Args:
            requirements: 招标需求
            company_profile: 企业档案

        Returns:
            ContentPlan: 内容规划结果
        """
        # 1. 分析需求类型
        project_type = self._identify_project_type(requirements)

        # 2. 选择模板
        template = self._select_template(project_type)

        # 3. 生成文档结构
        structure = await self._generate_structure(
            requirements,
            template
        )

        # 4. 分配内容权重
        allocation = self._allocate_content(
            structure,
            requirements.get('word_count', 50000)
        )

        # 5. 确定生成策略
        strategy = self._determine_strategy(requirements)

        return ContentPlan(
            structure=structure,
            allocation=allocation,
            estimated_pages=self._estimate_pages(allocation),
            generation_strategy=strategy
        )

    def _identify_project_type(self, requirements: Dict) -> str:
        """识别项目类型"""
        # 实现项目类型识别逻辑
        keywords = requirements.get('keywords', [])
        if '工程' in keywords:
            return 'engineering'
        elif '服务' in keywords:
            return 'service'
        else:
            return 'goods'

    def _select_template(self, project_type: str) -> Dict:
        """选择文档模板"""
        return self.templates.get(
            project_type,
            self.templates['default']
        )
```

### 2.2 多模型生成器

```python
# app/services/content_generation/generator.py

import asyncio
from typing import List, Dict, Optional
from app.core.llm_manager import LLMManager
from app.services.content_generation.models import GenerationTask

class MultiModelGenerator:
    """多模型协同生成器"""

    def __init__(self):
        self.llm_manager = LLMManager()
        self.model_selector = ModelSelector()
        self.prompt_builder = PromptBuilder()

    async def generate_content(
        self,
        tasks: List[GenerationTask]
    ) -> List[Dict]:
        """
        并发生成内容

        Args:
            tasks: 生成任务列表

        Returns:
            生成结果列表
        """
        # 创建异步任务
        coroutines = [
            self._generate_single(task)
            for task in tasks
        ]

        # 并发执行
        results = await asyncio.gather(
            *coroutines,
            return_exceptions=True
        )

        # 处理结果
        return self._process_results(results, tasks)

    async def _generate_single(
        self,
        task: GenerationTask
    ) -> Dict:
        """生成单个章节"""
        try:
            # 1. 选择模型
            model = self.model_selector.select(
                task.content_type,
                task.complexity
            )

            # 2. 构建Prompt
            prompt = self.prompt_builder.build(
                task.section,
                task.requirements,
                task.context
            )

            # 3. 调用LLM
            response = await self.llm_manager.generate(
                model=model,
                prompt=prompt,
                max_tokens=task.max_tokens,
                temperature=task.temperature
            )

            # 4. 后处理
            processed = self._post_process(response, task)

            return {
                'section_id': task.section_id,
                'content': processed,
                'model_used': model,
                'tokens_used': response.get('usage', {})
            }

        except Exception as e:
            return {
                'section_id': task.section_id,
                'error': str(e),
                'retry_needed': True
            }
```

### 2.3 LLM管理器

```python
# app/core/llm_manager.py

import openai
from anthropic import Anthropic
from typing import Dict, Optional
import asyncio
from functools import lru_cache

class LLMManager:
    """统一的LLM管理器"""

    def __init__(self):
        self.openai_client = openai.AsyncOpenAI()
        self.anthropic_client = Anthropic()
        self.model_config = self._load_model_config()

    async def generate(
        self,
        model: str,
        prompt: str,
        max_tokens: int = 2000,
        temperature: float = 0.7,
        **kwargs
    ) -> Dict:
        """
        统一的生成接口

        Args:
            model: 模型名称
            prompt: 提示词
            max_tokens: 最大生成长度
            temperature: 温度参数

        Returns:
            生成结果
        """
        if model.startswith('gpt'):
            return await self._generate_openai(
                model, prompt, max_tokens, temperature, **kwargs
            )
        elif model.startswith('claude'):
            return await self._generate_anthropic(
                model, prompt, max_tokens, temperature, **kwargs
            )
        else:
            raise ValueError(f"Unknown model: {model}")

    async def _generate_openai(
        self,
        model: str,
        prompt: str,
        max_tokens: int,
        temperature: float,
        **kwargs
    ) -> Dict:
        """OpenAI模型生成"""
        response = await self.openai_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "你是专业的标书撰写专家"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=temperature,
            **kwargs
        )

        return {
            'content': response.choices[0].message.content,
            'usage': response.usage.dict() if response.usage else {},
            'model': model
        }
```

### 2.4 内容优化器

```python
# app/services/content_generation/optimizer.py

from typing import Dict, List
import numpy as np
from app.services.quality.scorer import QualityScorer

class ContentOptimizer:
    """内容优化器"""

    def __init__(self):
        self.quality_scorer = QualityScorer()
        self.optimization_strategies = {
            'relevance': self._optimize_relevance,
            'completeness': self._optimize_completeness,
            'readability': self._optimize_readability,
            'professionalism': self._optimize_professionalism
        }

    async def optimize(
        self,
        content: str,
        requirements: Dict,
        target_score: float = 85.0
    ) -> Dict:
        """
        优化内容直到达到目标分数

        Args:
            content: 原始内容
            requirements: 需求
            target_score: 目标分数

        Returns:
            优化结果
        """
        current_score = 0
        optimized_content = content
        iterations = 0
        max_iterations = 3

        while current_score < target_score and iterations < max_iterations:
            # 评分
            scores = await self.quality_scorer.score(
                optimized_content,
                requirements
            )
            current_score = scores['total']

            if current_score >= target_score:
                break

            # 识别薄弱维度
            weak_dimensions = self._identify_weak_dimensions(scores)

            # 应用优化策略
            for dimension in weak_dimensions:
                if dimension in self.optimization_strategies:
                    optimized_content = await self.optimization_strategies[dimension](
                        optimized_content,
                        requirements
                    )

            iterations += 1

        return {
            'content': optimized_content,
            'final_score': current_score,
            'iterations': iterations,
            'improved': current_score > scores['total']
        }

    def _identify_weak_dimensions(
        self,
        scores: Dict
    ) -> List[str]:
        """识别需要优化的维度"""
        weak = []
        thresholds = {
            'relevance': 70,
            'completeness': 75,
            'readability': 70,
            'professionalism': 70
        }

        for dimension, threshold in thresholds.items():
            if scores.get(dimension, 0) < threshold:
                weak.append(dimension)

        return weak
```

## 3. API接口实现

```python
# app/api/v1/content.py

from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import Optional
from app.services.content_generation.planner import ContentPlanningEngine
from app.services.content_generation.generator import MultiModelGenerator
from app.schemas.content import (
    GenerateContentRequest,
    GenerateContentResponse,
    GenerationStatus
)

router = APIRouter(prefix="/api/v1/ai", tags=["content"])

# 任务存储（实际应使用Redis）
generation_tasks = {}

@router.post("/generate-content", response_model=GenerateContentResponse)
async def generate_content(
    request: GenerateContentRequest,
    background_tasks: BackgroundTasks
):
    """
    生成标书内容接口

    Args:
        request: 生成请求
        background_tasks: 后台任务

    Returns:
        GenerateContentResponse: 生成响应
    """
    try:
        # 创建任务ID
        task_id = generate_task_id()

        # 初始化任务状态
        generation_tasks[task_id] = {
            'status': GenerationStatus.PROCESSING,
            'progress': 0,
            'created_at': datetime.now()
        }

        # 启动后台生成任务
        background_tasks.add_task(
            generate_content_task,
            task_id,
            request.project_id,
            request.options
        )

        return GenerateContentResponse(
            success=True,
            task_id=task_id,
            status=GenerationStatus.PROCESSING,
            message="内容生成任务已启动"
        )

    except Exception as e:
        logger.error(f"Content generation failed: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"生成失败: {str(e)}"
        )

async def generate_content_task(
    task_id: str,
    project_id: str,
    options: Dict
):
    """后台生成任务"""
    try:
        # 1. 获取项目数据
        project_data = await get_project_data(project_id)

        # 2. 内容规划
        planner = ContentPlanningEngine()
        plan = await planner.plan_content(
            project_data['requirements'],
            project_data['company_profile']
        )

        # 更新进度
        generation_tasks[task_id]['progress'] = 20

        # 3. 内容生成
        generator = MultiModelGenerator()
        generated = await generator.generate_content(
            plan.to_tasks()
        )

        # 更新进度
        generation_tasks[task_id]['progress'] = 80

        # 4. 内容优化
        optimizer = ContentOptimizer()
        optimized = await optimizer.optimize(
            generated,
            project_data['requirements']
        )

        # 5. 保存结果
        await save_generated_content(
            project_id,
            optimized['content']
        )

        # 更新任务状态
        generation_tasks[task_id].update({
            'status': GenerationStatus.COMPLETED,
            'progress': 100,
            'completed_at': datetime.now()
        })

    except Exception as e:
        generation_tasks[task_id].update({
            'status': GenerationStatus.FAILED,
            'error': str(e)
        })
```

## 4. 配置管理

```python
# app/core/config.py

from pydantic import BaseSettings
from typing import Dict, Any

class Settings(BaseSettings):
    """应用配置"""

    # OpenAI配置
    OPENAI_API_KEY: str
    OPENAI_ORG_ID: Optional[str] = None

    # Anthropic配置
    ANTHROPIC_API_KEY: str

    # 模型配置
    MODEL_CONFIG: Dict[str, Any] = {
        "gpt-4": {
            "max_tokens": 8192,
            "default_temperature": 0.7,
            "cost_per_1k": 0.03
        },
        "claude-3-opus": {
            "max_tokens": 100000,
            "default_temperature": 0.7,
            "cost_per_1k": 0.025
        }
    }

    # 生成配置
    MAX_CONCURRENT_GENERATIONS: int = 5
    GENERATION_TIMEOUT: int = 300  # 秒
    CACHE_TTL: int = 3600  # 缓存时间

    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()
```

## 5. 测试代码

```python
# tests/test_content_generation.py

import pytest
from app.services.content_generation.planner import ContentPlanningEngine
from app.services.content_generation.generator import MultiModelGenerator

@pytest.mark.asyncio
async def test_content_planning():
    """测试内容规划"""
    planner = ContentPlanningEngine()

    requirements = {
        "project_type": "engineering",
        "word_count": 50000,
        "keywords": ["智能化", "系统集成"]
    }

    company_profile = {
        "name": "测试公司",
        "capabilities": ["软件开发", "系统集成"]
    }

    plan = await planner.plan_content(requirements, company_profile)

    assert plan is not None
    assert plan.estimated_pages > 0
    assert len(plan.structure) > 0

@pytest.mark.asyncio
async def test_multi_model_generation():
    """测试多模型生成"""
    generator = MultiModelGenerator()

    tasks = [
        GenerationTask(
            section_id="1",
            content_type="technical",
            complexity=0.8,
            max_tokens=2000
        )
    ]

    results = await generator.generate_content(tasks)

    assert len(results) == 1
    assert results[0].get('content') is not None
```

## 6. 部署配置

```yaml
# docker-compose.yml
services:
  fastapi-ai:
    build: ./backend/fastapi-ai-service
    ports:
      - "8001:8001"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
      - postgres
```

---

## 修改历史

| 日期 | 版本 | 修改者 | 修改内容概要 |
|------|------|--------|-------------|
| 2025-11-30 11:25 | 1.0 | claude-opus-4-1-20250805 | 创建实现指南，包含具体Python代码 |