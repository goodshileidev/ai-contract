# Python FastAPI AI æœåŠ¡ä»»åŠ¡è¯¦ç»†è®¡åˆ’ - AI-001

**æ–‡æ¡£ç±»å‹**: å®æ–½æ–‡æ¡£
**éœ€æ±‚ç¼–å·**: REQ-AI-001
**åˆ›å»ºæ—¥æœŸ**: 2025-11-26
**åˆ›å»ºè€…**: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
**æœ€åæ›´æ–°**: 2025-11-27
**æ›´æ–°è€…**: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
**çŠ¶æ€**: å¾…å¼€å§‹

---

## ä¿®æ”¹å†å²

| æ—¥æœŸ | ç‰ˆæœ¬ | ä¿®æ”¹è€… | ä¿®æ”¹å†…å®¹æ¦‚è¦ |
|------|------|--------|-------------|
| 2025-11-27 14:55 | 2.0 | claude-sonnet-4-5 | ä» task-plan-python-ai-è¯¦ç»†.md æ‹†åˆ†å‡º AI-001 æ¨¡å— |
| 2025-11-26 | 1.0 | claude-sonnet-4-5 | åˆ›å»ºPython AIæœåŠ¡è¯¦ç»†ä»»åŠ¡è®¡åˆ’ |

---

## ğŸ“‘ æ–‡æ¡£å¯¼èˆª

**è¿”å›ç´¢å¼•**: [task-plan-python-ai-è¯¦ç»†-INDEX.md](./task-plan-python-ai-è¯¦ç»†-INDEX.md)

**å…¶ä»–æ¨¡å—**: [AI-002](./task-plan-python-ai-è¯¦ç»†-AI-002.md) | [AI-003](./task-plan-python-ai-è¯¦ç»†-AI-003.md) | [AI-004](./task-plan-python-ai-è¯¦ç»†-AI-004.md)

---

# Python FastAPI AI æœåŠ¡ä»»åŠ¡è®¡åˆ’ï¼ˆè¯¦ç»†ç‰ˆï¼‰

**æ–‡æ¡£ç±»å‹**: å®ç°æ–‡æ¡£
**éœ€æ±‚ç¼–å·**: REQ-AI-001 ~ REQ-AI-004
**åˆ›å»ºæ—¥æœŸ**: 2025-11-26
**åˆ›å»ºè€…**: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
**æœ€åæ›´æ–°**: 2025-11-26 11:15
**æ›´æ–°è€…**: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
**çŠ¶æ€**: å¾…å¼€å§‹
**ç‰ˆæœ¬**: v2.0 (ç»†åŒ–ç‰ˆ)

---

## ä¿®æ”¹å†å²

| æ—¥æœŸ | æ—¶é—´ | ç‰ˆæœ¬ | ä¿®æ”¹è€… | ä¿®æ”¹å†…å®¹æ¦‚è¦ |
|------|------|------|--------|-------------|
| 2025-11-26 | 10:00 | 1.0 | claude-sonnet-4-5 | ä»task-plan.mdæ‹†åˆ†å‡ºPython AIæœåŠ¡ä»»åŠ¡ |
| 2025-11-26 | 11:15 | 2.0 | claude-sonnet-4-5 | åº”ç”¨5ç±»åˆ«ç»†åˆ†ï¼ˆæ•°æ®/å‰ç«¯/Java/Python/éƒ¨ç½²ï¼‰ï¼Œç»†åŒ–åˆ°æœ€å°ç²’åº¦ |

---

## æ¨¡å—æ¦‚è¿°

æœ¬æ¨¡å—åŒ…å« Python FastAPI AI æœåŠ¡çš„æ‰€æœ‰ AI èƒ½åŠ›å¼€å‘ä»»åŠ¡ã€‚

**æŠ€æœ¯æ ˆ**:
- Python 3.11+ + FastAPI 0.104+
- LlamaIndex 0.14.8 (ä¸»åŠ›RAGæ¡†æ¶) âœ… å·²å‡çº§
- LangChain 1.1.0 (å¤‡ç”¨æ¡†æ¶) âœ… å·²æ·»åŠ 
- Elasticsearch 9.2.1 (å‘é‡å­˜å‚¨+å…¨æ–‡æ£€ç´¢) âœ… å·²å‡çº§
- OpenAI SDK 1.0+ + Anthropic SDK 0.7+

**æœåŠ¡èŒè´£**:
- æ‹›æ ‡æ–‡ä»¶æ™ºèƒ½è§£æå’Œå‘é‡åŒ–
- æ™ºèƒ½å†…å®¹ç”Ÿæˆå’Œä¼˜åŒ–
- ä¼ä¸šèƒ½åŠ›åº“å‘é‡åŒ–å’Œæ£€ç´¢
- æ™ºèƒ½åŒ¹é…åˆ†æå’Œæ¨è

**æ€»ä½“è¿›åº¦**: 0% (0/4 ä¸»ä»»åŠ¡ï¼Œ0/24 äºŒçº§ä»»åŠ¡å®Œæˆ)

---

## AI-001: æ‹›æ ‡æ–‡ä»¶æ™ºèƒ½è§£ææ¨¡å—

**éœ€æ±‚ç¼–å·**: REQ-AI-001
**è´Ÿè´£äºº**: Python AI å¼€å‘
**ä¼˜å…ˆçº§**: P1 - é«˜ä¼˜å…ˆçº§
**å¼€å§‹æ—¶é—´**: YYYY-MM-DD
**é¢„è®¡å®Œæˆ**: YYYY-MM-DD
**å®é™…å®Œæˆ**: -
**å½“å‰çŠ¶æ€**: â¸ï¸ å¾…å¼€å§‹
**å®Œæˆè¿›åº¦**: 0% (0/6 äºŒçº§ä»»åŠ¡)

---

### äºŒçº§ä»»åŠ¡ 1.1: PDFæ–‡æ¡£è§£æå¼•æ“

**é¢„è®¡å·¥ä½œé‡**: 3 äººå¤©
**å®Œæˆè¿›åº¦**: 0% (0/5 ç±»åˆ«)

#### 1.1.1 æ•°æ®å®šä¹‰

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] å®šä¹‰ `ParsedDocument` æ•°æ®æ¨¡å‹
  ```python
  # app/models/parsed_document.py
  from pydantic import BaseModel
  from typing import List, Dict, Any, Optional
  from datetime import datetime

  class ParsedDocument(BaseModel):
      """è§£æåçš„æ–‡æ¡£æ•°æ®æ¨¡å‹"""
      document_id: str
      file_name: str
      file_type: str  # 'pdf' | 'docx' | 'xlsx'
      file_size: int
      page_count: int
      parsed_content: Dict[str, Any]  # ç»“æ„åŒ–å†…å®¹
      plain_text: str  # çº¯æ–‡æœ¬
      metadata: Dict[str, Any]
      created_at: datetime
  ```

- [ ] å®šä¹‰ `DocumentMetadata` ç»“æ„
  ```python
  class DocumentMetadata(BaseModel):
      """æ–‡æ¡£å…ƒæ•°æ®"""
      title: Optional[str]
      author: Optional[str]
      created_date: Optional[datetime]
      modified_date: Optional[datetime]
      keywords: List[str]
      page_count: int
  ```

- [ ] å®šä¹‰ `ParsedPage` ç»“æ„ï¼ˆPDFé¡µé¢ï¼‰
  ```python
  class ParsedPage(BaseModel):
      """PDFé¡µé¢è§£æç»“æœ"""
      page_number: int
      text_content: str
      images: List[str]  # Base64 encoded images
      tables: List[Dict[str, Any]]
      bounding_boxes: List[Dict[str, float]]
  ```

- [ ] è®¾è®¡ PostgreSQL å­˜å‚¨è¡¨ç»“æ„
  ```sql
  -- JavaæœåŠ¡è´Ÿè´£åˆ›å»ºè¡¨
  -- PythonæœåŠ¡é€šè¿‡REST APIå†™å…¥æ•°æ®
  CREATE TABLE bidding_documents (
      id UUID PRIMARY KEY,
      project_id UUID NOT NULL,
      file_name VARCHAR(255) NOT NULL,
      file_path TEXT NOT NULL,
      file_size BIGINT NOT NULL,
      file_type VARCHAR(50) NOT NULL,
      parsed_status VARCHAR(20) DEFAULT 'pending',
      parsed_content JSONB,  -- å­˜å‚¨ParsedDocument JSON
      parsed_at TIMESTAMP WITH TIME ZONE,
      parse_error TEXT,
      FOREIGN KEY (project_id) REFERENCES projects(id)
  );
  ```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ‰€æœ‰æ•°æ®æ¨¡å‹é€šè¿‡ Pydantic éªŒè¯
- [ ] æ•°æ®æ¨¡å‹æ”¯æŒ JSON åºåˆ—åŒ–/ååºåˆ—åŒ–
- [ ] è¡¨ç»“æ„è®¾è®¡æ–‡æ¡£å·²æ›´æ–°

---

#### 1.1.2 å‰ç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] åˆ›å»ºæ–‡ä»¶ä¸Šä¼ ç»„ä»¶
  ```typescript
  // apps/frontend/src/components/upload/DocumentUpload.tsx
  import { ProFormUploadButton } from '@ant-design/pro-form';
  import { message } from 'antd';

  export function DocumentUpload({ projectId, onSuccess }: Props) {
      return (
          <ProFormUploadButton
              name="file"
              label="ä¸Šä¼ æ‹›æ ‡æ–‡ä»¶"
              max={1}
              fieldProps={{
                  accept: '.pdf,.docx,.xlsx',
                  customRequest: async ({ file, onSuccess, onError }) => {
                      try {
                          const formData = new FormData();
                          formData.append('file', file);
                          formData.append('project_id', projectId);

                          const response = await fetch('http://localhost:8001/api/v1/ai/parse-document', {
                              method: 'POST',
                              body: formData,
                          });

                          if (response.ok) {
                              onSuccess(await response.json());
                              message.success('æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨è§£æ...');
                          }
                      } catch (error) {
                          onError(error);
                          message.error('ä¸Šä¼ å¤±è´¥');
                      }
                  }
              }}
              extra="æ”¯æŒ PDFã€Wordã€Excel æ ¼å¼ï¼Œæœ€å¤§ 50MB"
          />
      );
  }
  ```

- [ ] åˆ›å»ºè§£æè¿›åº¦æ˜¾ç¤ºç»„ä»¶
  ```typescript
  // apps/frontend/src/components/parsing/ParsingProgress.tsx
  import { Progress, Card, Spin } from 'antd';

  export function ParsingProgress({ taskId }: { taskId: string }) {
      const { data, isLoading } = useQuery({
          queryKey: ['parsing-progress', taskId],
          queryFn: () => fetch(`http://localhost:8001/api/v1/ai/tasks/${taskId}`).then(r => r.json()),
          refetchInterval: 1000,  // æ¯ç§’è½®è¯¢
      });

      return (
          <Card title="æ–‡æ¡£è§£æä¸­...">
              <Progress percent={data?.progress || 0} status="active" />
              <p>{data?.status_message}</p>
          </Card>
      );
  }
  ```

- [ ] åˆ›å»ºè§£æç»“æœå±•ç¤ºé¡µé¢
  ```typescript
  // apps/frontend/src/pages/documents/ParsingResult.tsx
  import { ProDescriptions } from '@ant-design/pro-descriptions';

  export default function ParsingResult({ documentId }: Props) {
      // å±•ç¤ºè§£æåçš„ç»“æ„åŒ–å†…å®¹
      // - é¡¹ç›®åŸºæœ¬ä¿¡æ¯
      // - æŠ€æœ¯è¦æ±‚
      // - å•†åŠ¡æ¡æ¬¾
      // - è¯„åˆ†æ ‡å‡†
  }
  ```

- [ ] é›†æˆåˆ°é¡¹ç›®è¯¦æƒ…é¡µ
  ```typescript
  // apps/frontend/src/pages/projects/ProjectDetail.tsx
  // æ·»åŠ "ä¸Šä¼ æ‹›æ ‡æ–‡ä»¶"æŒ‰é’®
  // æ˜¾ç¤ºå·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
  // æ”¯æŒæŸ¥çœ‹è§£æç»“æœ
  ```

**éªŒæ”¶æ ‡å‡†**:
- [ ] ä¸Šä¼ ç»„ä»¶æ”¯æŒæ‹–æ‹½ä¸Šä¼ 
- [ ] å®æ—¶æ˜¾ç¤ºä¸Šä¼ è¿›åº¦
- [ ] è§£æè¿›åº¦å®æ—¶æ›´æ–°
- [ ] è§£æç»“æœæ­£ç¡®å±•ç¤º

---

#### 1.1.3 Javaåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] åˆ›å»º `BiddingDocument` å®ä½“ï¼ˆå·²å­˜åœ¨ï¼Œéœ€éªŒè¯å­—æ®µå®Œæ•´æ€§ï¼‰
  ```java
  // apps/backend-java/ac-dao-postgres/src/main/java/com/aibidcomposer/dao/entity/BiddingDocument.java
  @Data
  @TableName(value = "bidding_documents", autoResultMap = true)
  public class BiddingDocument extends BaseEntity {
      @TableField("project_id")
      private String projectId;

      @TableField("file_name")
      private String fileName;

      @TableField("file_path")
      private String filePath;

      @TableField("file_size")
      private Long fileSize;

      @TableField("file_type")
      private String fileType;

      @TableField("parsed_status")
      private String parsedStatus;  // 'pending'|'processing'|'success'|'failed'

      @TableField(value = "parsed_content", typeHandler = JacksonTypeHandler.class)
      private Map<String, Object> parsedContent;

      @TableField("parsed_at")
      private LocalDateTime parsedAt;

      @TableField("parse_error")
      private String parseError;
  }
  ```

- [ ] åˆ›å»º `BiddingDocumentService` ä¸šåŠ¡é€»è¾‘
  ```java
  // apps/backend-java/ac-service/src/main/java/com/aibidcomposer/service/BiddingDocumentService.java
  @Service
  @RequiredArgsConstructor
  public class BiddingDocumentService {

      /**
       * åˆ›å»ºæ‹›æ ‡æ–‡ä»¶è®°å½•ï¼ˆæ–‡ä»¶ä¸Šä¼ æ—¶è°ƒç”¨ï¼‰
       * éœ€æ±‚ç¼–å·: REQ-AI-001
       */
      public BiddingDocument createRecord(String projectId, String fileName,
                                          String filePath, Long fileSize, String fileType) {
          BiddingDocument doc = new BiddingDocument();
          doc.setProjectId(projectId);
          doc.setFileName(fileName);
          doc.setFilePath(filePath);
          doc.setFileSize(fileSize);
          doc.setFileType(fileType);
          doc.setParsedStatus("pending");

          biddingDocumentMapper.insert(doc);

          // å‘é€RabbitMQæ¶ˆæ¯é€šçŸ¥PythonæœåŠ¡å¼€å§‹è§£æ
          rabbitTemplate.convertAndSend("ai.parse.queue", doc.getId());

          return doc;
      }

      /**
       * æ›´æ–°è§£æçŠ¶æ€ï¼ˆPythonæœåŠ¡å›è°ƒï¼‰
       * éœ€æ±‚ç¼–å·: REQ-AI-001
       */
      public void updateParseStatus(String docId, String status,
                                    Map<String, Object> content, String error) {
          BiddingDocument doc = biddingDocumentMapper.selectById(docId);
          doc.setParsedStatus(status);
          doc.setParsedContent(content);
          doc.setParsedAt(LocalDateTime.now());
          doc.setParseError(error);

          biddingDocumentMapper.updateById(doc);
      }
  }
  ```

- [ ] åˆ›å»º `BiddingDocumentController` REST API
  ```java
  // apps/backend-java/ac-web-api/src/main/java/com/aibidcomposer/web/controller/BiddingDocumentController.java
  @RestController
  @RequestMapping("/api/v1/bidding-documents")
  @RequiredArgsConstructor
  public class BiddingDocumentController {

      private final BiddingDocumentService biddingDocumentService;

      /**
       * è·å–æ‹›æ ‡æ–‡ä»¶åˆ—è¡¨
       * éœ€æ±‚ç¼–å·: REQ-AI-001
       */
      @GetMapping
      public Result<Page<BiddingDocument>> list(@RequestParam String projectId,
                                                  @RequestParam(defaultValue = "1") int page,
                                                  @RequestParam(defaultValue = "20") int pageSize) {
          Page<BiddingDocument> result = biddingDocumentService.listByProject(projectId, page, pageSize);
          return Result.success(result);
      }

      /**
       * è·å–è§£æç»“æœ
       * éœ€æ±‚ç¼–å·: REQ-AI-001
       */
      @GetMapping("/{id}")
      public Result<BiddingDocument> get(@PathVariable String id) {
          BiddingDocument doc = biddingDocumentService.getById(id);
          return Result.success(doc);
      }
  }
  ```

- [ ] é…ç½® RabbitMQ æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆJava â†’ Pythoné€šä¿¡ï¼‰
  ```java
  // apps/backend-java/ac-service/src/main/java/com/aibidcomposer/config/RabbitMQConfig.java
  @Configuration
  public class RabbitMQConfig {

      @Bean
      public Queue aiParseQueue() {
          return new Queue("ai.parse.queue", true);  // durable=true
      }

      @Bean
      public Queue aiParseResultQueue() {
          return new Queue("ai.parse.result.queue", true);
      }
  }
  ```

**éªŒæ”¶æ ‡å‡†**:
- [ ] BiddingDocumentå®ä½“æ˜ å°„æ­£ç¡®
- [ ] JavaæœåŠ¡å¯ä»¥åˆ›å»ºè§£æè®°å½•
- [ ] JavaæœåŠ¡å¯ä»¥æŸ¥è¯¢è§£æç»“æœ
- [ ] RabbitMQæ¶ˆæ¯å‘é€æˆåŠŸ

---

#### 1.1.4 Pythonåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] åˆ›å»º FastAPI æ–‡ä»¶ä¸Šä¼ ç«¯ç‚¹
  ```python
  # apps/backend-python/app/api/v1/document_parser.py
  from fastapi import APIRouter, UploadFile, File, Form, HTTPException
  from app.services.ai.document_parser import DocumentParserService
  from app.models.parsed_document import ParsedDocument

  router = APIRouter(prefix="/api/v1/ai", tags=["Document Parser"])

  @router.post("/parse-document")
  async def parse_document(
      file: UploadFile = File(...),
      project_id: str = Form(...)
  ):
      """
      è§£ææ‹›æ ‡æ–‡ä»¶
      éœ€æ±‚ç¼–å·: REQ-AI-001
      """
      # 1. éªŒè¯æ–‡ä»¶ç±»å‹å’Œå¤§å°
      if file.content_type not in ['application/pdf', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document']:
          raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")

      if file.size > 50 * 1024 * 1024:  # 50MB
          raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶")

      # 2. ä¿å­˜æ–‡ä»¶åˆ°MinIOï¼ˆé€šè¿‡JavaæœåŠ¡APIï¼‰
      file_path = await save_to_storage(file, project_id)

      # 3. åˆ›å»ºè§£æä»»åŠ¡è®°å½•ï¼ˆè°ƒç”¨JavaæœåŠ¡APIï¼‰
      doc_record = await create_document_record(project_id, file.filename, file_path, file.size)

      # 4. å¼‚æ­¥è§£æï¼ˆå‘é€åˆ°Celeryä»»åŠ¡é˜Ÿåˆ—ï¼‰
      from app.tasks.document_parsing import parse_pdf_task
      task = parse_pdf_task.delay(doc_record['id'], file_path)

      return {
          "task_id": task.id,
          "document_id": doc_record['id'],
          "status": "processing",
          "message": "æ–‡æ¡£è§£æä»»åŠ¡å·²æäº¤"
      }
  ```

- [ ] å®ç° PDF è§£ææœåŠ¡
  ```python
  # apps/backend-python/app/services/ai/document_parser.py
  import pdfplumber
  from typing import Dict, Any, List

  class DocumentParserService:
      """æ–‡æ¡£è§£ææœåŠ¡"""

      async def parse_pdf(self, file_path: str) -> ParsedDocument:
          """
          è§£æPDFæ–‡æ¡£
          éœ€æ±‚ç¼–å·: REQ-AI-001
          """
          pages = []

          with pdfplumber.open(file_path) as pdf:
              for i, page in enumerate(pdf.pages):
                  # æå–æ–‡æœ¬
                  text = page.extract_text()

                  # æå–è¡¨æ ¼
                  tables = page.extract_tables()

                  # æå–å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
                  # images = page.images

                  pages.append({
                      "page_number": i + 1,
                      "text_content": text,
                      "tables": tables,
                  })

          # åˆå¹¶æ‰€æœ‰é¡µé¢æ–‡æœ¬
          plain_text = "\n\n".join([p["text_content"] for p in pages])

          return ParsedDocument(
              document_id=...,
              file_name=...,
              file_type="pdf",
              page_count=len(pages),
              parsed_content={"pages": pages},
              plain_text=plain_text,
              metadata={}
          )
  ```

- [ ] å®ç° Celery å¼‚æ­¥ä»»åŠ¡
  ```python
  # apps/backend-python/app/tasks/document_parsing.py
  from celery import Task
  from app.tasks.celery_app import celery_app
  from app.services.ai.document_parser import DocumentParserService

  @celery_app.task(bind=True, max_retries=3)
  def parse_pdf_task(self: Task, document_id: str, file_path: str):
      """
      å¼‚æ­¥è§£æPDFä»»åŠ¡
      éœ€æ±‚ç¼–å·: REQ-AI-001
      """
      try:
          # 1. æ›´æ–°JavaæœåŠ¡ï¼šçŠ¶æ€=processing
          await update_java_status(document_id, "processing")

          # 2. è§£æPDF
          parser = DocumentParserService()
          parsed_doc = await parser.parse_pdf(file_path)

          # 3. æ›´æ–°JavaæœåŠ¡ï¼šçŠ¶æ€=successï¼Œå†…å®¹=parsed_doc
          await update_java_status(
              document_id,
              "success",
              content=parsed_doc.dict()
          )

          return {"status": "success", "document_id": document_id}

      except Exception as e:
          # å¤±è´¥ï¼šæ›´æ–°JavaæœåŠ¡çŠ¶æ€=failed
          await update_java_status(document_id, "failed", error=str(e))

          # é‡è¯•
          if self.request.retries < self.max_retries:
              raise self.retry(exc=e, countdown=60 * (self.request.retries + 1))

          raise
  ```

- [ ] å®ç°ä¸JavaæœåŠ¡é€šä¿¡
  ```python
  # apps/backend-python/app/services/java_api_client.py
  import httpx
  from typing import Dict, Any

  class JavaAPIClient:
      """JavaæœåŠ¡APIå®¢æˆ·ç«¯"""

      def __init__(self):
          self.base_url = "http://backend-java:8080"
          self.client = httpx.AsyncClient()

      async def update_document_status(
          self,
          document_id: str,
          status: str,
          content: Dict[str, Any] = None,
          error: str = None
      ):
          """
          æ›´æ–°JavaæœåŠ¡ä¸­çš„æ–‡æ¡£è§£æçŠ¶æ€
          éœ€æ±‚ç¼–å·: REQ-AI-001
          """
          response = await self.client.put(
              f"{self.base_url}/api/v1/bidding-documents/{document_id}/parse-status",
              json={
                  "status": status,
                  "content": content,
                  "error": error
              }
          )
          response.raise_for_status()
          return response.json()
  ```

**éªŒæ”¶æ ‡å‡†**:
- [ ] POST /api/v1/ai/parse-document æ¥å£æ­£å¸¸
- [ ] PDFè§£ææå–æ–‡æœ¬æ­£ç¡®
- [ ] PDFè§£ææå–è¡¨æ ¼æ­£ç¡®
- [ ] Celeryå¼‚æ­¥ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ
- [ ] è§£æç»“æœæ­£ç¡®å†™å›JavaæœåŠ¡

---

#### 1.1.5 éƒ¨ç½²é…ç½®

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] æ›´æ–° Python æœåŠ¡ Dockerfile
  ```dockerfile
  # apps/backend-python/Dockerfile
  FROM python:3.11-slim

  # å®‰è£…ç³»ç»Ÿä¾èµ–ï¼ˆPDFè§£æéœ€è¦ï¼‰
  RUN apt-get update && apt-get install -y \
      libpoppler-cpp-dev \
      poppler-utils \
      tesseract-ocr \
      tesseract-ocr-chi-sim \
      && rm -rf /var/lib/apt/lists/*

  WORKDIR /app

  # å¤åˆ¶ä¾èµ–æ–‡ä»¶
  COPY pyproject.toml ./
  RUN pip install --no-cache-dir -e .

  # å¤åˆ¶åº”ç”¨ä»£ç 
  COPY app /app/app

  EXPOSE 8001

  CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8001"]
  ```

- [ ] æ·»åŠ ç¯å¢ƒå˜é‡
  ```bash
  # .env
  # Python AIæœåŠ¡é…ç½®
  PYTHON_AI_SERVICE_URL=http://backend-python:8001
  MAX_UPLOAD_SIZE=52428800  # 50MB

  # Celeryé…ç½®
  CELERY_BROKER_URL=amqp://rabbitmq:rabbitmq@rabbitmq:5672/
  CELERY_RESULT_BACKEND=redis://:redis-password@redis:6379/1

  # JavaæœåŠ¡è¿æ¥
  JAVA_SERVICE_URL=http://backend-java:8080
  JAVA_SERVICE_API_KEY=secret_key_here
  ```

- [ ] é…ç½® docker-compose.yml
  ```yaml
  # docker-compose.yml
  services:
    backend-python:
      build:
        context: ./apps/backend-python
        dockerfile: Dockerfile
      ports:
        - "8001:8001"
      environment:
        - CELERY_BROKER_URL=${CELERY_BROKER_URL}
        - JAVA_SERVICE_URL=${JAVA_SERVICE_URL}
      depends_on:
        - rabbitmq
        - redis
        - backend-java
      volumes:
        - ./apps/backend-python/app:/app/app  # å¼€å‘æ¨¡å¼çƒ­é‡è½½

    ai-worker:
      build:
        context: ./apps/backend-python
        dockerfile: Dockerfile
      command: celery -A app.tasks.celery_app worker --loglevel=info -Q pdf_parsing
      depends_on:
        - rabbitmq
        - redis
  ```

- [ ] é…ç½®å¥åº·æ£€æŸ¥
  ```python
  # apps/backend-python/app/main.py
  @app.get("/health")
  async def health_check():
      """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
      return {
          "status": "healthy",
          "service": "python-ai-service",
          "version": "1.0.0"
      }
  ```

**éªŒæ”¶æ ‡å‡†**:
- [ ] Dockeré•œåƒæ„å»ºæˆåŠŸ
- [ ] æœåŠ¡å¯åŠ¨æ­£å¸¸
- [ ] å¥åº·æ£€æŸ¥ç«¯ç‚¹è¿”å›200
- [ ] Celery Workerè¿æ¥æˆåŠŸ

---

### äºŒçº§ä»»åŠ¡ 1.2: Wordæ–‡æ¡£è§£æå¼•æ“

**é¢„è®¡å·¥ä½œé‡**: 2 äººå¤©
**å®Œæˆè¿›åº¦**: 0% (0/5 ç±»åˆ«)

#### 1.2.1 æ•°æ®å®šä¹‰

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] æ‰©å±• `ParsedDocument` æ”¯æŒWordæ ¼å¼
- [ ] å®šä¹‰ `WordSection` æ•°æ®ç»“æ„
  ```python
  class WordSection(BaseModel):
      """Wordæ–‡æ¡£ç« èŠ‚"""
      level: int  # æ ‡é¢˜çº§åˆ« 1-9
      title: str
      content: str
      style: str  # æ ·å¼åç§°
  ```

#### 1.2.2 å‰ç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] æ–‡ä»¶ä¸Šä¼ ç»„ä»¶æ”¯æŒ .docx æ ¼å¼
- [ ] è§£æç»“æœå±•ç¤ºæ”¯æŒWordæ–‡æ¡£ç»“æ„
- [ ] æ”¯æŒç« èŠ‚æ ‘å½¢å¯¼èˆª

#### 1.2.3 Javaåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] éªŒè¯ BiddingDocument å®ä½“æ”¯æŒWordæ–‡æ¡£
- [ ] æ·»åŠ Wordæ–‡æ¡£ç‰¹å®šå­—æ®µï¼ˆå¦‚ç« èŠ‚æ•°é‡ï¼‰

#### 1.2.4 Pythonåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] å®ç° Word è§£ææœåŠ¡
  ```python
  # apps/backend-python/app/services/ai/word_parser.py
  from docx import Document

  class WordParserService:
      async def parse_word(self, file_path: str) -> ParsedDocument:
          """
          è§£æWordæ–‡æ¡£
          éœ€æ±‚ç¼–å·: REQ-AI-001
          """
          doc = Document(file_path)

          sections = []
          for para in doc.paragraphs:
              if para.style.name.startswith('Heading'):
                  level = int(para.style.name.split()[-1])
                  sections.append({
                      "level": level,
                      "title": para.text,
                      "style": para.style.name
                  })
              else:
                  # æ™®é€šæ®µè½å†…å®¹
                  pass

          return ParsedDocument(...)
  ```

- [ ] åˆ›å»º Celery ä»»åŠ¡
  ```python
  @celery_app.task
  def parse_word_task(document_id: str, file_path: str):
      parser = WordParserService()
      result = await parser.parse_word(file_path)
      # ...
  ```

#### 1.2.5 éƒ¨ç½²é…ç½®

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] ç¡®ä¿ python-docx å·²å®‰è£…ï¼ˆå·²åœ¨ pyproject.tomlï¼‰
- [ ] æ— éœ€é¢å¤–ç³»ç»Ÿä¾èµ–

---

### äºŒçº§ä»»åŠ¡ 1.3: Excelè¡¨æ ¼è§£æå¼•æ“

**é¢„è®¡å·¥ä½œé‡**: 2 äººå¤©
**å®Œæˆè¿›åº¦**: 0% (0/5 ç±»åˆ«)

#### 1.3.1 æ•°æ®å®šä¹‰

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] å®šä¹‰ `ExcelSheet` æ•°æ®ç»“æ„
  ```python
  class ExcelSheet(BaseModel):
      """Excelå·¥ä½œè¡¨"""
      sheet_name: str
      rows: List[List[Any]]  # äºŒç»´æ•°ç»„
      header: List[str]
      total_rows: int
      total_columns: int
  ```

#### 1.3.2 å‰ç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] æ–‡ä»¶ä¸Šä¼ ç»„ä»¶æ”¯æŒ .xlsx æ ¼å¼
- [ ] Excelè¡¨æ ¼é¢„è§ˆç»„ä»¶ï¼ˆProTableï¼‰
- [ ] å¤šå·¥ä½œè¡¨åˆ‡æ¢å±•ç¤º

#### 1.3.3 Javaåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] BiddingDocument å®ä½“æ”¯æŒExcelæ–‡æ¡£

#### 1.3.4 Pythonåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] å®ç° Excel è§£ææœåŠ¡
  ```python
  # apps/backend-python/app/services/ai/excel_parser.py
  import openpyxl

  class ExcelParserService:
      async def parse_excel(self, file_path: str) -> ParsedDocument:
          """
          è§£æExcelæ–‡æ¡£
          éœ€æ±‚ç¼–å·: REQ-AI-001
          """
          wb = openpyxl.load_workbook(file_path)

          sheets = []
          for sheet in wb.worksheets:
              rows = []
              for row in sheet.iter_rows(values_only=True):
                  rows.append(list(row))

              sheets.append({
                  "sheet_name": sheet.title,
                  "rows": rows,
                  "total_rows": sheet.max_row,
                  "total_columns": sheet.max_column
              })

          return ParsedDocument(...)
  ```

#### 1.3.5 éƒ¨ç½²é…ç½®

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] ç¡®ä¿ openpyxl å·²å®‰è£…ï¼ˆå·²åœ¨ pyproject.tomlï¼‰

---

### äºŒçº§ä»»åŠ¡ 1.4: åŸºäºLlamaIndexçš„å…³é”®ä¿¡æ¯æå–

**é¢„è®¡å·¥ä½œé‡**: 5 äººå¤©
**å®Œæˆè¿›åº¦**: 0% (0/5 ç±»åˆ«)

#### 1.4.1 æ•°æ®å®šä¹‰

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] å®šä¹‰ `ExtractedInfo` æ•°æ®ç»“æ„
  ```python
  class ProjectBasicInfo(BaseModel):
      """é¡¹ç›®åŸºæœ¬ä¿¡æ¯"""
      project_name: str
      client_name: str
      budget: Optional[float]
      deadline: Optional[datetime]
      location: Optional[str]

  class TechnicalRequirement(BaseModel):
      """æŠ€æœ¯è¦æ±‚"""
      requirement_id: str
      category: str  # 'technical'|'business'|'compliance'
      title: str
      description: str
      is_mandatory: bool
      priority: str  # 'high'|'medium'|'low'

  class ExtractedInfo(BaseModel):
      """æå–çš„å…³é”®ä¿¡æ¯"""
      basic_info: ProjectBasicInfo
      technical_requirements: List[TechnicalRequirement]
      business_terms: List[Dict[str, Any]]
      scoring_criteria: List[Dict[str, Any]]
  ```

- [ ] è®¾è®¡ `project_requirements` è¡¨ï¼ˆJavaæœåŠ¡è´Ÿè´£ï¼‰
  ```sql
  CREATE TABLE project_requirements (
      id UUID PRIMARY KEY,
      project_id UUID NOT NULL,
      requirement_type VARCHAR(50),  -- 'technical'|'business'|'compliance'
      category VARCHAR(100),
      title VARCHAR(200) NOT NULL,
      description TEXT,
      priority VARCHAR(20),
      is_mandatory BOOLEAN DEFAULT TRUE,
      match_status VARCHAR(20),  -- 'pending'|'matched'|'unmatched'
      match_score DECIMAL(5, 2),
      FOREIGN KEY (project_id) REFERENCES projects(id)
  );
  ```

#### 1.4.2 å‰ç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] åˆ›å»ºä¿¡æ¯æå–ç»“æœå±•ç¤ºé¡µé¢
  ```typescript
  // apps/frontend/src/pages/documents/ExtractedInfo.tsx
  import { ProDescriptions } from '@ant-design/pro-descriptions';
  import { ProList } from '@ant-design/pro-list';

  export default function ExtractedInfo({ documentId }: Props) {
      // å±•ç¤ºé¡¹ç›®åŸºæœ¬ä¿¡æ¯ï¼ˆProDescriptionsï¼‰
      // å±•ç¤ºæŠ€æœ¯è¦æ±‚åˆ—è¡¨ï¼ˆProListï¼‰
      // å±•ç¤ºå•†åŠ¡æ¡æ¬¾åˆ—è¡¨
      // å±•ç¤ºè¯„åˆ†æ ‡å‡†
  }
  ```

- [ ] åˆ›å»ºéœ€æ±‚åŒ¹é…çŠ¶æ€å±•ç¤º
  ```typescript
  // æ˜¾ç¤ºæ¯ä¸ªéœ€æ±‚çš„åŒ¹é…çŠ¶æ€ï¼ˆmatched/unmatchedï¼‰
  // æ˜¾ç¤ºåŒ¹é…åˆ†æ•°
  // æ”¯æŒæ‰‹åŠ¨è°ƒæ•´åŒ¹é…ç»“æœ
  ```

#### 1.4.3 Javaåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] åˆ›å»º `ProjectRequirement` å®ä½“
  ```java
  @Data
  @TableName("project_requirements")
  public class ProjectRequirement extends BaseEntity {
      @TableField("project_id")
      private String projectId;

      @TableField("requirement_type")
      private String requirementType;

      @TableField("title")
      private String title;

      @TableField("description")
      private String description;

      @TableField("is_mandatory")
      private Boolean isMandatory;

      @TableField("priority")
      private String priority;

      @TableField("match_status")
      private String matchStatus;

      @TableField("match_score")
      private BigDecimal matchScore;
  }
  ```

- [ ] åˆ›å»º `ProjectRequirementService`
  ```java
  @Service
  public class ProjectRequirementService {

      /**
       * æ‰¹é‡ä¿å­˜æå–çš„éœ€æ±‚ï¼ˆPythonæœåŠ¡å›è°ƒï¼‰
       * éœ€æ±‚ç¼–å·: REQ-AI-001
       */
      @Transactional
      public void batchSave(String projectId, List<RequirementDTO> requirements) {
          for (RequirementDTO req : requirements) {
              ProjectRequirement entity = new ProjectRequirement();
              entity.setProjectId(projectId);
              entity.setRequirementType(req.getCategory());
              entity.setTitle(req.getTitle());
              entity.setDescription(req.getDescription());
              entity.setIsMandatory(req.getIsMandatory());
              entity.setPriority(req.getPriority());
              entity.setMatchStatus("pending");

              projectRequirementMapper.insert(entity);
          }
      }
  }
  ```

- [ ] åˆ›å»º REST API
  ```java
  @RestController
  @RequestMapping("/api/v1/requirements")
  public class RequirementController {

      @GetMapping
      public Result<Page<ProjectRequirement>> list(@RequestParam String projectId) {
          // æŸ¥è¯¢é¡¹ç›®éœ€æ±‚åˆ—è¡¨
      }

      @PostMapping("/batch")
      public Result<Void> batchCreate(@RequestBody BatchRequirementRequest request) {
          // PythonæœåŠ¡å›è°ƒï¼šæ‰¹é‡åˆ›å»ºéœ€æ±‚
          requirementService.batchSave(request.getProjectId(), request.getRequirements());
          return Result.success();
      }
  }
  ```

#### 1.4.4 Pythonåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] é›†æˆ LlamaIndex 0.14.8
  ```python
  # apps/backend-python/app/services/ai/llama_index_service.py
  from llama_index import VectorStoreIndex, ServiceContext, Document
  from llama_index.llms import OpenAI
  from llama_index.embeddings import OpenAIEmbedding

  class LlamaIndexService:
      """LlamaIndex RAGæœåŠ¡"""

      def __init__(self):
          self.llm = OpenAI(model="gpt-4-turbo-preview", api_key=settings.OPENAI_API_KEY)
          self.embed_model = OpenAIEmbedding(api_key=settings.OPENAI_API_KEY)

      async def extract_info(self, document_text: str) -> ExtractedInfo:
          """
          ä½¿ç”¨LlamaIndexæå–å…³é”®ä¿¡æ¯
          éœ€æ±‚ç¼–å·: REQ-AI-001
          """
          # 1. åˆ›å»ºæ–‡æ¡£ç´¢å¼•
          documents = [Document(text=document_text)]
          service_context = ServiceContext.from_defaults(
              llm=self.llm,
              embed_model=self.embed_model
          )
          index = VectorStoreIndex.from_documents(
              documents,
              service_context=service_context
          )

          # 2. æŸ¥è¯¢é¡¹ç›®åŸºæœ¬ä¿¡æ¯
          query_engine = index.as_query_engine()
          basic_info_response = await query_engine.aquery(
              "è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼šé¡¹ç›®åç§°ã€æ‹›æ ‡å•ä½ã€é¡¹ç›®é¢„ç®—ã€æäº¤æˆªæ­¢æ—¶é—´ã€é¡¹ç›®åœ°ç‚¹"
          )

          # 3. æŸ¥è¯¢æŠ€æœ¯è¦æ±‚
          tech_req_response = await query_engine.aquery(
              "è¯·æå–æ‰€æœ‰æŠ€æœ¯è¦æ±‚ï¼ŒåŒ…æ‹¬ï¼šè¦æ±‚æ ‡é¢˜ã€è¯¦ç»†æè¿°ã€æ˜¯å¦å¼ºåˆ¶ã€ä¼˜å…ˆçº§"
          )

          # 4. è§£æLLMå“åº”ï¼Œæ„å»ºç»“æ„åŒ–æ•°æ®
          # TODO: ä½¿ç”¨GPT-4è¾“å‡ºJSONæ ¼å¼ï¼Œç›´æ¥è§£æ

          return ExtractedInfo(
              basic_info=ProjectBasicInfo(...),
              technical_requirements=[...],
              business_terms=[...],
              scoring_criteria=[...]
          )
  ```

- [ ] åˆ›å»ºä¿¡æ¯æå–API
  ```python
  # apps/backend-python/app/api/v1/information_extraction.py
  @router.post("/extract-requirements")
  async def extract_requirements(document_id: str):
      """
      æå–æ‹›æ ‡æ–‡ä»¶çš„å…³é”®ä¿¡æ¯
      éœ€æ±‚ç¼–å·: REQ-AI-001
      """
      # 1. ä»JavaæœåŠ¡è·å–æ–‡æ¡£å†…å®¹
      doc = await java_client.get_document(document_id)

      # 2. ä½¿ç”¨LlamaIndexæå–ä¿¡æ¯
      llama_service = LlamaIndexService()
      extracted = await llama_service.extract_info(doc['plain_text'])

      # 3. å›è°ƒJavaæœåŠ¡ï¼Œä¿å­˜æå–ç»“æœ
      await java_client.save_requirements(
          doc['project_id'],
          extracted.technical_requirements
      )

      return extracted
  ```

- [ ] å®ç°Celeryå¼‚æ­¥ä»»åŠ¡
  ```python
  @celery_app.task
  def extract_info_task(document_id: str):
      """å¼‚æ­¥æå–ä¿¡æ¯ä»»åŠ¡"""
      # è°ƒç”¨extract_requirementsé€»è¾‘
      pass
  ```

#### 1.4.5 éƒ¨ç½²é…ç½®

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] ç¡®ä¿ LlamaIndex 0.14.8 å·²å®‰è£… âœ…
- [ ] é…ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡
- [ ] é…ç½® Celery é˜Ÿåˆ—ï¼š`ai_extraction`

---

### äºŒçº§ä»»åŠ¡ 1.5: å‘é‡åŒ–å’ŒElasticsearchå­˜å‚¨

**é¢„è®¡å·¥ä½œé‡**: 4 äººå¤©
**å®Œæˆè¿›åº¦**: 0% (0/5 ç±»åˆ«)

#### 1.5.1 æ•°æ®å®šä¹‰

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] è®¾è®¡ Elasticsearch ç´¢å¼•ç»“æ„
  ```json
  {
    "mappings": {
      "properties": {
        "document_id": { "type": "keyword" },
        "project_id": { "type": "keyword" },
        "content": { "type": "text", "analyzer": "ik_max_word" },
        "embedding": {
          "type": "dense_vector",
          "dims": 1536,
          "index": true,
          "similarity": "cosine"
        },
        "metadata": { "type": "object" },
        "created_at": { "type": "date" }
      }
    }
  }
  ```

#### 1.5.2 å‰ç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] åˆ›å»ºè¯­ä¹‰æœç´¢ç•Œé¢
  ```typescript
  // apps/frontend/src/components/search/SemanticSearch.tsx
  import { ProFormText } from '@ant-design/pro-form';

  export function SemanticSearch() {
      const [results, setResults] = useState([]);

      const handleSearch = async (query: string) => {
          const response = await fetch('http://localhost:8001/api/v1/ai/semantic-search', {
              method: 'POST',
              body: JSON.stringify({ query, top_k: 10 })
          });
          setResults(await response.json());
      };

      return (
          <div>
              <ProFormText
                  name="query"
                  placeholder="è¾“å…¥æœç´¢å…³é”®è¯..."
                  fieldProps={{
                      onPressEnter: (e) => handleSearch(e.target.value)
                  }}
              />
              <SearchResults results={results} />
          </div>
      );
  }
  ```

#### 1.5.3 Javaåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] æ— éœ€Javaåç«¯æ”¯æŒï¼ˆçº¯Pythonå®ç°ï¼‰

#### 1.5.4 Pythonåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] å®ç° Elasticsearch å‘é‡å­˜å‚¨æœåŠ¡
  ```python
  # apps/backend-python/app/services/ai/elasticsearch_store.py
  from elasticsearch import AsyncElasticsearch
  from llama_index.vector_stores import ElasticsearchStore
  from app.services.ai.embedding_service import EmbeddingService

  class ElasticsearchVectorStore:
      """Elasticsearchå‘é‡å­˜å‚¨ï¼ˆä¸»åŠ›æ–¹æ¡ˆï¼‰"""

      def __init__(self):
          self.es_client = AsyncElasticsearch(
              hosts=[settings.ELASTICSEARCH_URL],
              basic_auth=(settings.ELASTICSEARCH_USER, settings.ELASTICSEARCH_PASSWORD)
          )
          self.index_name = "aibidcomposer-vectors"

      async def initialize_index(self):
          """åˆå§‹åŒ–ç´¢å¼•"""
          if not await self.es_client.indices.exists(index=self.index_name):
              await self.es_client.indices.create(
                  index=self.index_name,
                  body={
                      "mappings": {
                          "properties": {
                              "content": {"type": "text"},
                              "embedding": {
                                  "type": "dense_vector",
                                  "dims": 1536,
                                  "index": True,
                                  "similarity": "cosine"
                              },
                              "document_id": {"type": "keyword"},
                              "project_id": {"type": "keyword"},
                              "created_at": {"type": "date"}
                          }
                      }
                  }
              )

      async def add_documents(
          self,
          documents: List[Dict[str, Any]],
          embeddings: List[List[float]]
      ):
          """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“"""
          from elasticsearch.helpers import async_bulk

          actions = []
          for i, (doc, embedding) in enumerate(zip(documents, embeddings)):
              actions.append({
                  "_index": self.index_name,
                  "_id": doc.get("id", f"doc_{i}"),
                  "_source": {
                      "content": doc.get("text", ""),
                      "embedding": embedding,
                      "document_id": doc.get("document_id", ""),
                      "project_id": doc.get("project_id", ""),
                      "created_at": doc.get("created_at", "")
                  }
              })

          await async_bulk(self.es_client, actions)

      async def semantic_search(
          self,
          query_text: str,
          top_k: int = 10
      ) -> List[Dict[str, Any]]:
          """è¯­ä¹‰æœç´¢"""
          # 1. è·å–æŸ¥è¯¢å‘é‡
          embedding_service = EmbeddingService()
          query_embedding = await embedding_service.embed_text(query_text)

          # 2. æ‰§è¡ŒkNNæœç´¢
          response = await self.es_client.search(
              index=self.index_name,
              body={
                  "knn": {
                      "field": "embedding",
                      "query_vector": query_embedding,
                      "k": top_k,
                      "num_candidates": top_k * 10
                  }
              },
              size=top_k
          )

          return [
              {
                  "id": hit["_id"],
                  "score": hit["_score"],
                  "content": hit["_source"]["content"],
                  "metadata": {
                      "document_id": hit["_source"]["document_id"],
                      "project_id": hit["_source"]["project_id"]
                  }
              }
              for hit in response["hits"]["hits"]
          ]
  ```

- [ ] å®ç°å‘é‡åŒ–æœåŠ¡
  ```python
  # apps/backend-python/app/services/ai/embedding_service.py
  from openai import AsyncOpenAI

  class EmbeddingService:
      """å‘é‡åµŒå…¥æœåŠ¡"""

      def __init__(self):
          self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

      async def embed_text(self, text: str) -> List[float]:
          """æ–‡æœ¬è½¬å‘é‡"""
          response = await self.client.embeddings.create(
              model="text-embedding-ada-002",
              input=text
          )
          return response.data[0].embedding

      async def embed_documents(self, documents: List[str]) -> List[List[float]]:
          """æ‰¹é‡åµŒå…¥"""
          response = await self.client.embeddings.create(
              model="text-embedding-ada-002",
              input=documents
          )
          return [item.embedding for item in response.data]
  ```

- [ ] åˆ›å»ºAPIç«¯ç‚¹
  ```python
  @router.post("/vectorize-document")
  async def vectorize_document(document_id: str):
      """æ–‡æ¡£å‘é‡åŒ–"""
      # 1. è·å–æ–‡æ¡£å†…å®¹
      doc = await java_client.get_document(document_id)

      # 2. æ–‡æœ¬åµŒå…¥
      embedding_service = EmbeddingService()
      embedding = await embedding_service.embed_text(doc['plain_text'])

      # 3. å­˜å‚¨åˆ°Elasticsearch
      es_store = ElasticsearchVectorStore()
      await es_store.add_documents(
          documents=[{"id": document_id, "text": doc['plain_text']}],
          embeddings=[embedding]
      )

      return {"status": "success"}

  @router.post("/semantic-search")
  async def semantic_search(query: str, top_k: int = 10):
      """è¯­ä¹‰æœç´¢"""
      es_store = ElasticsearchVectorStore()
      results = await es_store.semantic_search(query, top_k)
      return results
  ```

#### 1.5.5 éƒ¨ç½²é…ç½®

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] ç¡®ä¿ Elasticsearch 9.2.1 å·²éƒ¨ç½² âœ…
- [ ] åˆå§‹åŒ–å‘é‡ç´¢å¼•ï¼ˆå¯åŠ¨æ—¶è‡ªåŠ¨æ‰§è¡Œï¼‰
- [ ] é…ç½® Elasticsearch ç¯å¢ƒå˜é‡

---

### äºŒçº§ä»»åŠ¡ 1.6: APIæ¥å£æ•´åˆå’Œæµ‹è¯•

**é¢„è®¡å·¥ä½œé‡**: 2 äººå¤©
**å®Œæˆè¿›åº¦**: 0% (0/5 ç±»åˆ«)

#### 1.6.1 æ•°æ®å®šä¹‰

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] å®šä¹‰APIè¯·æ±‚/å“åº”æ¨¡å‹ï¼ˆå·²åœ¨å„å­ä»»åŠ¡å®Œæˆï¼‰

#### 1.6.2 å‰ç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] é›†æˆæ‰€æœ‰APIåˆ°å‰ç«¯æœåŠ¡å±‚
  ```typescript
  // apps/frontend/src/services/ai.service.ts
  export const aiService = {
      parseDocument: (file: File, projectId: string) => { ... },
      extractRequirements: (documentId: string) => { ... },
      semanticSearch: (query: string) => { ... },
  };
  ```

#### 1.6.3 Javaåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] åˆ›å»ºç»Ÿä¸€çš„AIæœåŠ¡ä»£ç†ï¼ˆå¯é€‰ï¼‰
  ```java
  @Service
  public class AIServiceProxy {
      @Value("${ai.service.url}")
      private String aiServiceUrl;

      public <T> T callAIService(String endpoint, Object request, Class<T> responseType) {
          // ç»Ÿä¸€è°ƒç”¨Python AIæœåŠ¡
      }
  }
  ```

#### 1.6.4 Pythonåç«¯å®ç°

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] æ•´åˆæ‰€æœ‰APIåˆ°ä¸»è·¯ç”±
  ```python
  # apps/backend-python/app/api/v1/__init__.py
  from fastapi import APIRouter
  from app.api.v1 import (
      document_parser,
      information_extraction,
      semantic_search
  )

  api_router = APIRouter()
  api_router.include_router(document_parser.router)
  api_router.include_router(information_extraction.router)
  api_router.include_router(semantic_search.router)
  ```

- [ ] æ·»åŠ APIæ–‡æ¡£
  ```python
  # apps/backend-python/app/main.py
  app = FastAPI(
      title="AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å° - AIæœåŠ¡",
      description="æä¾›æ–‡æ¡£è§£æã€ä¿¡æ¯æå–ã€è¯­ä¹‰æœç´¢ç­‰AIèƒ½åŠ›",
      version="1.0.0",
      docs_url="/docs",
      redoc_url="/redoc"
  )
  ```

#### 1.6.5 éƒ¨ç½²é…ç½®

**å¾…å®Œæˆä»»åŠ¡**:
- [ ] ç¼–å†™é›†æˆæµ‹è¯•è„šæœ¬
  ```bash
  # scripts/test-ai-integration.sh
  #!/bin/bash

  echo "æµ‹è¯•æ–‡æ¡£ä¸Šä¼ ..."
  curl -X POST http://localhost:8001/api/v1/ai/parse-document \
    -F "file=@test.pdf" \
    -F "project_id=test-project-id"

  echo "æµ‹è¯•ä¿¡æ¯æå–..."
  curl -X POST http://localhost:8001/api/v1/ai/extract-requirements \
    -H "Content-Type: application/json" \
    -d '{"document_id": "test-doc-id"}'

  echo "æµ‹è¯•è¯­ä¹‰æœç´¢..."
  curl -X POST http://localhost:8001/api/v1/ai/semantic-search \
    -H "Content-Type: application/json" \
    -d '{"query": "æŠ€æœ¯è¦æ±‚", "top_k": 10}'
  ```

---

## æ€»ç»“å’Œä¸‹ä¸€æ­¥

### AI-001 æ€»ä½“è¿›åº¦

- **æ€»è®¡äºŒçº§ä»»åŠ¡**: 6ä¸ª
- **å·²å®Œæˆ**: 0ä¸ªï¼ˆ0%ï¼‰
- **å¾…å¼€å§‹**: 6ä¸ª
- **é¢„è®¡æ€»å·¥ä½œé‡**: 18 äººå¤©

### ç»†åŒ–æ•ˆæœ

âœ… **ç»†åŒ–å‰**: 6ä¸ªç²—ç²’åº¦å­ä»»åŠ¡ï¼ˆå¦‚"æ–‡æ¡£è§£æå¼•æ“"ï¼‰
âœ… **ç»†åŒ–å**: æ¯ä¸ªå­ä»»åŠ¡æ‹†åˆ†ä¸º5ç±»åˆ«ï¼ˆæ•°æ®/å‰ç«¯/Java/Python/éƒ¨ç½²ï¼‰ï¼Œå…± 30+ å…·ä½“ä»»åŠ¡é¡¹

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å¼€å§‹**: äºŒçº§ä»»åŠ¡ 1.1ï¼ˆPDFæ–‡æ¡£è§£æå¼•æ“ï¼‰
   - ä»æ•°æ®å®šä¹‰å¼€å§‹
   - ç„¶åå‰ç«¯ç»„ä»¶
   - å†Pythonåç«¯å®ç°
   - æœ€åéƒ¨ç½²é…ç½®

2. **å¹¶è¡Œå¼€å‘**ï¼ˆå¦‚æœå›¢é˜Ÿå……è¶³ï¼‰:
   - å‰ç«¯å›¢é˜Ÿï¼š1.1.2ï¼ˆå‰ç«¯å®ç°ï¼‰
   - Pythonå›¢é˜Ÿï¼š1.1.4ï¼ˆPythonåç«¯ï¼‰
   - Javaå›¢é˜Ÿï¼š1.1.3ï¼ˆJavaåç«¯ï¼‰
   - DevOpså›¢é˜Ÿï¼š1.1.5ï¼ˆéƒ¨ç½²é…ç½®ï¼‰

3. **ä¾èµ–å…³ç³»**:
   - 1.1.1ï¼ˆæ•°æ®å®šä¹‰ï¼‰å¿…é¡»ä¼˜å…ˆå®Œæˆ
   - 1.1.2-1.1.4 å¯ä»¥å¹¶è¡Œå¼€å‘
   - 1.1.5ï¼ˆéƒ¨ç½²ï¼‰åœ¨å¼€å‘å®Œæˆåè¿›è¡Œ

---


---
**ğŸ“– ä¸‹ä¸€æ­¥**: [AI-002 æ™ºèƒ½å†…å®¹ç”Ÿæˆå¼•æ“](./task-plan-python-ai-è¯¦ç»†-AI-002.md)
