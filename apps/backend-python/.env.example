# =============================================================================
# AI Backend Service - Environment Variables
# =============================================================================
# Copy this file to .env and fill in the actual values

# Application Settings
APP_NAME="AIBidComposer AI Service"
APP_ENV=development  # development, testing, staging, production
DEBUG=True
LOG_LEVEL=INFO
API_VERSION=v1

# Server Settings
HOST=0.0.0.0
PORT=8001
WORKERS=4
RELOAD=True  # Set to False in production

# CORS Settings
CORS_ORIGINS=http://localhost:5173,http://localhost:8080
CORS_ALLOW_CREDENTIALS=True
CORS_ALLOW_METHODS=*
CORS_ALLOW_HEADERS=*

# Security
SECRET_KEY=your-secret-key-min-32-characters-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Java Backend Service Integration
JAVA_SERVICE_URL=http://localhost:8080
JAVA_SERVICE_API_KEY=  # Optional if using internal network

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=
REDIS_MAX_CONNECTIONS=50

# Elasticsearch Configuration (Vector Store + Search)
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=your_elasticsearch_password
ELASTICSEARCH_INDEX_PREFIX=aibidcomposer
ELASTICSEARCH_TIMEOUT=30
ELASTICSEARCH_MAX_RETRIES=3

# RabbitMQ Configuration (Message Queue)
RABBITMQ_URL=amqp://guest:guest@localhost:5672/
RABBITMQ_QUEUE_NAME=ai_tasks
CELERY_BROKER_URL=amqp://guest:guest@localhost:5672/
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# OpenAI Configuration (Primary LLM)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7
OPENAI_TIMEOUT=60

# Anthropic Configuration (Claude - Backup LLM)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-opus-20240229
ANTHROPIC_MAX_TOKENS=4000
ANTHROPIC_TIMEOUT=60

# Pinecone Configuration (Backup Vector Store - Optional)
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=
PINECONE_INDEX_NAME=aibidcomposer

# Neo4j Configuration (Knowledge Graph - Optional)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password
NEO4J_DATABASE=neo4j

# LlamaIndex Settings
LLAMAINDEX_CHUNK_SIZE=1024
LLAMAINDEX_CHUNK_OVERLAP=200
LLAMAINDEX_SIMILARITY_TOP_K=10
LLAMAINDEX_CACHE_DIR=.cache/llama_index

# Document Processing Settings
MAX_FILE_SIZE_MB=50
ALLOWED_EXTENSIONS=pdf,docx,doc,xlsx,xls,txt
UPLOAD_DIR=/tmp/uploads
PROCESSING_TIMEOUT=300  # seconds

# Rate Limiting
RATE_LIMIT_ENABLED=True
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_BURST=10

# Monitoring & Logging
ENABLE_METRICS=True
METRICS_PORT=9090
SENTRY_DSN=  # Optional
SENTRY_ENVIRONMENT=development
SENTRY_TRACES_SAMPLE_RATE=0.1

# Feature Flags
ENABLE_CACHE=True
ENABLE_ASYNC_TASKS=True
ENABLE_DISTRIBUTED_TRACING=False
