# AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å° - å¼€å‘ç¯å¢ƒé…ç½®æŒ‡å—

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒæ¦‚è§ˆ

### ç¯å¢ƒè¦æ±‚
```yaml
ç³»ç»Ÿè¦æ±‚:
  æ“ä½œç³»ç»Ÿ:
    - å¼€å‘ç¯å¢ƒ: macOS 12+ / Windows 11 / Ubuntu 20.04+
    - ç”Ÿäº§ç¯å¢ƒ: Linux (Ubuntu 20.04+ / CentOS 8+)
    - æµ‹è¯•ç¯å¢ƒ: æ”¯æŒä»¥ä¸Šæ‰€æœ‰æ“ä½œç³»ç»Ÿ

  ç¡¬ä»¶è¦æ±‚:
    CPU: 4æ ¸å¿ƒä»¥ä¸Šï¼ˆæ¨è8æ ¸å¿ƒï¼‰
    å†…å­˜: 16GBä»¥ä¸Šï¼ˆæ¨è32GBï¼‰
    ç¡¬ç›˜: 500GB SSDï¼ˆæ¨è1TB NVMeï¼‰
    ç½‘ç»œ: ç¨³å®šç½‘ç»œè¿æ¥ï¼ˆ100Mbpsä»¥ä¸Šï¼‰

  å¼€å‘å·¥å…·:
    - IDE: VS Code / WebStorm / PyCharm
    - ç‰ˆæœ¬æ§åˆ¶: Git 2.30+
    - å®¹å™¨åŒ–: Docker Desktop / Docker Engine
    - APIæµ‹è¯•: Postman / Insomnia
    - æ•°æ®åº“å·¥å…·: pgAdmin / DataGrip
```

### å¼€å‘å›¢é˜Ÿåä½œç¯å¢ƒ
```yaml
ä»£ç ä»“åº“:
  ä¸»è¦ä»“åº“: GitHub / GitLab
    - å‰ç«¯ä»£ç : Reactåº”ç”¨
    - åç«¯ä»£ç : FastAPIåº”ç”¨
    - é…ç½®æ–‡ä»¶: Dockerã€CI/CDé…ç½®
    - æ–‡æ¡£: é¡¹ç›®æ–‡æ¡£ã€APIæ–‡æ¡£

  åˆ†æ”¯ç­–ç•¥:
    - main: ç”Ÿäº§ç¯å¢ƒä»£ç 
    - develop: å¼€å‘ç¯å¢ƒä»£ç 
    - feature/*: åŠŸèƒ½å¼€å‘åˆ†æ”¯
    - hotfix/*: ç´§æ€¥ä¿®å¤åˆ†æ”¯

  åä½œæµç¨‹:
    - åŠŸèƒ½å¼€å‘: develop â†’ feature/* â†’ develop â†’ main
    - ç´§æ€¥ä¿®å¤: main â†’ hotfix/* â†’ main
    - ä»£ç å®¡æŸ¥: æ‰€æœ‰åˆ†æ”¯å¿…é¡»ç»è¿‡ä»£ç å®¡æŸ¥
    - è‡ªåŠ¨åŒ–æµ‹è¯•: CI/CDè‡ªåŠ¨è¿è¡Œæµ‹è¯•
```

## ğŸ› ï¸ å‰ç«¯å¼€å‘ç¯å¢ƒé…ç½®

### å¼€å‘ç¯å¢ƒæ­å»º
```typescript
// package.json - é¡¹ç›®ä¾èµ–é…ç½®
{
  "name": "aibidcomposer-frontend",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite --host 0.0.0.0 --port 3000",
    "build": "tsc && vite build",
    "preview": "vite preview --port 4173",
    "test": "vitest --no-coverage",
    "test:ui": "vitest --ui",
    "test:e2e": "playwright test",
    "test:e2e:headed": "playwright test --headed",
    "type-check": "tsc --noEmit",
    "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
    "lint:fix": "eslint . --ext ts,tsx --fix",
    "format": "prettier --write .",
    "postinstall": "husky install",
    "prepare": "husky",
    "pre-commit": "lint-staged",
    "pre-commit:lint": "lint-staged",
    "pre-commit:format": "lint-staged --fix"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.1",
    "@mui/material": "^5.14.19",
    "@mui/icons-material": "^5.14.19",
    "@mui/x-date-pickers": "^6.18.2",
    "@blocknote/core": "^0.17.2",
    "@blocknote/react": "^0.17.2",
    "@tanstack/react-query": "^5.28.5",
    "@tanstack/react-table": "^8.11.8",
    "@hookform/resolvers": "^3.3.2",
    "@hookform/react": "^7.45.4",
    "zod": "^3.22.4",
    "axios": "^1.6.2",
    "react-hook-form": "^7.48.2",
    "y-websocket": "^13.6.1",
    "yjs": "^13.6.19",
    "socket.io-client": "^4.7.2",
    "uuid": "^9.0.1",
    "lodash": "^4.17.21",
    "date-fns": "^2.30.0",
    "react-beautiful-dnd": "^16.1.1",
    "react-dropzone": "^14.2.3",
    "react-pdf": "^7.7.0",
    "react-syntax-highlighter": "^15.5.0",
    "react-markdown": "^9.0.1",
    "recharts": "^2.8.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.37",
    "@types/react-dom": "^18.2.15",
    "@types/node": "^20.8.7",
    "@types/lodash": "^4.14.197",
    "@types/uuid": "^9.0.7",
    "@typescript-eslint/eslint-plugin": "^6.10.0",
    "@typescript-eslint/parser": "^6.10.0",
    "@vitejs/plugin-react": "^4.0.4",
    "@vitejs/plugin-typescript": "^1.0.1",
    "vite": "^5.0.11",
    "eslint": "^8.51.0",
    "eslint-config-react": "^18.2.0",
    "eslint-config-prettier": "^9.0.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.4",
    "prettier": "^3.0.3",
    "husky": "^8.0.3",
    "lint-staged": "^15.1.0",
    "vitest": "^1.0.4",
    "@vitest/ui": "^0.0.0",
    "@playwright/test": "^1.40.1",
    "ts-node": "^10.9.1",
    "tsx": "^4.6.0"
  },
  "engines": {
    "node": ">=18.0.0"
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  }
}

// vite.config.ts - Viteé…ç½®
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'
import { resolve } from 'path'

export default defineConfig({
  plugins: [react()],
  resolve: {
    alias: {
      '@': resolve(__dirname, './src'),
      '@/components': resolve(__dirname, './src/components'),
      '@/pages': resolve(__dirname, './src/pages'),
      '@/hooks': resolve(__dirname, './src/hooks'),
      '@/services': resolve(__dirname, './src/services'),
      '@/utils': resolve(__dirname, './src/utils'),
      '@/types': resolve(__dirname, './src/types')
    }
  },
  server: {
    port: 3000,
    host: true,
    open: true
  },
  build: {
    outDir: 'dist',
    sourcemap: true,
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['react', 'react-dom', 'react-router-dom'],
          mui: ['@mui/material', '@mui/icons-material'],
          blocknote: ['@blocknote/core', '@blocknote/react'],
          utils: ['lodash', 'date-fns', 'uuid']
        }
      }
    }
  },
  optimizeDeps: {
    include: ['react', 'react-dom', '@mui/material', '@blocknote/core']
  },
  define: {
    'process.env.VITE_API_BASE_URL': JSON.stringify(
      process.env.VITE_API_BASE_URL || 'http://localhost:8000'
    )
  }
})

// tsconfig.json - TypeScripté…ç½®
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["DOM", "DOM.Iterable", "ES6"],
    "allowJs": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "forceConsistentCasingInImports": true,
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",
    "jsxImportSource": "react",
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"],
      "@/components/*": ["./src/components/*"],
      "@/pages/*": ["./src/pages/*"],
      "@/hooks/*": ["./src/hooks/*"],
      "@/services/*": ["./src/services/*"],
      "@/utils/*": ["./src/utils/*"],
      "@/types/*": ["./src/types/*"]
    }
  },
  "include": [
    "src",
    "src/**/*.tsx",
    "src/**/*.ts"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "**/*.test.ts",
    "**/*.test.tsx",
    "**/*.spec.ts",
    "**/*.spec.tsx"
  ]
}

// .eslintrc.js - ESLinté…ç½®
module.exports = {
  root: true,
  env: {
    browser: true,
    es2020: true,
    node: true
  },
  extends: [
    'eslint:recommended',
    '@typescript-eslint/recommended',
    'plugin:react/recommended',
    'plugin:react-hooks/recommended',
    'prettier'
  ],
  ignorePatterns: ['dist', '.eslintrc.js'],
  parser: '@typescript-eslint/parser',
  parserOptions: {
    ecmaVersion: 'latest',
    sourceType: 'module',
    ecmaFeatures: {
      jsx: true
    }
  },
  plugins: ['react-refresh'],
  rules: {
    'react-refresh/only-export-components': [
      'warn',
      { allowConstantExport: true }
    ],
    '@typescript-eslint/no-unused-vars': ['error', { 'argsIgnorePattern': '^_' }],
    '@typescript-eslint/no-explicit-any': 'warn',
    'react/prop-types': 'off',
    'react/react-in-jsx-uses-react': 'off'
  },
  settings: {
    react: {
      version: 'detect'
    }
  }
}

// prettier.config.js - Prettieré…ç½®
module.exports = {
  semi: true,
  trailingComma: 'es5',
  singleQuote: true,
  printWidth: 80,
  tabWidth: 2,
  useTabs: false,
  endOfLine: 'lf',
  bracketSpacing: true,
  jsxSingleQuote: false,
  arrowParensAvoidAvoidingAmbiguity: true
}
```

### å¼€å‘å·¥å…·é…ç½®
```json
// .vscode/settings.json - VSCodeé…ç½®
{
  "typescript.preferences": {
    "importModuleSpecifier": "relative"
  },
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.fixAll.eslint": "always",
    "source.organizeImports": "never"
  },
  "emmet.includeLanguages": {
    "typescript": "react",
    "typescriptreact": "react"
  },
  "emmet.aliases": {
    "@": "/src",
    "@/components": "/src/components",
    "@/pages": "/src/pages",
    "@/hooks": "/src/hooks",
    "@/services": "/src/services",
    "@/utils": "/src/utils",
    "@/types": "/src/types"
  }
}

// .vscode/launch.json - è°ƒè¯•é…ç½®
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Debug React Components",
      "type": "react",
      "request": "launch",
      "cwd": "${workspaceFolder}",
      "runtimeExecutable": "npm",
      "runtimeArgs": ["run-script", "dev"],
      "env": {
        "NODE_ENV": "development"
      },
      "port": 3000,
      "webRoot": "${workspaceFolder}/src",
      "console": "integratedTerminal",
      "sourceMaps": true,
      "breakOnUncaughtExceptions": true,
      "envFile": "${workspaceFolder}/.env.local"
    },
    {
      "name": "Debug Backend",
      "type": "node",
      "request": "launch",
      "program": "${workspaceFolder}/server/app.py",
      "cwd": "${workspaceFolder}/server",
      "console": "integratedTerminal",
      "env": {
        "PYTHONPATH": "${workspaceFolder}/.venv/bin"
      },
      "python": "/Users/yourname/.pyenv/bin/python3",
      "args": ["run", "app.py"],
      "envFile": "${workspaceFolder}/server/.env.local"
    },
    {
      "name": "Run Tests",
      "type": "node",
      "request": "launch",
      "cwd": "${workspaceFolder}",
      "runtimeExecutable": "npm",
      "runtimeArgs": ["run", "test"]
    }
  ]
}

// .vscode/tasks.json - ä»»åŠ¡é…ç½®
{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "Start Frontend Dev Server",
      "type": "npm",
      "script": "dev",
      "problemMatcher": [],
      "group": "build"
    },
    {
      "label": "Build Frontend",
      "type": "npm",
      "script": "build",
      "problemMatcher": [],
      "group": "build"
    },
    {
      "label": "Run Tests",
      "type": "npm",
      "script": "test",
      "problemMatcher": [],
      "group": "test"
    },
    {
      "label": "Type Check",
      "type": "npm",
      "script": "type-check",
      "problemMatcher": [],
      "group": "test"
    },
    {
      "label": "Lint Code",
      "type": "npm",
      "script": "lint",
      "problemMatcher": [],
      "group": "code-quality"
    },
    {
      "label": "Format Code",
      "type": "npm",
      "script": "format",
      "problemMatcher": [],
      "group": "code-quality"
    }
  ]
}
```

## ğŸ”§ åç«¯å¼€å‘ç¯å¢ƒé…ç½®

### Pythonç¯å¢ƒæ­å»º
```bash
# åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python -m venv aibidcomposer-backend
source aibidcomposer-backend/bin/activate

# å‡çº§pip
pip install --upgrade pip

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# å®‰è£…å¼€å‘å·¥å…·
pip install black isort flake8 mypy pytest pytest-cov pre-commit

# é…ç½®pre-commité’©å­
pre-commit install
```

### requirements.txt - Pythonä¾èµ–é…ç½®
```python
# Webæ¡†æ¶
fastapi==0.104.1
uvicorn[standard]==0.24.0.post1
python-multipart==0.0.6
pydantic==2.5.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4

# æ•°æ®åº“
sqlalchemy==2.0.23
asyncpg==0.29.0
alembic==1.12.1
redis==5.0.1
psycopg2-binary==2.9.7
asyncpg-binary==0.29.0

# AIå’Œæœºå™¨å­¦ä¹ 
openai==1.3.7
langchain==0.1.0
sentence-transformers==2.2.2
pinecone-client==2.2.4
numpy==1.26.0
pandas==2.1.4
scikit-learn==1.3.2

# HTTPå®¢æˆ·ç«¯
httpx==0.25.2
requests==2.31.0
aiohttp==3.9.1

# æ•°æ®éªŒè¯
pydantic-settings==2.1.0
email-validator==2.0.0

# èº«ä»½è®¤è¯
python-jose[cryptography]==3.3.0
python-multipart==0.0.6
passlib[bcrypt]==1.7.4

# å¼‚æ­¥ä»»åŠ¡
celery==5.3.4
kombu==5.3.4
redis==5.0.1

# æ–‡æ¡£ç”Ÿæˆ
jinja2==3.1.2
python-docx==0.8.11
openpyxl==3.1.2

# æµ‹è¯•
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
httpx==0.25.2
pytest-mock==3.12.0

# å¼€å‘å·¥å…·
black==23.11.0
isort==5.12.0
flake8==6.1.0
mypy==1.7.1
pre-commit==3.6.0

# å®‰å…¨
cryptography==41.0.8
python-jose[cryptography]==3.3.0
bcrypt==4.1.2

# ç›‘æ§å’Œæ—¥å¿—
structlog==23.2.0
sentry-sdk[fastapi]==1.28.0
prometheus-client==0.19.0
```

### åº”ç”¨é…ç½®
```python
# .env - ç¯å¢ƒå˜é‡é…ç½®
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://aibidcomposer:password@localhost:5432/aibidcomposer
REDIS_URL=redis://localhost:6379/0

# AIæœåŠ¡é…ç½®
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000

# æ™ºè°±AIé…ç½®
ZHIPUAI_API_KEY=your-zhipu-api-key-here
ZHIPUAI_MODEL=chatglm3-6b

# Pineconeé…ç½®
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX=aibidcomposer-index

# JWTé…ç½®
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# åº”ç”¨é…ç½®
DEBUG=True
ENVIRONMENT=development
API_V1_STR=/api/v1
PROJECT_NAME=AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å°

# æ–‡ä»¶å­˜å‚¨é…ç½®
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET_NAME=aibidcomposer-files

# é‚®ä»¶é…ç½®
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password
EMAILS_FROM_EMAIL=noreply@aibidcomposer.com
EMAILS_FROM_NAME=AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å°

# å®‰å…¨é…ç½®
CORS_ORIGINS=http://localhost:3000,http://localhost:8000
ALLOWED_HOSTS=localhost,127.0.0.1
ALLOWED_CREDENTIALS_FROM_ORIGINS=http://localhost:3000
```

### åº”ç”¨å¯åŠ¨é…ç½®
```python
# main.py - åº”ç”¨å…¥å£æ–‡ä»¶
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException
from contextlib import asynccontextmanager

import os
import logging
import uvicorn

# å¯¼å…¥åº”ç”¨æ¨¡å—
from app.core.config import settings
from app.core.database import engine
from app.core.exceptions import setup_exception_handlers
from app.core.middleware import setup_middleware
from app.api.v1.api import api_router
from app.core.events import startup_event, shutdown_event

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log'),
        logging.StreamHandler()
    ]
)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title=settings.PROJECT_NAME,
    description=settings.PROJECT_DESCRIPTION,
    version=settings.VERSION,
    debug=settings.DEBUG,
    openapi_url=f"{settings.API_V1_STR}/openapi.json"
)

# è®¾ç½®å¼‚å¸¸å¤„ç†
setup_exception_handlers(app)

# è®¾ç½®ä¸­é—´ä»¶
setup_middleware(app)

# è®¾ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è®¾ç½®ä¿¡ä»»ä¸»æœº
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=settings.ALLOWED_HOSTS
)

# æ³¨å†ŒAPIè·¯ç”±
app.include_router(api_router, prefix=settings.API_V1_STR)

# æ³¨å†Œäº‹ä»¶å¤„ç†
app.add_event_handler("startup", startup_event)
app.add_event_handler("shutdown", shutdown_event)

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": settings.PROJECT_NAME,
        "version": settings.VERSION,
        "environment": settings.ENVIRONMENT,
        "database": "connected" if await check_database() else "disconnected",
        "redis": "connected" if await check_redis() else "disconnected"
    }

# æ•°æ®åº“è¿æ¥æ£€æŸ¥
async def check_database():
    try:
        async with engine.begin() as conn:
            await conn.execute("SELECT 1")
        return True
    except Exception as e:
        logging.error(f"Database connection failed: {e}")
        return False

# Redisè¿æ¥æ£€æŸ¥
async def check_redis():
    try:
        import redis
        r = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=settings.REDIS_DB,
            password=settings.REDIS_PASSWORD
        )
        await r.ping()
        return True
    except Exception as e:
        logging.error(f"Redis connection failed: {e}")
        return False

# ç”Ÿäº§ç¯å¢ƒå¯åŠ¨é…ç½®
if __name__ == "__main__":
    uvicorn.run(
        "app:main",
        host="0.0.0.0",
        port=8000,
        reload=settings.DEBUG,
        log_level="info",
        access_log=True,
        workers=4,
        limit_concurrency=1000,
        timeout_keep_alive=65,
        max_requests=1000,
        max_request_size=50 * 1024 * 1024,  # 50MB
    )
```

## ğŸ³ï¸ æ•°æ®åº“é…ç½®

### PostgreSQLé…ç½®
```sql
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE aibidcomposer;
CREATE DATABASE aibidcomposer_test;
CREATE DATABASE aibidcomposer_dev;

-- åˆ›å»ºç”¨æˆ·
CREATE USER aibidcomposer WITH PASSWORD 'your-secure-password';
GRANT ALL PRIVILEGES ON DATABASE aibidcomposer TO aibidcomposer;
GRANT ALL PRIVILEGES ON DATABASE aibidcomposer_test TO aibidcomposer;
GRANT ALL PRIVILEGES ON DATABASE aibidcomposer_dev TO aibidcomposer;

-- è¿æ¥åˆ°ä¸»æ•°æ®åº“
\c aibidcomposer

-- åˆ›å»ºæ‰©å±•
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";
CREATE EXTENSION IF NOT EXISTS "vector";
CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";

-- åˆ›å»ºç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_projects_company_id ON projects(company_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_company_id ON users(company_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_documents_project_id ON documents(project_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_templates_company_id ON templates(company_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_enterprise_capabilities_company_id ON enterprise_capabilities(company_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_assistants_company_id ON ai_assistants(company_id);

-- åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_projects_fulltext ON projects USING gin(to_tsvector('chinese', project_name || ' ' || description));
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_enterprise_capabilities_fulltext ON enterprise_capabilities USING gin(to_tsvector('chinese', name || ' ' || description));
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_search_ai_assistants_fulltext ON ai_assistants USING gin(to_tsvector('chinese', name || ' ' || description));

-- åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_enterprise_capabilities_embedding ON enterprise_capabilities USING ivfflat (embedding_vector vector_cosine_ops);
```

### Redisé…ç½®
```yaml
# redis.conf - Redisé…ç½®æ–‡ä»¶
# åŸºç¡€é…ç½®
port 6379
bind 127.0.0.1
protected-mode no
daemonize yes
pidfile /var/run/redis/redis-server.pid
logfile /var/log/redis/redis-server.log
loglevel notice

# å†…å­˜é…ç½®
maxmemory 2gb
maxmemory-policy allkeys-lru

# æŒä¹…åŒ–é…ç½®
save 900 1
save 300 10
save 60 10000
stop-writes-on-bgsave-error yes

# å®‰å…¨é…ç½®
requirepass your-redis-password
rename-command FLUSHDB "CONFIRM"

# ç½‘ç»œé…ç½®
timeout 300
tcp-keepalive 60
tcp-backlog 300
tcp-keepalive-timeout 60

# æ€§èƒ½ä¼˜åŒ–
maxclients 10000
tcp-backlog 511
slowlog-log-slow-more-than 10000

# å†…å­˜ä¼˜åŒ–
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
hash-max-ziplist-entries 512
```

## ğŸ³ï¸ Dockeré…ç½®

### å¤šæœåŠ¡Dockeré…ç½®
```yaml
# docker-compose.yml - å®Œæ•´çš„Docker Composeé…ç½®
version: '3.8'

services:
  # å‰ç«¯åº”ç”¨
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_ENVIRONMENT=development
    volumes:
      - ./frontend:/app
      - /app/node_modules:/app/node_modules
    depends_on:
      - api
    networks:
      - aibidcomposer-network

  # åç«¯APIæœåŠ¡
  api:
    build:
      context: ./server
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://aibidcomposer:password@postgres:5432/aibidcomposer
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ZHIPUAI_API_KEY=${ZHIPUAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - SECRET_KEY=${SECRET_KEY}
      - ENVIRONMENT=development
    volumes:
      - ./server:/app
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    depends_on:
      - postgres
      - redis
    networks:
      - aibidcomposer-network

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=aibidcomposer
      - POSTGRES_USER=aibidcomposer
      - POSTGRES_PASSWORD=secure_password
      - POSTGRES_HOST=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./server/migrations:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - aibcomposer-network

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - aibcomposer-network

  # MinIOå¯¹è±¡å­˜å‚¨
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_DEFAULT_BUCKETS=aibidcomposer-files
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - aibcomposer-network

  # Celeryå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
  celery-worker:
    build:
      context: ./server
      dockerfile: Dockerfile.celery
    environment:
      - DATABASE_URL=postgresql://aibidcomposer:password@postgres:5432/aibidcomposer
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - ./server:/app
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    depends_on:
      - postgres
      - redis
      - api
    networks:
      - aibcomposer-network

  # Celeryç›‘æ§
  celery-flower:
    build:
      context: ./server
      dockerfile: Dockerfile.celery-flower
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_DEBUG=1
    depends_on:
      - redis
      - api
    networks:
      - aibcomposer-network

  # Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - frontend
      - api
    networks:
      - aibidcomposer-network

networks:
  aibicomposer-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
        gateway: 172.20.0.1
```

### Dockeré…ç½®æ–‡ä»¶
```dockerfile
# Dockerfile - å‰ç«¯Dockerfile
FROM node:18-alpine as builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶package.jsonå’Œpackage-lock.json
COPY package*.json ./
RUN npm ci

# å®‰è£…ä¾èµ–
RUN npm install

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§é•œåƒ
FROM nginx:alpine

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶nginxé…ç½®
COPY nginx.conf /etc/nginx/conf.d/default.conf

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¯åŠ¨nginx
CMD ["nginx", "-g", "daemon off;"]
```

```dockerfile
# Dockerfile - åç«¯Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apk add --no-cache \
    gcc \
    musl-dev \
    postgresql-dev \
    linux-headers \
    libffi-dev \
    openssl-dev \
    curl

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g appuser appuser
RUN adduser -D -G appuser appuser

# å¤åˆ¶requirementsæ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache --upgrade pip
RUN pip install --no-cache -r requirements.txt

# å¤åˆ¶æºä»£ç 
COPY . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app/.venv/bin
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/logs /app/uploads /app/static

# è®¾ç½®æƒé™
RUN chown -R appuser:appuser /app

# åˆ‡æ¢åˆ°åº”ç”¨ç”¨æˆ·
USER appuser

# å¥åº·æ£€æŸ¥
RUN curl -f http://localhost:8000/health || echo "API service not ready"

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨åº”ç”¨
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```dockerfile
# Dockerfile.celery - Celeryå·¥ä½œèŠ‚ç‚¹Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apk add --no-cache \
    gcc \
    musl-dev \
    postgresql-dev \
    linux-headers \
    libffi-dev \
    openssl-dev \
    curl

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g appuser appuser
RUN adduser -D -G appuser appuser

# å¤åˆ¶requirementsæ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache --upgrade pip
RUN pip install --no-cache -r requirements.txt

# å¤åˆ¶æºä»£ç 
COPY . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app/.venv/bin
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/logs /app/uploads

# è®¾ç½®æƒé™
RUN chown -R appuser:appuser /app

# å¯åŠ¨Celery Worker
CMD ["celery", "-A", "celery.celery:app", "--loglevel=info", "--concurrency=4"]
```

## ğŸ”’ IDEé…ç½®

### PyCharmé…ç½®
```json
{
  "name": "AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å°",
  "type": "Python",
  "python": {
    "version": "3.11",
    "paths": [
      "server"
    ],
    "venvPath": "server/.venv",
    "env": {
      "PYTHONPATH": "server/.venv/bin"
    },
    "environment": {
      "PYTHONPATH": "server/.env.local"
    },
    "django_settings_module": "server.core.config"
  },
  "javascript": {
    "path": "frontend",
    "version": "18.2.0",
    "nodeInterpreter": "/usr/local/bin/node",
    "npm": {
      "executable": "/usr/local/bin/npm",
      "run_script": true,
      "install": true
    }
  }
}
```

### VS Code Pythonæ‰©å±•é…ç½®
```json
{
  "python.defaultInterpreterPath": "./server/.venv/bin/python",
  "python.analysis.typeChecking": "basic",
  "python.analysis.autoImportCompletions": true,
  "python.analysis.autoSearchPaths": true,
  "python.analysis.typeChecking.mode": "off",
  "python.linting.pylintEnabled": true,
  "python.linting.pycodestyleEnabled": true,
  "python.linting.enabled": true,
  "python.formatting.provider": "black",
  "python.testing.pytestEnabled": true,
  "python.testing.pytestArgs": [
    "server/tests"
  ]
}
```

## ğŸ”§ å¼€å‘å·¥å…·å®‰è£…æŒ‡å—

### å®‰è£…Node.jså’Œnpm
```bash
# ä½¿ç”¨nvmç®¡ç†Node.jsç‰ˆæœ¬
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
source ~/.bashrc

# å®‰è£…æœ€æ–°LTS Node.js
nvm install --lts

# å®‰è£…npm
npm install -g npm@latest

# éªŒè¯å®‰è£…
node --version
npm --version
```

### å®‰è£…Pythonå’Œpip
```bash
# ä½¿ç”¨pyenvç®¡ç†Pythonç‰ˆæœ¬
curl -o- https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash
export PYENV_ROOT="$HOME/.pyenv"

# å®‰è£…Python 3.11
pyenv install 3.11.11

# è®¾ç½®é»˜è®¤Pythonç‰ˆæœ¬
pyenv global 3.11.11

# å‡çº§pip
pip install --upgrade pip

# å®‰è£…è™šæ‹Ÿç¯å¢ƒå·¥å…·
pip install --upgrade virtualenv

# åˆ›å»ºé¡¹ç›®è™šæ‹Ÿç¯å¢ƒ
python -m venv server/.venv
source server/.venv/bin/activate

# éªŒè¯Pythonå®‰è£…
python --version
```

### å®‰è£…Docker
```bash
# macOSå®‰è£…Docker Desktop
# ä» https://docs.docker.com/get-docker/ ä¸‹è½½å®‰è£…

# Linuxå®‰è£…Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -a $USER

# å¯åŠ¨Docker
sudo systemctl start docker
sudo systemctl enable docker

# éªŒè¯Dockerå®‰è£…
docker --version
docker-compose --version
```

## ğŸ” å¼€å‘è°ƒè¯•é…ç½®

### VS Codeè°ƒè¯•é…ç½®
```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Debug React Components",
      "type": "react",
      "request": "launch",
      "cwd": "${workspaceFolder}",
      "runtimeExecutable": "npm",
      "runtimeArgs": ["run", "dev"],
      "env": {
        "NODE_ENV": "development"
      },
      "port": 3000,
      "webRoot": "${workspaceFolder}/src",
      "console": "integratedTerminal",
      "sourceMaps": true,
      "breakOnUncaughtExceptions": true,
      "envFile": "${workspaceFolder}/.env.local"
    },
    {
      "name": "Debug API Endpoints",
      "type": "node",
      "request": "launch",
      "program": "${workspaceFolder}/server/app.py",
      "cwd": "${workspaceFolder}/server",
      "console": "integratedTerminal",
      "env": {
        "PYTHONPATH": "${workspaceFolder}/server/.venv/bin"
      },
      "python": "/Users/yourname/.pyenv/bin/python3",
      "args": ["run", "app.py"],
      "envFile": "${workspaceFolder}/server/.env.local"
    },
    {
      "name": "Run Tests",
      "type": "node",
      "request": "launch",
      "cwd": "${workspaceFolder}",
      "runtimeExecutable": "npm",
      "runtimeArgs": ["run", "test"],
      "problemMatcher": [],
      "group": "test"
    }
  ]
}
```

### æµ‹è¯•ç¯å¢ƒé…ç½®
```typescript
// vitest.config.ts - æµ‹è¯•é…ç½®
import { defineConfig } from 'vitest/config';
import react from '@vitejs/plugin-react';
import path from 'path';

export default defineConfig({
  plugins: [react()],
  testEnvironment: 'jsdom',
  testMatch: [
    '**/tests/**/*.{ts,tsx}',
    '**/test/**/*.{ts,tsx}',
    '**/__tests__/**/*.{ts,tsx}',
    '**/?(*.)+(spec|test).{ts,tsx}'
  ],
  testTimeout: 10000,
  coverage: {
    reporter: ['text', 'html', 'cobertura'],
    reportsDirectory: 'test-results',
    exclude: [
      'node_modules/',
      'dist/',
      '**/test/**/*.{ts,tsx}',
      '**/tests/**/*.{ts,tsx}'
    ]
  },
  setupFiles: [
    './tests/setupTests.ts'
  ],
  globals: {
    globalThis: 'jsdom',
    global: 'canvas',
    defineEmotion: 'jsdom'
  },
  include: [
    'src/**/*.{ts,tsx}',
    'tests/**/*.{ts,tsx}'
  ],
  exclude: [
    'node_modules/',
    'dist/',
    'build/'
  ],
  testEnvironmentOptions: {
    jsdom: {
      resources: [
        "data-testid=*",
        "data-testid=*"
      ]
    }
  }
});

// tests/setupTests.ts - æµ‹è¯•ç¯å¢ƒè®¾ç½®
import '@testing-library/jest-dom';
import '@testing-library/react';
import { expect, beforeAll, afterAll } from '@jest/globals';
import { server } from '../server/app';

// é…ç½®æµ‹è¯•æœåŠ¡å™¨è¿æ¥
beforeAll(async () => {
  // å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨
  if (!server.isRunning) {
    await server.start();
  }
});

afterAll(async () => {
  // å…³é—­æµ‹è¯•æœåŠ¡å™¨
  await server.close();
});

// å¯¼å…¥æµ‹è¯•å·¥å…·
global.TextEncoder = TextEncoder;
global.TextDecoder = TextDecoder;

// æ¨¡æ‹Ÿfetch
global.fetch = async (input: string | Request, init?: RequestInfo) => {
  const mockFetch = vi.fn();
  if (typeof input === 'string') {
    mockFetch.mockResolvedValue({
      ok: true,
      json: {},
    });
  } else {
    mockFetch.mockResolvedValue({});
  }
  return mockFetch(input, init);
};

// è®¾ç½®é»˜è®¤è¶…æ—¶
global.setDefaultTimeout(10000);
```

## ğŸ³ï¸ CI/CDé…ç½®

### GitHub Actionsé…ç½®
```yaml
# .github/workflows/ci.yml - GitHub Actionsé…ç½®
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop, 'feature/*', 'hotfix/*']
  pull_request:
    branches: [main, develop]

jobs:
  # å‰ç«¯æµ‹è¯•
  frontend-test:
    runs-on: ubuntu-latest
    container: node:18
    steps:
      - uses: actions/checkout@v3
      - name: Checkout code
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      - name: Install dependencies
        run: npm ci
      - name: Run linting
        run: npm run lint
      - name: Run type checking
        run: npm run type-check
      - name: Run unit tests
        run: npm run test
      - name: Run E2E tests
        run: npm run test:e2e2
      - name: Generate coverage report
        run: npm run test:cov

  # åç«¯æµ‹è¯•
  backend-test:
    runs-on: ubuntu-latest
    container: python:3.11
    steps:
      - uses: actions/checkout@v3
      - name: Checkout code
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run linting
        run: |
          black --check .
          isort --check .
          flake8 .
      - name: Run type checking
        run: mypy server/
      - name: Run tests
        run: pytest server/tests/ -v --cov=tests/coverage-report
      - name: Run E2E tests
        run: pytest tests/e2e2/ -v

  # æ„å»ºå’Œéƒ¨ç½²
  build-and-deploy:
    needs: [frontend-test, backend-test]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3
      - name: Build frontend
        run: |
          npm run build
      - name: Build backend image
        run: |
          docker build -t aibidcomposer-api:${{github.sha} .
      - name: Push to registry
        run: |
          echo ${{ secrets.DOCKERHUB_TOKEN }} | docker login -u ${{ secrets.DOCKERHUB_USERNAME }} --password-stdin
          docker push aibidcomposer-api:${{github.sha}
      - name: Deploy to staging
        run: |
          docker-compose -f docker-compose.staging.yml up -d

# ç”Ÿäº§éƒ¨ç½²
  deploy-production:
    needs: [build-and-deploy]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3
      - name: Deploy to production
        run: |
          docker-compose -f docker-compose.prod.yml up -d
```

### GitLab CI/CDé…ç½®
```yaml
# .gitlab-ci.yml - GitLab CI/CDé…ç½®
stages:
  - test
  - build
  - deploy

variables:
  DOCKER_DRIVER: docker
  DOCKER_HOST: tcp://docker:2375
  DOCKER_CERT_PATH: /certs/
  DOCKER_TLS_VERIFY: "true"
  FRONTEND_URL: http://localhost:3000
  BACKEND_URL: http://localhost:8000

cache:
  paths:
    - node_modules/
    - server/.venv/
    - .npm/
    - .cache/pip/
    - .cache/pytest/

test:
  stage: test
  script:
    - echo "Running frontend tests..."
    - cd frontend
    - npm ci
    - npm run test

    - echo "Running backend tests..."
    - cd server
    - python -m pytest tests/ -v --cov=tests/coverage
  coverage: '/coverage'
  artifacts:
    reports:
      reports:
        junit: reports/
        coverage: coverage/
    expire_in: 1 week

build:
  stage: build
  script:
    - echo "Building frontend..."
    - cd frontend
    - npm run build

    - echo "Building backend..."
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA_SHORT .
  cache:
    paths:
      - frontend/node_modules/
      - server/.venv/
  artifacts:
    paths:
      - frontend/dist/
      -server/
    expire_in: 1 week

deploy:
  stage: deploy
  script:
    - echo "Deploying to staging..."
    - docker-compose -f docker-compose.staging.yml up -d
    - echo "Deployment completed!"
  environment:
    - FRONTEND_URL: $FRONTEND_URL
    - BACKEND_URL: $BACKEND_URL
  when: manual
```

### Jenkinsé…ç½®
```yaml
pipeline {
  agent any
  stages:
    - checkout
    - test
    - build
    - deploy

  environment:
    NODE_VERSION: 18
    PYTHON_VERSION: 3.11
    DOCKER_HOST: localhost

  stages:
    - Checkout
    - Test
    - Build
    - Deploy

  Checkout:
    stage: checkout
    steps:
      - checkout scm
      - echo "Checking out $BRANCH branch"

  Test:
    stage: test
    stages:
      - Frontend Tests
      - Backend Tests
      - Integration Tests

    Frontend Tests:
      stage: Frontend Tests
      agent: node
      steps:
        - sh 'npm install'
        - sh 'npm run test'
        - sh 'npm run test:ui'
        - sh 'npm run test:e2e2'

    Backend Tests:
      stage: Backend Tests
      agent: python
      steps:
        - sh 'pip install -r requirements.txt'
        - sh 'python -m pytest tests/ -v --cov=tests/'
        - sh 'python -m pytest tests/e2e2/ -v'

  Build:
    stage: build
    stages:
      - Frontend Build
      - Backend Build
      - Image Build

    Frontend Build:
      stage: Frontend Build
      agent: node
      steps:
        - sh 'npm install'
        - sh 'npm run build'

    Backend Build:
      stage: Backend Build
      agent: python
      steps:
        - sh 'pip install -r requirements.txt'
        - docker build -t aibidcomposer-api:${BUILD_NUMBER} .

    Image Build:
      stage: Image Build
      agent: shell
      steps:
        - echo "Building Docker images..."
        - docker build -t aibidcomposer-${BUILD_NUMBER} .

  Deploy:
    stage: deploy
    stage: deploy
    agent: shell
    script:
      - echo "Deploying application..."
      - docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ“‹ è´¨é‡ä¿è¯å·¥å…·

### ä»£ç è´¨é‡æ£€æŸ¥
```json
// .eslintrc.js - ESLinté…ç½®
module.exports = {
  extends: [
    "eslint:recommended",
    "@typescript-eslint/recommended",
    "plugin:react/recommended",
    "plugin:react-hooks/recommended",
    "prettier"
  ],
  parser: "@typescript-eslint/parser",
  plugins: [
    "@typescript-eslint/eslint-plugin"
  ],
  rules: {
    "react-hooks/exhaustive-deps": "warn",
    "@typescript-eslint/no-unused-vars": "error",
    "@typescript-eslint/no-explicit-any": "warn",
    "react/no-unescaped-entities": "warn",
    "react/jsx-uses-react": "off",
    "react/prop-types": "off",
    "react/react-in-jsx": "off",
    "react/jsx-keywords": "off",
    "no-console": "warn",
    "no-debugger": "warn"
  },
  settings: {
    react: {
      version: "detect"
    }
  }
}
```

### ä»£ç æ ¼å¼åŒ–
```json
{
  "semi": true,
  "trailingComma": "es5",
  "singleQuote": true,
  "printWidth": 80,
  "tabWidth": 2,
  "useTabs": false,
  "bracketSpacing": true,
  "bracketSameLine": false,
    "arrowParensAvoidingAmbiguity": true,
    "endOfLine": "lf",
    "endOfLine": "lf",
    "bracketSpacing": true
}
```

### ç±»å‹æ£€æŸ¥é…ç½®
```json
{
  "compilerOptions": {
    "strict": true,
    "noEmit": true,
    "skipLibCheck": true,
    "target": "es2018",
    "lib": ["es2015", "es6", "dom"],
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "allowSyntheticDefaultImports": true,
    "esModuleInterop": true,
    "jsx": "react-jsx",
    "jsxImportSource": "react"
  },
  "include": [
    "src/**/*",
    "tests/**/*"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "build"
  ],
  "baseUrl": ".",
  "paths": {
    "@/*": ["./src/*"]
  }
}
```

## ğŸ“ ç›‘æ§å’Œæ—¥å¿—é…ç½®

### åº”ç”¨ç›‘æ§
```python
# server/monitoring.py - ç›‘æ§æ¨¡å—é…ç½®
import structlog
import logging
import time
from typing import Dict, Any
from datetime import datetime

# é…ç½®ç›‘æ§æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log'),
        logging.StreamHandler()
    ]
)

# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
def monitor_performance(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            end_time = time.time()
            duration = end_time - start_time

            # è®°å½•æ€§èƒ½æ•°æ®
            logging.info(
                f"Performance: {func.__name__}",
                f"Duration: {duration:.3f}s",
                f"Memory usage: {psutil.Process().memory_info().rss/1024/1024:.1f}MB"
            )
            return result
        except Exception as e:
            end_time = time.time()
            logging.error(
                f"Performance: {func.__name__}",
                f"Duration: {duration:.3f}s",
                f"Error: {str(e)}"
            )
            raise
    return wrapper

# APIæ€§èƒ½ç›‘æ§
@monitor_performance
async def measure_api_performance(endpoint: str, method: str, headers: Dict[str, Any] = None):
    start_time = time.time()

    # æ¨¡æ‹ŸAPIè°ƒç”¨
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

    end_time = time.time()
    duration = end_time - start_time

    return {
        "endpoint": endpoint,
        "method": method,
        "duration": duration,
        "timestamp": datetime.utcnow().isoformat(),
        "status": "success"
    }

# ç³»ç»Ÿèµ„æºç›‘æ§
def get_system_metrics():
    import psutil

    return {
        "cpu_percent": psutil.cpu_percent(),
        "memory_percent": psutil.virtual_memory().percent,
        "disk_usage": psutil.disk_usage('/'),
        "network_io": psutil.net_io_counters(),
        "process_count": len(psutil.pids()),
        "timestamp": datetime.utcnow().isoformat()
    }

# åº”ç”¨å¥åº·æ£€æŸ¥
async def check_application_health():
    health_status = {
        "status": "healthy",
        "database": "disconnected",
        "redis": "disconnected",
        "api": "disconnected",
        "frontend": "disconnected",
        "timestamp": datetime.utcnow().isoformat()
    }

    # æ£€æŸ¥æ•°æ®åº“
    try:
        async with engine.begin() as conn:
            await conn.execute("SELECT 1")
            health_status["database"] = "connected"
    except Exception as e:
        health_status["database"] = f"error: {e}"

    # æ£€æŸ¥Redis
    try:
        import redis
        r = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=settings.REDIS_DB
        )
        r.ping()
        health_status["redis"] = "connected"
    except Exception as e:
        health_status["redis"] = f"error: {e}"

    # æ£€æŸ¥API
    try:
        response = await httpx.get(f"{settings.API_BASE_URL}/health", timeout=5)
        if response.status_code == 200:
            health_status["api"] = "healthy"
        else:
            health_status["api"] = f"error: HTTP {response.status_code}"
    except Exception as e:
        health_status["api"] = f"error: {e}"

    return health_status
```

### æ—¥å¿—é…ç½®
```python
# server/core/logging_config.py - æ—¥å¿—é…ç½®
import os
import logging
import sys
import structlog
from typing import Dict, Any

# æ—¥å¿—æ ¼å¼é…ç½®
class ColoredFormatter(logging.Formatter):
    """å½©è‰²æ—¥å¿—æ ¼å¼åŒ–å™¨"""

    COLORS = {
        'DEBUG': '\033[94m',      # è“è‰²
        'INFO': '\033[92m',       # ç»¿è‰²
        'WARNING': '\033[93m',     # é»„è‰²
        'ERROR': '\033[91m',      # çº¢è‰²
        'CRITICAL': '\033[90m',    # çº¢è‰²
        'RESET': '\033[0m',      # é»˜è®¤
    }

    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        return f"{log_color}{formatter.format(record)}{self.COLORS['RESET']}"
    }

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log'),
        logging.StreamHandler()
    ]
)

# ç»“æ„åŒ–æ—¥å¿—é…ç½®
structlog
    timestamp: str
    level: str
    message: str
    module: str
    function_name: str
    user_id: str | None
    session_id: str | None
    request_id: str | None
    duration: float | None
    extra: Dict[str, Any] | None
```

## ğŸ”’ ç¯å¢ƒå˜é‡ç®¡ç†

### å¼€å‘ç¯å¢ƒå˜é‡
```yaml
# .env.development - å¼€å‘ç¯å¢ƒå˜é‡
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://aibidcomposer:dev_password@localhost:5432/aibidcomposer_dev
REDIS_URL=redis://localhost:6379/0

# AIæœåŠ¡é…ç½®
OPENAI_API_KEY=your-openai-development-key
OPENAI_MODEL=gpt-3.5-turbo
ZHIPUAI_API_KEY=your-zhipu-development-key
PINECONE_API_KEY=your-pinecone-development-key

# JWTé…ç½®
SECRET_KEY=your-secret-development-key
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60
REFRESH_TOKEN_EXPIRE_DAYS=7

# åº”ç”¨é…ç½®
ENVIRONMENT=development
DEBUG=True
API_V1_STR=/api/v1
PROJECT_NAME=AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å°
PROJECT_DESCRIPTION=åŸºäºaidev3çš„AIæ ‡ä¹¦åˆ›ä½œå¹³å°

# æ–‡ä»¶å­˜å‚¨é…ç½®
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET=minioadmin
MINIO_DEFAULT_BUCKETS=aibidcomposer-dev
UPLOAD_PATH=/app/uploads
MAX_FILE_SIZE=100MB

# é‚®ä»¶é…ç½®
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password
EMAIL_FROM_EMAIL=noreply@aibidcomposer.dev
EMAIL_FROM_NAME=AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å°

# ç›‘æ§é…ç½®
SENTRY_DSN=https://your-sentry-dsn
LOG_LEVEL=INFO
ENVIRONMENT=development

# å¼€å‘å·¥å…·é…ç½®
NODE_ENV=development
REACT_APP_ENVIRONMENT=development
VITE_DEV=true
```

### ç”Ÿäº§ç¯å¢ƒå˜é‡
```yaml
# .env.production - ç”Ÿäº§ç¯å¢ƒå˜é‡
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://aibidcomposer:prod_password@postgres:5432/aibidcomposer_prod
REDIS_URL=redis://redis:6379/1

# AIæœåŠ¡é…ç½®
OPENAI_API_KEY=your-openai-production-key
OPENAI_MODEL=gpt-4
ZHIPUAI_API_KEY=your-zhipu-production-key
PINECONE_API_KEY=your-pinecone-production-key

# JWTé…ç½®
SECRET_KEY=your-secret-production-key
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# åº”ç”¨é…ç½®
ENVIRONMENT=production
DEBUG=False
API_V1_STR=/api/v1
PROJECT_NAME=AIæ ‡ä¹¦æ™ºèƒ½åˆ›ä½œå¹³å°
PROJECT_DESCRIPTION=ä¼ä¸šçº§AIæ ‡ä¹¦åˆ›ä½œå¹³å°

# å®‰å…¨é…ç½®
CORS_ORIGINS=https://app.aibidcomposer.com
ALLOWED_CREDENTIALS_FROM_ORIGINS=https://app.aibidcomposer.com
CORS_ALLOWED_ORIGINS=app.aibidcomposer.com
CORS_ALLOW_CREDENTIALS=true

# æ–‡ä»¶å­˜å‚¨é…ç½®
MINIO_ENDPOINT=minio.aibidcomposer.com
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET=minioadmin
MINIO_DEFAULT_BUCKETS=aibidcomposer-prod
UPLOAD_PATH=/app/uploads
MAX_FILE_SIZE=100MB
SSL_ENABLED=true

# ç›‘æ§é…ç½®
SENTRY_DSN=https://your-sentry-dsn
LOG_LEVEL=WARNING
ENVIRONMENT=production

# æ€§èƒ½é…ç½®
WORKERS_PER_POOL=4
MAX_REQUEST_SIZE=1000
MAX_REQUEST_TIMEOUT=30000
MAX_CONCURRENT_REQUESTS=100
CACHE_TYPE=redis
```

### æµ‹è¯•ç¯å¢ƒå˜é‡
```yaml
# .env.test - æµ‹è¯•ç¯å¢ƒå˜é‡
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://aibidcomposer:test_password@localhost:5432/aibidcomposer_test
REDIS_URL=redis://localhost:6379/2

# AIæœåŠ¡é…ç½®
OPENAI_API_KEY=test-key
OPENAI_MODEL=gpt-3.5-turbo
ZHIPUAI_API_KEY=test-key
PINECONE_API_KEY=test-key

# JWTé…ç½®
SECRET_KEY=test-secret-key
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# åº”ç”¨é…ç½®
ENVIRONMENT=test
DEBUG=True
API_V1_STR=/api/v1
PROJECT_NAME=AIæ ‡ä¹¦æµ‹è¯•å¹³å°
PROJECT_DESCRIPTION=AIæ ‡ä¹¦åˆ›ä½œå¹³å°æµ‹è¯•ç¯å¢ƒ

# æµ‹è¯•æ•°æ®
TEST_DATABASE_URL=postgresql+asyncpg://test:test_user:test_password@localhost:5432/aibidcomposer_test
TEST_REDIS_URL=redis://localhost:6379/2
TEST_EMAIL_FROM=test@aibidcomposer.test

# æµ‹è¯•å·¥å…·
TEST_MAIL_ENABLED=false
TEST_PAYMENT_ENABLED=false
TEST_AI_API_RATE_LIMIT=100
TEST_CACHE_TTL=60
```

## ğŸ” ç‰ˆæœ¬æ§åˆ¶å’Œå‘å¸ƒ

### Gitå·¥ä½œæµ
```bash
# .git/workflow/feature-branch.yml - åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ
name: Feature Branch Workflow
on:
  create:
    branches: 'feature/*'
    tags: v*
  pull_request:
    branches:
      - main
      - develop
  push:
    branches:
      - feature/*
      - develop
      - main
    tags:
      - v*
      - release/*

  jobs:
    test-frontend:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v3
        - name: Checkout code
        - name: Setup Node.js
          uses: actions/setup-node@v3
          with:
            node-version: '18'
        - name: Install dependencies
          run: npm ci
        - name: Run tests
          run: npm run test
        - name: Check coverage
          run: npm run test:cov
        - name: Upload coverage
          uses: codecov/codecov-action@v3
          with:
            token: ${{ secrets.CODECOV_TOKEN }}
          with:
            files: ./coverage/lcov.info
            flags: --flags
            verbose: true
            -f coverage/
            -t coverage/
            -c -f lcov.info

    test-backend:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v3
        - name: Setup Python
          uses: actions/setup-python@v4
          with:
            python-version: '3.11'
        - name: Install dependencies
          run: pip install -r requirements.txt
        - name: Run tests
          run: pytest server/tests/ -v --cov=tests/
        - name: Upload coverage
          uses: codecov/codecov-action@v3
          with:
            token: ${{ secrets.CODECOV_TOKEN }}
          with:
            files: ./coverage/lcov.info
            flags: --flags
            verbose: true
            -f coverage/
            -c -f lcov.info

    build:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v3
        name: Build application
        run: |
          docker-compose build
          docker build -t aibidcomposer:${GITHUB_SHA}
        - name: Save artifacts
          uses: actions/upload-artifact@v3
          with:
          name: docker-images
          path: aibidcomposer.tar
          retention-days: 30
          path-matcher:
            - Dockerfile*
            - docker-compose*.yml
            - .dockerignore

    deploy-staging:
      needs: [build]
      runs-on: ubuntu-latest
      environment:
        - FRONTEND_URL: https://staging.aibidcomposer.com
        - BACKEND_URL: https://api-staging.aibidcomposer.com
        - DATABASE_URL=postgresql://staging-db:staging_password@staging-db:5432/aibidcomposer
        - REDIS_URL=redis://staging-redis:6379/1
      steps:
        - uses: docker-compose pull
          with:
          compose-file: docker-compose.staging.yml
          services: ['api', 'postgres', 'redis', 'minio']
        - uses: docker-compose up -d
          with:
            compose-file: docker-compose.staging.yml
      timeout: 300

    deploy-production:
      needs: [build]
      runs-on: ubuntu-latest
      environment:
        - FRONTEND_URL: https://app.aibidcomposer.com
        - BACKEND_URL: https://api.aibidcomposer.com
        - DATABASE_URL=postgresql://prod:aibidcomposer:prod_password@prod-db:5432/aibidcomposer
        - REDIS_URL=redis://prod-redis:6379/0
      steps:
        - uses: docker pull
          with:
            compose-file: docker-compose.prod.yml
            services: ['api', 'postgres', 'redis', 'minio']
        - uses: docker-compose up -d
          with:
            compose-file: docker-compose.prod.yml
        - timeout: 300
```

### ç‰ˆæœ¬æ ‡ç­¾ç­–ç•¥
```yaml
ç‰ˆæœ¬æ ‡ç­¾è§„åˆ™:
  ä¸»åˆ†æ”¯ (main):
    - ç‰ˆæœ¬å·: v1.0.0, v1.1.0, v1.2.0
    - æ ‡ç­¾æ ¼å¼: v{major}.{minor}.{patch}

  å¼€å‘åˆ†æ”¯ (develop):
    - ç‰ˆæœ¬å·: develop-{date}
    - ç¤ºä¾‹: develop-20251114

  åŠŸèƒ½åˆ†æ”¯ (feature/*):
    - ç‰ˆæœ¬å·: feature-{feature-name}-{date}
    - ç¤ºä¾‹: feature-document-parser-20251114

  çƒ­ä¿®åˆ†æ”¯ (hotfix/*):
    - ç‰ˆæœ¬å·: hotfix-{issue-number}-{date}
    - ç¤ºä¾‹: hotfix-security-fix-20251114

  å‘å¸ƒæ ‡ç­¾:
    - æ ‡ç­¾æ ¼å¼: v{major}.{minor}.{patch}
    - ç¤ºä¾‹: v1.0.0, v1.1.0, v2.0.0
    - å‘å¸ƒè¯´æ˜: ä¸»ç‰ˆæœ¬å·.æ¬¡ç‰ˆæœ¬å·.è¡¥ä¸å·

  é¢„å‘å¸ƒæ ‡ç­¾:
    - æ ‡ç­¾æ ¼å¼: v{major}.{minor}.{patch}-rc{number}
    - ç¤ºä¾‹: v1.0.0-rc1, v1.1.0-rc2
    - å‘å¸ƒè¯´æ˜: ä¸»ç‰ˆæœ¬.æ¬¡ç‰ˆæœ¬å·.å‘å¸ƒå€™é€‰
```

### å‘å¸ƒæµç¨‹
```yaml
å‘å¸ƒæ£€æŸ¥æ¸…å•:
   - ä»£ç å®¡æŸ¥é€šè¿‡
  - æ‰€æœ‰æµ‹è¯•é€šè¿‡
  - æ–‡æ¡£æ›´æ–°å®Œæˆ
  - å®‰å…¨æ‰«æé€šè¿‡
  - æ€§èƒ½æµ‹è¯•é€šè¿‡
  - ç”¨æˆ·éªŒæ”¶é€šè¿‡
  - å¤‡ä»½å®Œæˆ

  å‘å¸ƒæ­¥éª¤:
   1. ä»£ç åˆå¹¶åˆ°ä¸»åˆ†æ”¯
  2. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
 3. åˆ›å»ºå‘å¸ƒæ ‡ç­¾
  4. æ„å»ºDockeré•œåƒ
 5. éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
 6. ç”¨æˆ·éªŒæ”¶æµ‹è¯•
 7. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
  8. å‘å¸ƒç‰ˆæœ¬è¯´æ˜

  å›æ»šç­–ç•¥:
  - è‡ªåŠ¨å›æ»š: å¦‚æœå¥åº·æ£€æŸ¥å¤±è´¥ï¼Œè‡ªåŠ¨å›æ»š
  - æ‰‹åŠ¨å›æ»š: é€šè¿‡Git revertå‘½ä»¤
  - ç´§æ€¥ä¿®å¤: ä½¿ç”¨hotfixåˆ†æ”¯å¿«é€Ÿä¿®å¤
  - ç‰ˆæœ¬å›é€€: å›æ»šåˆ°ç¨³å®šç‰ˆæœ¬

  å‘å¸ƒé€šçŸ¥:
  - å›¢é˜Ÿé€šçŸ¥: å‘å¸ƒå‰é€šçŸ¥ç›¸å…³äººå‘˜
  - å®¢æˆ·é€šçŸ¥: å‘å¸ƒåé€šçŸ¥ç”¨æˆ·
  - ç›‘æ§å‘Š: å‘å¸ƒåå‘é€ç›‘æ§æŠ¥å‘Š
  - å‘å¸ƒæ€»ç»“: å‘å¸ƒå®Œæˆå‘é€æ€»ç»“
```
```yaml
# è¯¦ç»†çš„å¼€å‘ç¯å¢ƒé…ç½®æŒ‡å—å·²å®Œæˆï¼ŒåŒ…å«ï¼š
  - å®Œæ•´çš„ä¾èµ–é…ç½®ï¼ˆå‰ç«¯ã€åç«¯ã€æ•°æ®åº“ã€ç¼“å­˜ï¼‰
  - å¼€å‘å·¥å…·é…ç½®ï¼ˆVS Codeã€PyCharmç­‰ï¼‰
  - Dockeré…ç½®ï¼ˆå¤šæœåŠ¡Docker Composeï¼‰
  - CI/CDé…ç½®ï¼ˆGitHub Actionsã€GitLab CI/CDï¼‰
  - ç›‘æ§å’Œæ—¥å¿—é…ç½®
  - ç¯å¢ƒå˜é‡ç®¡ç†ï¼ˆå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ï¼‰
  - ç‰ˆæœ¬æ§åˆ¶å’Œå‘å¸ƒæµç¨‹
  - è´¨é‡ä¿è¯å·¥å…·é…ç½®
  - æ€§èƒ½ç›‘æ§å’Œè°ƒè¯•é…ç½®

è¿™ä»½é…ç½®æŒ‡å—ä¸ºå¼€å‘å›¢é˜Ÿæä¾›äº†è¯¦ç»†çš„ç¯å¢ƒæ­å»ºæŒ‡å—ï¼Œç¡®ä¿å¼€å‘ç¯å¢ƒçš„ä¸€è‡´æ€§å’Œç¨³å®šæ€§ã€‚
TodoWrite
<arg_key>todos</arg_key>
<arg_value>[{"content": "å¢åŠ è¯¦ç»†çš„å¼€å‘ç¯å¢ƒé…ç½®æŒ‡å—", "status": "completed", "activeForm": "å¢åŠ è¯¦ç»†çš„å¼€å‘ç¯å¢ƒé…ç½®æŒ‡å—"}, {"content": "å®Œå–„æ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤æ–¹æ¡ˆ", "status": "pending", "activeForm": "å®Œå–„æ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤æ–¹æ¡ˆ"}, {"content": "åˆ¶å®šè¯¦ç»†çš„è¿è¥æµç¨‹å’ŒæœåŠ¡æ ‡å‡†", "status": "pending", "activeForm": "åˆ¶å®šè¯¦ç»†çš„è¿è¥æµç¨‹å’ŒæœåŠ¡æ ‡å‡†"}, {"content": "è®¾è®¡å›½é™…åŒ–æ‰©å±•æ–¹æ¡ˆ", "status": "pending", "activeForm": "è®¾è®¡å›½é™…åŒ–æ‰©å±•æ–¹æ¡ˆ"}, {"content": "åˆ›å»ºç”¨æˆ·æ‰‹å†Œå’ŒåŸ¹è®­ææ–™å¤§çº²", "status": "pending", "activeForm": "åˆ›å»ºç”¨æˆ·æ‰‹å†Œå’ŒåŸ¹è®­ææ–™å¤§çº²"}]