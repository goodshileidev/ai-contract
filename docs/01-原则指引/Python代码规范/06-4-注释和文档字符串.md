---
文档类型: 知识库文档
需求编号: DOC-2025-11-004
创建日期: 2025-11-26
创建者: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
最后更新: 2025-11-26
更新者: claude-sonnet-4-5 (claude-sonnet-4-5-20250929)
状态: 已批准
---

# Python 代码规范 - 4. 注释和文档字符串

### 4.1 文档字符串（Docstrings）

**使用 Google 风格的文档字符串**：

```python
def analyze_document(
    doc_id: str,
    include_metadata: bool = True,
    max_chunks: int = 100
) -> dict:
    """分析文档并提取关键信息

    使用 LlamaIndex 对文档进行语义分析，提取关键信息和元数据。

    需求编号: REQ-AI-001

    Args:
        doc_id: 文档ID，必须是有效的UUID格式
        include_metadata: 是否包含元数据，默认为True
        max_chunks: 最大处理的文档块数，默认100

    Returns:
        包含分析结果的字典，格式如下：
        {
            "summary": str,      # 文档摘要
            "keywords": List[str],  # 关键词列表
            "entities": List[dict],  # 实体列表
        }

    Raises:
        ValueError: 当 doc_id 格式无效时
        DocumentNotFoundError: 当文档不存在时
        AIServiceError: 当AI服务调用失败时

    Example:
        >>> result = analyze_document("123e4567-e89b-12d3-a456-426614174000")
        >>> print(result["summary"])
        "这是一份招标文件..."
    """
    pass
```

**类的文档字符串**：
```python
class DocumentParser:
    """文档解析器，支持多种格式的文档解析

    该类负责解析 PDF、Word、Excel 等格式的文档，
    并提取结构化的文本内容。

    需求编号: REQ-AI-001
    实现日期: 2025-11-26

    Attributes:
        supported_formats: 支持的文件格式列表
        max_file_size: 最大文件大小（字节）

    Example:
        >>> parser = DocumentParser()
        >>> content = parser.parse_file("document.pdf")
        >>> print(content["text"])
    """

    def __init__(self, max_file_size: int = 10 * 1024 * 1024):
        """初始化文档解析器

        Args:
            max_file_size: 最大文件大小，默认10MB
        """
        self.max_file_size = max_file_size
        self.supported_formats = ["pdf", "docx", "xlsx"]
```

### 4.2 注释

```python
def process_bid_document(doc_id: str) -> dict:
    """处理招标文档"""

    # 1. 从数据库获取文档
    document = get_document_from_db(doc_id)

    # 2. 验证文档格式
    if not is_valid_format(document.format):
        raise ValueError(f"不支持的文档格式: {document.format}")

    # 3. 解析文档内容
    # 使用 PDF 解析器提取文本和表格
    parsed_content = parse_pdf_content(document.file_path)

    # 4. 向量化文档
    # TODO: 优化向量化性能，考虑批处理
    embeddings = vectorize_content(parsed_content)

    # 5. 存储到 Elasticsearch
    store_in_elasticsearch(doc_id, embeddings)

    return {
        "status": "success",
        "chunks_count": len(embeddings),
    }
```

**注释最佳实践**：
```python
# ✅ 好的注释：解释"为什么"
# 使用指数退避策略避免API限流
await asyncio.sleep(2 ** retry_count)

# ✅ 好的注释：解释复杂逻辑
# 计算加权平均分：技术分(60%) + 商务分(30%) + 经验分(10%)
total_score = tech_score * 0.6 + business_score * 0.3 + exp_score * 0.1

# ❌ 坏的注释：重复代码内容
# 设置 name 为 "John"
name = "John"

# ❌ 坏的注释：过时的注释
# 使用 MySQL 数据库
engine = create_engine("postgresql://...")  # ❌ 注释过时
```

---
