---
文档类型: 实现文档
需求编号: REQ-2025-11-008
创建日期: 2025-11-30 13:10
创建者: claude-opus-4-1-20250805
最后更新: 2025-11-30 13:10
更新者: claude-opus-4-1-20250805
状态: 草稿
---

# 质量保障算法 - Python实现代码

本文档包含质量保障算法的完整Python实现代码，用于对生成的标书内容进行全方位的质量检查和优化。

## 1. 导入依赖

```python
import hashlib
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sentence_transformers import SentenceTransformer
import jieba
import jieba.analyse
import re
import json
import logging
from datetime import datetime
from collections import defaultdict
import difflib
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
```

## 2. 数据模型定义

```python
@dataclass
class PlagiarismResult:
    """查重结果"""
    similarity_rate: float
    similar_segments: List[Dict[str, Any]]
    original_fingerprint: str
    check_method: str
    timestamp: str

@dataclass
class ComplianceResult:
    """合规性检查结果"""
    compliance_score: float
    violations: List[Dict[str, Any]]
    warnings: List[Dict[str, Any]]
    mandatory_items: List[Dict[str, Any]]
    check_details: Dict[str, Any]

@dataclass
class CompletenessResult:
    """完整性检查结果"""
    completeness_score: float
    missing_sections: List[str]
    coverage_rate: float
    content_distribution: Dict[str, float]
    suggestions: List[str]

@dataclass
class RiskAssessment:
    """风险评估结果"""
    risk_score: float
    high_risks: List[Dict[str, Any]]
    medium_risks: List[Dict[str, Any]]
    low_risks: List[Dict[str, Any]]
    mitigation_strategies: List[Dict[str, Any]]

@dataclass
class QualityReport:
    """综合质量报告"""
    overall_score: float
    plagiarism_result: PlagiarismResult
    compliance_result: ComplianceResult
    completeness_result: CompletenessResult
    risk_assessment: RiskAssessment
    improvement_suggestions: List[Dict[str, Any]]
    quality_grade: str
```

## 3. 深度查重引擎

```python
class DeepPlagiarismChecker:
    """深度查重引擎"""

    def __init__(self):
        self.semantic_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=3000,
            ngram_range=(1, 3)
        )
        self.logger = logging.getLogger(__name__)

        # 查重阈值配置
        self.thresholds = {
            'text_similarity': 0.7,
            'semantic_similarity': 0.85,
            'structure_similarity': 0.8,
            'keyword_density': 0.6
        }

    def check_plagiarism(self,
                        document: str,
                        reference_docs: List[str],
                        check_level: str = 'comprehensive') -> PlagiarismResult:
        """
        执行查重检查

        Args:
            document: 待检查文档
            reference_docs: 参考文档列表
            check_level: 检查级别 (quick/standard/comprehensive)

        Returns:
            查重结果
        """
        try:
            # 1. 文本预处理
            processed_doc = self._preprocess_text(document)
            processed_refs = [self._preprocess_text(ref) for ref in reference_docs]

            # 2. 多维度相似度计算
            similarity_results = []

            if check_level in ['standard', 'comprehensive']:
                # 文本相似度
                text_sim = self._calculate_text_similarity(processed_doc, processed_refs)
                similarity_results.append(('text', text_sim))

            if check_level == 'comprehensive':
                # 语义相似度
                semantic_sim = self._calculate_semantic_similarity(document, reference_docs)
                similarity_results.append(('semantic', semantic_sim))

                # 结构相似度
                structure_sim = self._calculate_structure_similarity(document, reference_docs)
                similarity_results.append(('structure', structure_sim))

            # 3. 综合评分
            overall_similarity = self._calculate_overall_similarity(similarity_results)

            # 4. 识别相似片段
            similar_segments = self._identify_similar_segments(
                document, reference_docs, overall_similarity
            )

            # 5. 生成文档指纹
            doc_fingerprint = self._generate_fingerprint(document)

            return PlagiarismResult(
                similarity_rate=overall_similarity,
                similar_segments=similar_segments,
                original_fingerprint=doc_fingerprint,
                check_method=check_level,
                timestamp=datetime.now().isoformat()
            )

        except Exception as e:
            self.logger.error(f"查重检查失败: {str(e)}")
            raise PlagiarismCheckError(f"查重失败: {str(e)}")

    def _preprocess_text(self, text: str) -> str:
        """文本预处理"""
        # 去除特殊字符
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)
        # 转小写
        text = text.lower()
        # 去除多余空格
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def _calculate_text_similarity(self, doc: str, refs: List[str]) -> float:
        """计算文本相似度（使用SimHash）"""
        # 生成SimHash
        doc_hash = self._simhash(doc)

        max_similarity = 0
        for ref in refs:
            ref_hash = self._simhash(ref)
            # 计算海明距离
            distance = bin(doc_hash ^ ref_hash).count('1')
            similarity = 1 - (distance / 64.0)  # 假设64位hash
            max_similarity = max(max_similarity, similarity)

        return max_similarity

    def _simhash(self, text: str, hashbits: int = 64) -> int:
        """生成SimHash指纹"""
        # 分词
        tokens = jieba.cut(text)

        # 初始化向量
        v = [0] * hashbits

        for token in tokens:
            # 计算token的hash
            token_hash = int(hashlib.md5(token.encode()).hexdigest(), 16)

            for i in range(hashbits):
                bitmask = 1 << i
                if token_hash & bitmask:
                    v[i] += 1
                else:
                    v[i] -= 1

        # 生成最终的hash
        fingerprint = 0
        for i in range(hashbits):
            if v[i] >= 0:
                fingerprint |= 1 << i

        return fingerprint

    def _calculate_semantic_similarity(self, doc: str, refs: List[str]) -> float:
        """计算语义相似度（使用BERT）"""
        # 文档分段
        doc_segments = self._split_into_segments(doc)

        # 生成语义向量
        doc_embeddings = self.semantic_model.encode(doc_segments)

        max_similarity = 0
        for ref in refs:
            ref_segments = self._split_into_segments(ref)
            ref_embeddings = self.semantic_model.encode(ref_segments)

            # 计算余弦相似度
            similarities = cosine_similarity(doc_embeddings, ref_embeddings)
            avg_similarity = np.mean(np.max(similarities, axis=1))
            max_similarity = max(max_similarity, avg_similarity)

        return float(max_similarity)

    def _split_into_segments(self, text: str, max_length: int = 500) -> List[str]:
        """将文本分割成段落"""
        sentences = re.split(r'[。！？\n]', text)
        segments = []
        current_segment = ""

        for sentence in sentences:
            if len(current_segment) + len(sentence) <= max_length:
                current_segment += sentence + "。"
            else:
                if current_segment:
                    segments.append(current_segment)
                current_segment = sentence + "。"

        if current_segment:
            segments.append(current_segment)

        return segments

    def _calculate_structure_similarity(self, doc: str, refs: List[str]) -> float:
        """计算结构相似度"""
        doc_structure = self._extract_structure(doc)

        max_similarity = 0
        for ref in refs:
            ref_structure = self._extract_structure(ref)
            similarity = self._compare_structures(doc_structure, ref_structure)
            max_similarity = max(max_similarity, similarity)

        return max_similarity

    def _extract_structure(self, text: str) -> Dict[str, Any]:
        """提取文档结构"""
        structure = {
            'sections': [],
            'total_length': len(text),
            'paragraph_count': len(text.split('\n')),
            'heading_pattern': []
        }

        # 提取章节标题
        headings = re.findall(r'^#+\s+(.+)$', text, re.MULTILINE)
        structure['sections'] = headings

        # 提取标题层级模式
        heading_levels = re.findall(r'^(#+)\s+', text, re.MULTILINE)
        structure['heading_pattern'] = [len(h) for h in heading_levels]

        return structure

    def _compare_structures(self, struct1: Dict, struct2: Dict) -> float:
        """比较文档结构"""
        # 比较章节相似度
        sections_sim = self._sequence_similarity(struct1['sections'], struct2['sections'])

        # 比较标题层级模式
        pattern_sim = self._sequence_similarity(
            struct1['heading_pattern'],
            struct2['heading_pattern']
        )

        # 比较文档长度
        length_sim = 1 - abs(struct1['total_length'] - struct2['total_length']) / \
                     max(struct1['total_length'], struct2['total_length'])

        # 加权平均
        return 0.4 * sections_sim + 0.3 * pattern_sim + 0.3 * length_sim

    def _sequence_similarity(self, seq1: List, seq2: List) -> float:
        """计算序列相似度"""
        if not seq1 or not seq2:
            return 0.0

        # 使用difflib计算相似度
        matcher = difflib.SequenceMatcher(None, seq1, seq2)
        return matcher.ratio()

    def _calculate_overall_similarity(self, results: List[Tuple[str, float]]) -> float:
        """计算综合相似度"""
        if not results:
            return 0.0

        weights = {
            'text': 0.3,
            'semantic': 0.4,
            'structure': 0.3
        }

        weighted_sum = 0
        total_weight = 0

        for method, score in results:
            weight = weights.get(method, 0.25)
            weighted_sum += score * weight
            total_weight += weight

        return weighted_sum / total_weight if total_weight > 0 else 0

    def _identify_similar_segments(self,
                                  doc: str,
                                  refs: List[str],
                                  threshold: float) -> List[Dict[str, Any]]:
        """识别相似片段"""
        similar_segments = []
        doc_segments = self._split_into_segments(doc)

        for i, segment in enumerate(doc_segments):
            for j, ref in enumerate(refs):
                ref_segments = self._split_into_segments(ref)
                for k, ref_segment in enumerate(ref_segments):
                    similarity = self._calculate_segment_similarity(segment, ref_segment)
                    if similarity > threshold:
                        similar_segments.append({
                            'doc_segment_index': i,
                            'doc_segment': segment[:100] + "...",
                            'ref_doc_index': j,
                            'ref_segment_index': k,
                            'ref_segment': ref_segment[:100] + "...",
                            'similarity': similarity
                        })

        return similar_segments

    def _calculate_segment_similarity(self, seg1: str, seg2: str) -> float:
        """计算段落相似度"""
        # 使用TF-IDF和余弦相似度
        try:
            vectors = self.tfidf_vectorizer.fit_transform([seg1, seg2])
            similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0, 0]
            return float(similarity)
        except:
            return 0.0

    def _generate_fingerprint(self, text: str) -> str:
        """生成文档指纹"""
        hash_obj = hashlib.sha256(text.encode('utf-8'))
        return hash_obj.hexdigest()
```

## 4. 合规性检查器

```python
class ComplianceChecker:
    """合规性检查器"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.rule_patterns = self._load_rule_patterns()
        self.semantic_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

    def check_compliance(self,
                        document: Dict[str, Any],
                        requirements: Dict[str, Any]) -> ComplianceResult:
        """
        执行合规性检查

        Args:
            document: 标书文档
            requirements: 招标要求

        Returns:
            合规性检查结果
        """
        try:
            violations = []
            warnings = []
            mandatory_items = []

            # 1. 提取招标要求中的规则
            rules = self._extract_rules(requirements)

            # 2. 检查强制性要求
            mandatory_violations = self._check_mandatory_requirements(document, rules['mandatory'])
            violations.extend(mandatory_violations)

            # 3. 检查资质要求
            qualification_issues = self._check_qualifications(document, rules['qualifications'])
            violations.extend([q for q in qualification_issues if q['severity'] == 'high'])
            warnings.extend([q for q in qualification_issues if q['severity'] == 'medium'])

            # 4. 检查技术要求
            tech_issues = self._check_technical_requirements(document, rules['technical'])
            warnings.extend(tech_issues)

            # 5. 检查商务要求
            business_issues = self._check_business_requirements(document, rules['business'])
            warnings.extend(business_issues)

            # 6. 检查格式规范
            format_issues = self._check_format_requirements(document, rules.get('format', {}))
            warnings.extend(format_issues)

            # 7. 计算合规性得分
            compliance_score = self._calculate_compliance_score(violations, warnings)

            # 8. 生成强制性条款清单
            mandatory_items = self._generate_mandatory_checklist(document, rules['mandatory'])

            return ComplianceResult(
                compliance_score=compliance_score,
                violations=violations,
                warnings=warnings,
                mandatory_items=mandatory_items,
                check_details={
                    'total_rules': len(rules),
                    'checked_rules': len(violations) + len(warnings),
                    'pass_rate': compliance_score / 100
                }
            )

        except Exception as e:
            self.logger.error(f"合规性检查失败: {str(e)}")
            raise ComplianceCheckError(f"合规检查失败: {str(e)}")

    def _load_rule_patterns(self) -> Dict[str, List[str]]:
        """加载规则模式"""
        return {
            'mandatory_keywords': [
                '必须', '必需', '应当', '不得', '禁止',
                '强制', '务必', '严禁', '不允许', '必备'
            ],
            'qualification_keywords': [
                '资质', '证书', '认证', '资格', '等级',
                'ISO', 'CMMI', '许可证', '备案'
            ],
            'technical_keywords': [
                '技术要求', '性能指标', '参数', '规格',
                '标准', '接口', '协议', '兼容性'
            ],
            'business_keywords': [
                '报价', '价格', '付款', '交付', '工期',
                '保修', '质保', '服务', '培训'
            ]
        }

    def _extract_rules(self, requirements: Dict[str, Any]) -> Dict[str, List[Dict]]:
        """从招标要求中提取规则"""
        rules = {
            'mandatory': [],
            'qualifications': [],
            'technical': [],
            'business': [],
            'format': []
        }

        requirement_text = requirements.get('full_text', '')

        # 提取强制性要求
        for keyword in self.rule_patterns['mandatory_keywords']:
            if keyword in requirement_text:
                # 提取包含关键词的句子
                sentences = self._extract_sentences_with_keyword(requirement_text, keyword)
                for sent in sentences:
                    rules['mandatory'].append({
                        'text': sent,
                        'keyword': keyword,
                        'type': 'mandatory'
                    })

        # 提取资质要求
        for keyword in self.rule_patterns['qualification_keywords']:
            if keyword in requirement_text:
                sentences = self._extract_sentences_with_keyword(requirement_text, keyword)
                for sent in sentences:
                    rules['qualifications'].append({
                        'text': sent,
                        'keyword': keyword,
                        'type': 'qualification'
                    })

        # 类似地提取技术和商务要求
        # ...

        return rules

    def _extract_sentences_with_keyword(self, text: str, keyword: str) -> List[str]:
        """提取包含关键词的句子"""
        sentences = re.split(r'[。；]', text)
        matching_sentences = [sent for sent in sentences if keyword in sent]
        return matching_sentences

    def _check_mandatory_requirements(self,
                                     document: Dict[str, Any],
                                     mandatory_rules: List[Dict]) -> List[Dict[str, Any]]:
        """检查强制性要求"""
        violations = []
        doc_text = document.get('content', '')

        for rule in mandatory_rules:
            # 使用语义匹配检查是否响应了该要求
            if not self._is_requirement_addressed(doc_text, rule['text']):
                violations.append({
                    'type': 'mandatory_violation',
                    'rule': rule['text'],
                    'severity': 'high',
                    'consequence': '废标',
                    'suggestion': f"必须明确响应要求：{rule['text']}"
                })

        return violations

    def _is_requirement_addressed(self, doc_text: str, requirement: str) -> bool:
        """判断需求是否被响应"""
        # 使用语义相似度判断
        doc_embedding = self.semantic_model.encode([doc_text])
        req_embedding = self.semantic_model.encode([requirement])
        similarity = cosine_similarity(doc_embedding, req_embedding)[0, 0]

        # 如果相似度高于阈值，认为已响应
        return similarity > 0.7

    def _check_qualifications(self,
                             document: Dict[str, Any],
                             qualification_rules: List[Dict]) -> List[Dict[str, Any]]:
        """检查资质要求"""
        issues = []
        doc_qualifications = document.get('qualifications', [])

        for rule in qualification_rules:
            # 解析资质要求
            required_qual = self._parse_qualification_requirement(rule['text'])

            # 检查是否具备
            if not self._has_qualification(doc_qualifications, required_qual):
                issues.append({
                    'type': 'qualification_missing',
                    'rule': rule['text'],
                    'required': required_qual,
                    'severity': 'high' if '必须' in rule['text'] else 'medium',
                    'consequence': '废标' if '必须' in rule['text'] else '扣分',
                    'suggestion': f"需要补充资质：{required_qual}"
                })

        return issues

    def _parse_qualification_requirement(self, text: str) -> str:
        """解析资质要求"""
        # 使用正则提取资质名称
        patterns = [
            r'(ISO\d+)',
            r'(CMMI\d)',
            r'(\w+认证)',
            r'(\w+资质)',
            r'(\w+证书)'
        ]

        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1)

        return text

    def _has_qualification(self, doc_quals: List[str], required: str) -> bool:
        """检查是否具备资质"""
        for qual in doc_quals:
            if required.lower() in qual.lower():
                return True
        return False

    def _check_technical_requirements(self,
                                     document: Dict[str, Any],
                                     tech_rules: List[Dict]) -> List[Dict[str, Any]]:
        """检查技术要求"""
        warnings = []
        # 实现技术要求检查逻辑
        # ...
        return warnings

    def _check_business_requirements(self,
                                    document: Dict[str, Any],
                                    business_rules: List[Dict]) -> List[Dict[str, Any]]:
        """检查商务要求"""
        warnings = []
        # 实现商务要求检查逻辑
        # ...
        return warnings

    def _check_format_requirements(self,
                                  document: Dict[str, Any],
                                  format_rules: Dict) -> List[Dict[str, Any]]:
        """检查格式规范"""
        warnings = []

        # 检查页数限制
        if 'max_pages' in format_rules:
            if document.get('page_count', 0) > format_rules['max_pages']:
                warnings.append({
                    'type': 'format_violation',
                    'issue': '超过页数限制',
                    'severity': 'low',
                    'suggestion': f"控制在{format_rules['max_pages']}页以内"
                })

        return warnings

    def _calculate_compliance_score(self,
                                   violations: List[Dict],
                                   warnings: List[Dict]) -> float:
        """计算合规性得分"""
        # 基础分100分
        score = 100.0

        # 扣分规则
        for violation in violations:
            if violation['severity'] == 'high':
                score -= 10
            elif violation['severity'] == 'medium':
                score -= 5

        for warning in warnings:
            score -= 2

        return max(0, score)

    def _generate_mandatory_checklist(self,
                                     document: Dict[str, Any],
                                     mandatory_rules: List[Dict]) -> List[Dict[str, Any]]:
        """生成强制性条款清单"""
        checklist = []

        for rule in mandatory_rules:
            checklist.append({
                'requirement': rule['text'],
                'is_addressed': self._is_requirement_addressed(
                    document.get('content', ''),
                    rule['text']
                ),
                'location': self._find_response_location(
                    document.get('content', ''),
                    rule['text']
                )
            })

        return checklist

    def _find_response_location(self, doc_text: str, requirement: str) -> Optional[str]:
        """找到响应位置"""
        # 简化实现：返回章节标题
        # 实际应该实现更复杂的定位逻辑
        return "技术方案章节"
```

## 5. 完整性验证器

```python
class CompletenessValidator:
    """完整性验证器"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.required_sections = self._define_required_sections()

    def validate_completeness(self,
                             document: Dict[str, Any],
                             template: Optional[Dict[str, Any]] = None) -> CompletenessResult:
        """
        验证文档完整性

        Args:
            document: 标书文档
            template: 模板（可选）

        Returns:
            完整性检查结果
        """
        try:
            # 1. 检查必需章节
            missing_sections = self._check_required_sections(document)

            # 2. 计算内容覆盖率
            coverage_rate = self._calculate_coverage_rate(document, template)

            # 3. 分析内容分布
            content_distribution = self._analyze_content_distribution(document)

            # 4. 检查关键要素
            missing_elements = self._check_key_elements(document)

            # 5. 计算完整性得分
            completeness_score = self._calculate_completeness_score(
                missing_sections,
                missing_elements,
                coverage_rate,
                content_distribution
            )

            # 6. 生成补充建议
            suggestions = self._generate_suggestions(
                missing_sections,
                missing_elements,
                content_distribution
            )

            return CompletenessResult(
                completeness_score=completeness_score,
                missing_sections=missing_sections,
                coverage_rate=coverage_rate,
                content_distribution=content_distribution,
                suggestions=suggestions
            )

        except Exception as e:
            self.logger.error(f"完整性验证失败: {str(e)}")
            raise CompletenessCheckError(f"完整性验证失败: {str(e)}")

    def _define_required_sections(self) -> Dict[str, float]:
        """定义必需章节及其权重"""
        return {
            '技术方案': 0.30,
            '商务报价': 0.25,
            '项目团队': 0.20,
            '实施计划': 0.15,
            '售后服务': 0.10
        }

    def _check_required_sections(self, document: Dict[str, Any]) -> List[str]:
        """检查必需章节"""
        doc_sections = document.get('sections', {})
        missing = []

        for section in self.required_sections.keys():
            if section not in doc_sections or not doc_sections[section]:
                missing.append(section)

        return missing

    def _calculate_coverage_rate(self,
                                document: Dict[str, Any],
                                template: Optional[Dict[str, Any]]) -> float:
        """计算内容覆盖率"""
        if not template:
            # 如果没有模板，使用默认的内容要求
            expected_elements = self._get_default_elements()
        else:
            expected_elements = template.get('required_elements', [])

        doc_content = document.get('content', '')
        covered = 0

        for element in expected_elements:
            if self._is_element_covered(doc_content, element):
                covered += 1

        return covered / len(expected_elements) if expected_elements else 0

    def _get_default_elements(self) -> List[str]:
        """获取默认的内容要素"""
        return [
            '公司介绍', '项目理解', '技术方案', '实施方法',
            '项目团队', '项目经理', '技术人员', '质量保证',
            '进度计划', '里程碑', '交付物', '风险管理',
            '培训计划', '售后服务', '服务承诺', '商务报价'
        ]

    def _is_element_covered(self, content: str, element: str) -> bool:
        """判断要素是否被覆盖"""
        return element in content or any(
            synonym in content
            for synonym in self._get_synonyms(element)
        )

    def _get_synonyms(self, term: str) -> List[str]:
        """获取同义词"""
        synonyms_dict = {
            '公司介绍': ['企业简介', '公司简介', '企业概况'],
            '项目理解': ['需求理解', '需求分析', '项目分析'],
            '技术方案': ['技术解决方案', '解决方案', '技术架构'],
            '项目团队': ['人员配置', '团队组成', '项目组'],
            # ... 更多同义词
        }
        return synonyms_dict.get(term, [])

    def _analyze_content_distribution(self, document: Dict[str, Any]) -> Dict[str, float]:
        """分析内容分布"""
        sections = document.get('sections', {})
        total_length = sum(len(str(content)) for content in sections.values())

        distribution = {}
        for section, content in sections.items():
            if total_length > 0:
                distribution[section] = len(str(content)) / total_length
            else:
                distribution[section] = 0

        return distribution

    def _check_key_elements(self, document: Dict[str, Any]) -> List[str]:
        """检查关键要素"""
        missing_elements = []
        doc_content = document.get('content', '')

        # 检查必需的关键要素
        key_elements = [
            ('项目负责人', ['项目经理', '负责人', 'PM']),
            ('实施周期', ['工期', '时间', '进度']),
            ('质量保证', ['质量管理', 'QA', '质控']),
            ('价格', ['报价', '费用', '成本'])
        ]

        for element, keywords in key_elements:
            if not any(kw in doc_content for kw in keywords):
                missing_elements.append(element)

        return missing_elements

    def _calculate_completeness_score(self,
                                     missing_sections: List[str],
                                     missing_elements: List[str],
                                     coverage_rate: float,
                                     content_distribution: Dict[str, float]) -> float:
        """计算完整性得分"""
        # 基础分
        score = 100.0

        # 缺失章节扣分（每个章节根据权重扣分）
        for section in missing_sections:
            weight = self.required_sections.get(section, 0.1)
            score -= weight * 100

        # 缺失要素扣分（每个要素扣3分）
        score -= len(missing_elements) * 3

        # 覆盖率调整
        score *= coverage_rate

        # 内容分布均衡性调整
        distribution_balance = self._calculate_distribution_balance(content_distribution)
        score *= distribution_balance

        return max(0, min(100, score))

    def _calculate_distribution_balance(self, distribution: Dict[str, float]) -> float:
        """计算内容分布均衡性"""
        if not distribution:
            return 0

        expected = self.required_sections
        balance_score = 1.0

        for section, expected_weight in expected.items():
            actual_weight = distribution.get(section, 0)
            # 计算偏差
            deviation = abs(actual_weight - expected_weight) / expected_weight
            balance_score *= (1 - min(deviation, 0.5))

        return balance_score

    def _generate_suggestions(self,
                            missing_sections: List[str],
                            missing_elements: List[str],
                            content_distribution: Dict[str, float]) -> List[str]:
        """生成补充建议"""
        suggestions = []

        # 章节缺失建议
        if missing_sections:
            suggestions.append(
                f"建议补充以下章节：{', '.join(missing_sections)}"
            )

        # 要素缺失建议
        if missing_elements:
            suggestions.append(
                f"需要添加以下关键要素：{', '.join(missing_elements)}"
            )

        # 内容分布建议
        for section, weight in self.required_sections.items():
            actual = content_distribution.get(section, 0)
            if actual < weight * 0.7:  # 实际内容少于期望的70%
                suggestions.append(
                    f"建议增加'{section}'部分的内容，当前占比{actual:.1%}，建议占比{weight:.1%}"
                )

        return suggestions
```

## 6. 风险评估器

```python
class RiskAssessor:
    """风险评估器"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.risk_patterns = self._load_risk_patterns()

    def assess_risks(self,
                    document: Dict[str, Any],
                    requirements: Dict[str, Any]) -> RiskAssessment:
        """
        评估风险

        Args:
            document: 标书文档
            requirements: 招标要求

        Returns:
            风险评估结果
        """
        try:
            high_risks = []
            medium_risks = []
            low_risks = []

            # 1. 废标风险评估
            rejection_risks = self._assess_rejection_risks(document, requirements)
            high_risks.extend(rejection_risks)

            # 2. 扣分风险评估
            scoring_risks = self._assess_scoring_risks(document, requirements)
            medium_risks.extend(scoring_risks)

            # 3. 竞争力风险评估
            competitive_risks = self._assess_competitive_risks(document)
            low_risks.extend([r for r in competitive_risks if r['level'] == 'low'])
            medium_risks.extend([r for r in competitive_risks if r['level'] == 'medium'])

            # 4. 计算综合风险分数
            risk_score = self._calculate_risk_score(high_risks, medium_risks, low_risks)

            # 5. 生成缓解策略
            mitigation_strategies = self._generate_mitigation_strategies(
                high_risks, medium_risks, low_risks
            )

            return RiskAssessment(
                risk_score=risk_score,
                high_risks=high_risks,
                medium_risks=medium_risks,
                low_risks=low_risks,
                mitigation_strategies=mitigation_strategies
            )

        except Exception as e:
            self.logger.error(f"风险评估失败: {str(e)}")
            raise RiskAssessmentError(f"风险评估失败: {str(e)}")

    def _load_risk_patterns(self) -> Dict[str, List[str]]:
        """加载风险模式"""
        return {
            'rejection_keywords': [
                '废标', '否决', '不接受', '不符合', '无效'
            ],
            'mandatory_keywords': [
                '必须', '应当', '强制', '必需'
            ],
            'penalty_keywords': [
                '扣分', '减分', '处罚', '违约'
            ]
        }

    def _assess_rejection_risks(self,
                               document: Dict[str, Any],
                               requirements: Dict[str, Any]) -> List[Dict[str, Any]]:
        """评估废标风险"""
        risks = []

        # 检查实质性条款响应
        mandatory_clauses = self._extract_mandatory_clauses(requirements)
        for clause in mandatory_clauses:
            if not self._is_clause_responded(document, clause):
                risks.append({
                    'type': 'rejection_risk',
                    'issue': f"未响应实质性条款：{clause[:50]}...",
                    'level': 'high',
                    'probability': 0.9,
                    'impact': '废标',
                    'location': self._find_clause_location(clause)
                })

        # 检查资质符合性
        qualification_risks = self._check_qualification_risks(document, requirements)
        risks.extend(qualification_risks)

        return risks

    def _extract_mandatory_clauses(self, requirements: Dict[str, Any]) -> List[str]:
        """提取实质性条款"""
        clauses = []
        req_text = requirements.get('full_text', '')

        for keyword in self.risk_patterns['mandatory_keywords']:
            sentences = re.findall(f'[^。]*{keyword}[^。]*。', req_text)
            clauses.extend(sentences)

        return clauses

    def _is_clause_responded(self, document: Dict[str, Any], clause: str) -> bool:
        """判断条款是否被响应"""
        doc_content = document.get('content', '')
        # 简化判断：检查关键词是否出现
        keywords = jieba.analyse.extract_tags(clause, topK=3)
        return all(kw in doc_content for kw in keywords)

    def _find_clause_location(self, clause: str) -> str:
        """定位条款位置"""
        # 简化实现
        return "招标文件第X章第Y节"

    def _check_qualification_risks(self,
                                  document: Dict[str, Any],
                                  requirements: Dict[str, Any]) -> List[Dict[str, Any]]:
        """检查资质风险"""
        risks = []
        # 实现资质风险检查逻辑
        # ...
        return risks

    def _assess_scoring_risks(self,
                            document: Dict[str, Any],
                            requirements: Dict[str, Any]) -> List[Dict[str, Any]]:
        """评估扣分风险"""
        risks = []

        # 技术方案薄弱
        tech_score = self._evaluate_technical_strength(document)
        if tech_score < 0.6:
            risks.append({
                'type': 'scoring_risk',
                'issue': '技术方案描述不够详细',
                'level': 'medium',
                'probability': 0.7,
                'impact': '扣5-10分',
                'suggestion': '增强技术方案的深度和细节'
            })

        # 案例相关性
        case_relevance = self._evaluate_case_relevance(document, requirements)
        if case_relevance < 0.5:
            risks.append({
                'type': 'scoring_risk',
                'issue': '项目案例相关性不足',
                'level': 'medium',
                'probability': 0.6,
                'impact': '扣3-5分',
                'suggestion': '选择更相关的项目案例'
            })

        return risks

    def _evaluate_technical_strength(self, document: Dict[str, Any]) -> float:
        """评估技术方案强度"""
        tech_section = document.get('sections', {}).get('技术方案', '')

        # 简化评估：基于内容长度和关键词密度
        length_score = min(len(tech_section) / 5000, 1.0)

        tech_keywords = ['架构', '算法', '性能', '安全', '可靠性', '扩展性']
        keyword_count = sum(1 for kw in tech_keywords if kw in tech_section)
        keyword_score = keyword_count / len(tech_keywords)

        return 0.6 * length_score + 0.4 * keyword_score

    def _evaluate_case_relevance(self,
                                document: Dict[str, Any],
                                requirements: Dict[str, Any]) -> float:
        """评估案例相关性"""
        # 简化实现
        return 0.7

    def _assess_competitive_risks(self, document: Dict[str, Any]) -> List[Dict[str, Any]]:
        """评估竞争力风险"""
        risks = []

        # 价格竞争力
        price_competitiveness = self._evaluate_price_competitiveness(document)
        if price_competitiveness < 0.5:
            risks.append({
                'type': 'competitive_risk',
                'issue': '报价可能缺乏竞争力',
                'level': 'low',
                'probability': 0.5,
                'impact': '影响中标概率',
                'suggestion': '重新评估定价策略'
            })

        return risks

    def _evaluate_price_competitiveness(self, document: Dict[str, Any]) -> float:
        """评估价格竞争力"""
        # 简化实现
        return 0.6

    def _calculate_risk_score(self,
                            high_risks: List[Dict],
                            medium_risks: List[Dict],
                            low_risks: List[Dict]) -> float:
        """计算风险分数"""
        # 风险权重
        high_weight = 0.5
        medium_weight = 0.3
        low_weight = 0.2

        # 基础分100，根据风险扣分
        score = 100

        score -= len(high_risks) * 15 * high_weight
        score -= len(medium_risks) * 10 * medium_weight
        score -= len(low_risks) * 5 * low_weight

        return max(0, score)

    def _generate_mitigation_strategies(self,
                                       high_risks: List[Dict],
                                       medium_risks: List[Dict],
                                       low_risks: List[Dict]) -> List[Dict[str, Any]]:
        """生成缓解策略"""
        strategies = []

        # 高风险缓解策略
        if high_risks:
            strategies.append({
                'priority': 'critical',
                'action': '立即处理高风险项',
                'items': [
                    {
                        'risk': risk['issue'],
                        'mitigation': risk.get('suggestion', '请专家审核')
                    }
                    for risk in high_risks[:3]
                ],
                'timeline': '立即'
            })

        # 中风险缓解策略
        if medium_risks:
            strategies.append({
                'priority': 'high',
                'action': '优化中风险项',
                'items': [
                    {
                        'risk': risk['issue'],
                        'mitigation': risk.get('suggestion', '建议改进')
                    }
                    for risk in medium_risks[:3]
                ],
                'timeline': '1-2小时内'
            })

        return strategies
```

## 7. 质量优化器

```python
class QualityOptimizer:
    """质量优化器"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def optimize_document(self,
                         document: Dict[str, Any],
                         quality_report: QualityReport) -> Dict[str, Any]:
        """
        优化文档质量

        Args:
            document: 原始文档
            quality_report: 质量报告

        Returns:
            优化后的文档
        """
        optimized_doc = document.copy()

        # 根据质量分数决定优化策略
        if quality_report.overall_score < 60:
            optimized_doc = self._major_revision(optimized_doc, quality_report)
        elif quality_report.overall_score < 80:
            optimized_doc = self._moderate_optimization(optimized_doc, quality_report)
        else:
            optimized_doc = self._minor_polishing(optimized_doc, quality_report)

        return optimized_doc

    def _major_revision(self,
                       document: Dict[str, Any],
                       report: QualityReport) -> Dict[str, Any]:
        """重大修订"""
        # 实现重大修订逻辑
        return document

    def _moderate_optimization(self,
                              document: Dict[str, Any],
                              report: QualityReport) -> Dict[str, Any]:
        """中度优化"""
        # 实现中度优化逻辑
        return document

    def _minor_polishing(self,
                        document: Dict[str, Any],
                        report: QualityReport) -> Dict[str, Any]:
        """细节润色"""
        # 实现细节润色逻辑
        return document
```

## 8. 主控制器

```python
class QualityAssuranceEngine:
    """质量保障引擎主控制器"""

    def __init__(self):
        self.plagiarism_checker = DeepPlagiarismChecker()
        self.compliance_checker = ComplianceChecker()
        self.completeness_validator = CompletenessValidator()
        self.risk_assessor = RiskAssessor()
        self.optimizer = QualityOptimizer()
        self.logger = logging.getLogger(__name__)

    async def check_quality(self,
                           document: Dict[str, Any],
                           requirements: Dict[str, Any],
                           reference_docs: List[str],
                           check_type: str = 'comprehensive') -> QualityReport:
        """
        执行全面的质量检查

        Args:
            document: 标书文档
            requirements: 招标要求
            reference_docs: 参考文档（用于查重）
            check_type: 检查类型

        Returns:
            质量报告
        """
        try:
            # 并行执行各项检查
            tasks = []

            # 查重检查
            tasks.append(self._async_plagiarism_check(document, reference_docs))

            # 合规性检查
            tasks.append(self._async_compliance_check(document, requirements))

            # 完整性检查
            tasks.append(self._async_completeness_check(document))

            # 风险评估
            tasks.append(self._async_risk_assessment(document, requirements))

            # 等待所有检查完成
            results = await asyncio.gather(*tasks)

            plagiarism_result = results[0]
            compliance_result = results[1]
            completeness_result = results[2]
            risk_assessment = results[3]

            # 计算综合质量分数
            overall_score = self._calculate_overall_score(
                plagiarism_result,
                compliance_result,
                completeness_result,
                risk_assessment
            )

            # 生成改进建议
            suggestions = self._generate_improvement_suggestions(
                plagiarism_result,
                compliance_result,
                completeness_result,
                risk_assessment
            )

            # 确定质量等级
            quality_grade = self._determine_quality_grade(overall_score)

            return QualityReport(
                overall_score=overall_score,
                plagiarism_result=plagiarism_result,
                compliance_result=compliance_result,
                completeness_result=completeness_result,
                risk_assessment=risk_assessment,
                improvement_suggestions=suggestions,
                quality_grade=quality_grade
            )

        except Exception as e:
            self.logger.error(f"质量检查失败: {str(e)}")
            raise QualityCheckError(f"质量检查失败: {str(e)}")

    async def _async_plagiarism_check(self, document: Dict, refs: List[str]) -> PlagiarismResult:
        """异步执行查重检查"""
        return await asyncio.to_thread(
            self.plagiarism_checker.check_plagiarism,
            document.get('content', ''),
            refs
        )

    async def _async_compliance_check(self, document: Dict, requirements: Dict) -> ComplianceResult:
        """异步执行合规性检查"""
        return await asyncio.to_thread(
            self.compliance_checker.check_compliance,
            document,
            requirements
        )

    async def _async_completeness_check(self, document: Dict) -> CompletenessResult:
        """异步执行完整性检查"""
        return await asyncio.to_thread(
            self.completeness_validator.validate_completeness,
            document
        )

    async def _async_risk_assessment(self, document: Dict, requirements: Dict) -> RiskAssessment:
        """异步执行风险评估"""
        return await asyncio.to_thread(
            self.risk_assessor.assess_risks,
            document,
            requirements
        )

    def _calculate_overall_score(self,
                                plagiarism: PlagiarismResult,
                                compliance: ComplianceResult,
                                completeness: CompletenessResult,
                                risk: RiskAssessment) -> float:
        """计算综合质量分数"""
        weights = {
            'plagiarism': 0.25,
            'compliance': 0.30,
            'completeness': 0.25,
            'risk': 0.20
        }

        # 查重得分（相似度越低越好）
        plagiarism_score = max(0, 100 * (1 - plagiarism.similarity_rate))

        # 各维度得分
        scores = {
            'plagiarism': plagiarism_score,
            'compliance': compliance.compliance_score,
            'completeness': completeness.completeness_score,
            'risk': risk.risk_score
        }

        # 加权计算
        overall = sum(scores[key] * weights[key] for key in weights)

        return overall

    def _generate_improvement_suggestions(self,
                                         plagiarism: PlagiarismResult,
                                         compliance: ComplianceResult,
                                         completeness: CompletenessResult,
                                         risk: RiskAssessment) -> List[Dict[str, Any]]:
        """生成改进建议"""
        suggestions = []

        # 查重建议
        if plagiarism.similarity_rate > 0.3:
            suggestions.append({
                'category': 'plagiarism',
                'priority': 'high',
                'suggestion': '降低内容相似度',
                'actions': ['重写相似段落', '增加原创内容', '调整表述方式']
            })

        # 合规建议
        if compliance.violations:
            suggestions.append({
                'category': 'compliance',
                'priority': 'critical',
                'suggestion': '修复合规性问题',
                'actions': [v['suggestion'] for v in compliance.violations[:3]]
            })

        # 完整性建议
        if completeness.missing_sections:
            suggestions.append({
                'category': 'completeness',
                'priority': 'high',
                'suggestion': '补充缺失内容',
                'actions': completeness.suggestions[:3]
            })

        # 风险建议
        if risk.high_risks:
            suggestions.append({
                'category': 'risk',
                'priority': 'critical',
                'suggestion': '处理高风险项',
                'actions': [s['items'][0]['mitigation']
                          for s in risk.mitigation_strategies
                          if s['priority'] == 'critical'][:3]
            })

        return suggestions

    def _determine_quality_grade(self, score: float) -> str:
        """确定质量等级"""
        if score >= 90:
            return '优秀'
        elif score >= 80:
            return '良好'
        elif score >= 70:
            return '合格'
        else:
            return '不合格'
```

## 9. 异常处理

```python
class QualityCheckError(Exception):
    """质量检查异常基类"""
    pass

class PlagiarismCheckError(QualityCheckError):
    """查重检查异常"""
    pass

class ComplianceCheckError(QualityCheckError):
    """合规性检查异常"""
    pass

class CompletenessCheckError(QualityCheckError):
    """完整性检查异常"""
    pass

class RiskAssessmentError(QualityCheckError):
    """风险评估异常"""
    pass
```

## 10. 使用示例

```python
async def main():
    """主程序入口"""
    # 初始化质量保障引擎
    qa_engine = QualityAssuranceEngine()

    # 示例数据
    document = {
        'content': '这是标书的完整内容...',
        'sections': {
            '技术方案': '详细的技术方案描述...',
            '商务报价': '报价明细...',
            '项目团队': '团队成员介绍...',
            '实施计划': '项目实施计划...',
            '售后服务': '售后服务承诺...'
        },
        'qualifications': ['ISO9001', 'CMMI3'],
        'page_count': 100
    }

    requirements = {
        'full_text': '招标文件的完整内容...',
        'mandatory_clauses': ['必须提供ISO认证', '必须有3年以上经验']
    }

    reference_docs = [
        '历史标书1的内容...',
        '历史标书2的内容...'
    ]

    # 执行质量检查
    try:
        quality_report = await qa_engine.check_quality(
            document=document,
            requirements=requirements,
            reference_docs=reference_docs,
            check_type='comprehensive'
        )

        # 输出结果
        print(f"=== 质量检查报告 ===")
        print(f"综合质量分数: {quality_report.overall_score:.2f}")
        print(f"质量等级: {quality_report.quality_grade}")
        print(f"查重相似度: {quality_report.plagiarism_result.similarity_rate:.2%}")
        print(f"合规性得分: {quality_report.compliance_result.compliance_score:.2f}")
        print(f"完整性得分: {quality_report.completeness_result.completeness_score:.2f}")
        print(f"风险评分: {quality_report.risk_assessment.risk_score:.2f}")

        print("\n=== 改进建议 ===")
        for suggestion in quality_report.improvement_suggestions:
            print(f"- [{suggestion['priority']}] {suggestion['suggestion']}")
            for action in suggestion['actions']:
                print(f"  • {action}")

    except QualityCheckError as e:
        print(f"质量检查失败: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 修改历史

| 日期 | 版本 | 修改者 | 修改内容概要 |
|------|------|--------|-------------|
| 2025-11-30 13:10 | 1.0 | claude-opus-4-1-20250805 | 创建质量保障算法实现代码 |