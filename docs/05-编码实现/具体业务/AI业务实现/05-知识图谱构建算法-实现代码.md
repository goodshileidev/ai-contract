---
文档类型: 实现文档
需求编号: REQ-2025-11-009
创建日期: 2025-11-30 13:25
创建者: claude-opus-4-1-20250805
最后更新: 2025-11-30 13:25
更新者: claude-opus-4-1-20250805
状态: 草稿
---

# 知识图谱构建算法 - Python实现代码

本文档包含知识图谱构建算法的完整Python实现代码，用于构建和管理企业能力知识图谱。

## 1. 导入依赖

```python
import json
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import hashlib
import uuid

# Neo4j数据库
from neo4j import GraphDatabase
from neo4j.exceptions import Neo4jError

# 自然语言处理
import jieba
import jieba.posseg as pseg
from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np

# 实体识别和关系抽取
from transformers import pipeline
import spacy

# 图算法
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity

# 向量数据库
from elasticsearch import Elasticsearch
import faiss

# 数据处理
import pandas as pd
from collections import defaultdict

# 异步处理
import asyncio
from concurrent.futures import ThreadPoolExecutor
```

## 2. 数据模型定义

```python
class NodeType(Enum):
    """节点类型枚举"""
    ORGANIZATION = "Organization"
    PROJECT = "Project"
    PERSON = "Person"
    PRODUCT = "Product"
    SERVICE = "Service"
    REQUIREMENT = "Requirement"
    CAPABILITY = "Capability"
    TECHNOLOGY = "Technology"
    CERTIFICATION = "Certification"

class RelationType(Enum):
    """关系类型枚举"""
    OWNS = "OWNS"
    PARTICIPATES = "PARTICIPATES"
    REQUIRES = "REQUIRES"
    PROVIDES = "PROVIDES"
    USES = "USES"
    BELONGS_TO = "BELONGS_TO"
    SIMILAR_TO = "SIMILAR_TO"
    DEPENDS_ON = "DEPENDS_ON"
    HAS_CERTIFICATION = "HAS_CERTIFICATION"
    WORKS_FOR = "WORKS_FOR"

@dataclass
class KnowledgeNode:
    """知识图谱节点"""
    node_id: str
    node_type: NodeType
    name: str
    properties: Dict[str, Any] = field(default_factory=dict)
    embeddings: Optional[np.ndarray] = None
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())

    def to_dict(self) -> Dict[str, Any]:
        """转换为字典"""
        return {
            'node_id': self.node_id,
            'node_type': self.node_type.value,
            'name': self.name,
            'properties': self.properties,
            'created_at': self.created_at,
            'updated_at': self.updated_at
        }

@dataclass
class KnowledgeRelation:
    """知识图谱关系"""
    relation_id: str
    relation_type: RelationType
    source_node_id: str
    target_node_id: str
    properties: Dict[str, Any] = field(default_factory=dict)
    confidence: float = 1.0
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())

    def to_dict(self) -> Dict[str, Any]:
        """转换为字典"""
        return {
            'relation_id': self.relation_id,
            'relation_type': self.relation_type.value,
            'source_node_id': self.source_node_id,
            'target_node_id': self.target_node_id,
            'properties': self.properties,
            'confidence': self.confidence,
            'created_at': self.created_at
        }

@dataclass
class KnowledgeGraph:
    """知识图谱"""
    graph_id: str
    nodes: List[KnowledgeNode] = field(default_factory=list)
    relations: List[KnowledgeRelation] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
```

## 3. 知识图谱构建引擎

```python
class KnowledgeGraphBuilder:
    """知识图谱构建引擎"""

    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str):
        self.driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        self.entity_extractor = EntityExtractor()
        self.relation_extractor = RelationExtractor()
        self.embedder = KnowledgeEmbedder()
        self.logger = logging.getLogger(__name__)

    def build_graph(self,
                   data_sources: List[Dict[str, Any]],
                   existing_graph: Optional[KnowledgeGraph] = None) -> KnowledgeGraph:
        """
        构建知识图谱

        Args:
            data_sources: 数据源列表
            existing_graph: 现有图谱（用于增量更新）

        Returns:
            知识图谱
        """
        try:
            # 1. 初始化图谱
            graph = existing_graph or KnowledgeGraph(graph_id=str(uuid.uuid4()))

            # 2. 从数据源提取实体
            entities = self._extract_entities_from_sources(data_sources)

            # 3. 实体消歧和对齐
            aligned_entities = self._align_entities(entities, graph.nodes)

            # 4. 创建节点
            new_nodes = self._create_nodes(aligned_entities)
            graph.nodes.extend(new_nodes)

            # 5. 提取关系
            relations = self._extract_relations(graph.nodes, data_sources)

            # 6. 创建关系边
            new_relations = self._create_relations(relations)
            graph.relations.extend(new_relations)

            # 7. 计算节点嵌入
            self._compute_embeddings(graph.nodes)

            # 8. 知识推理
            inferred_relations = self._infer_relations(graph)
            graph.relations.extend(inferred_relations)

            # 9. 存储到Neo4j
            self._save_to_neo4j(graph)

            # 10. 更新元数据
            graph.metadata['node_count'] = len(graph.nodes)
            graph.metadata['relation_count'] = len(graph.relations)
            graph.metadata['last_updated'] = datetime.now().isoformat()

            return graph

        except Exception as e:
            self.logger.error(f"知识图谱构建失败: {str(e)}")
            raise GraphBuildError(f"构建失败: {str(e)}")

    def _extract_entities_from_sources(self,
                                      data_sources: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """从数据源提取实体"""
        all_entities = []

        for source in data_sources:
            source_type = source.get('type')

            if source_type == 'structured':
                # 结构化数据直接映射
                entities = self._extract_from_structured(source['data'])
            elif source_type == 'text':
                # 非结构化文本提取
                entities = self.entity_extractor.extract(source['data'])
            elif source_type == 'document':
                # 文档提取
                entities = self._extract_from_document(source['data'])
            else:
                self.logger.warning(f"未知数据源类型: {source_type}")
                continue

            all_entities.extend(entities)

        return all_entities

    def _extract_from_structured(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """从结构化数据提取实体"""
        entities = []

        # 企业实体
        if 'organization' in data:
            org = data['organization']
            entities.append({
                'type': NodeType.ORGANIZATION,
                'name': org['name'],
                'properties': {
                    'industry': org.get('industry', ''),
                    'scale': org.get('scale', ''),
                    'location': org.get('location', '')
                }
            })

        # 项目实体
        if 'projects' in data:
            for project in data['projects']:
                entities.append({
                    'type': NodeType.PROJECT,
                    'name': project['name'],
                    'properties': {
                        'amount': project.get('amount', 0),
                        'start_date': project.get('start_date', ''),
                        'end_date': project.get('end_date', ''),
                        'status': project.get('status', '')
                    }
                })

        # 人员实体
        if 'personnel' in data:
            for person in data['personnel']:
                entities.append({
                    'type': NodeType.PERSON,
                    'name': person['name'],
                    'properties': {
                        'role': person.get('role', ''),
                        'experience': person.get('experience', ''),
                        'skills': person.get('skills', [])
                    }
                })

        return entities

    def _extract_from_document(self, document: Dict[str, Any]) -> List[Dict[str, Any]]:
        """从文档提取实体"""
        # 使用NER模型提取
        text = document.get('content', '')
        return self.entity_extractor.extract(text)

    def _align_entities(self,
                       new_entities: List[Dict[str, Any]],
                       existing_nodes: List[KnowledgeNode]) -> List[Dict[str, Any]]:
        """实体对齐和消歧"""
        aligned_entities = []

        for entity in new_entities:
            # 检查是否已存在相同实体
            is_duplicate = False

            for node in existing_nodes:
                similarity = self._calculate_entity_similarity(entity, node)
                if similarity > 0.85:  # 相似度阈值
                    # 合并属性
                    node.properties.update(entity.get('properties', {}))
                    node.updated_at = datetime.now().isoformat()
                    is_duplicate = True
                    break

            if not is_duplicate:
                aligned_entities.append(entity)

        return aligned_entities

    def _calculate_entity_similarity(self,
                                    entity: Dict[str, Any],
                                    node: KnowledgeNode) -> float:
        """计算实体相似度"""
        # 名称相似度
        name_sim = self._string_similarity(entity['name'], node.name)

        # 类型匹配
        type_match = 1.0 if entity['type'] == node.node_type else 0.0

        # 属性相似度
        prop_sim = self._property_similarity(
            entity.get('properties', {}),
            node.properties
        )

        # 加权平均
        return 0.5 * name_sim + 0.3 * type_match + 0.2 * prop_sim

    def _string_similarity(self, str1: str, str2: str) -> float:
        """字符串相似度"""
        # 使用Jaccard相似度
        set1 = set(str1)
        set2 = set(str2)
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        return intersection / union if union > 0 else 0

    def _property_similarity(self, props1: Dict, props2: Dict) -> float:
        """属性相似度"""
        if not props1 or not props2:
            return 0

        common_keys = set(props1.keys()) & set(props2.keys())
        if not common_keys:
            return 0

        matches = sum(1 for k in common_keys if props1[k] == props2[k])
        return matches / len(common_keys)

    def _create_nodes(self, entities: List[Dict[str, Any]]) -> List[KnowledgeNode]:
        """创建节点"""
        nodes = []

        for entity in entities:
            node = KnowledgeNode(
                node_id=self._generate_node_id(entity),
                node_type=entity['type'],
                name=entity['name'],
                properties=entity.get('properties', {})
            )
            nodes.append(node)

        return nodes

    def _generate_node_id(self, entity: Dict[str, Any]) -> str:
        """生成节点ID"""
        # 基于实体内容生成唯一ID
        content = f"{entity['type']}_{entity['name']}"
        hash_obj = hashlib.md5(content.encode())
        return hash_obj.hexdigest()[:16]

    def _extract_relations(self,
                          nodes: List[KnowledgeNode],
                          data_sources: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """提取关系"""
        relations = []

        # 从文本中提取关系
        for source in data_sources:
            if source.get('type') == 'text':
                text_relations = self.relation_extractor.extract(
                    source['data'],
                    nodes
                )
                relations.extend(text_relations)

        # 从结构化数据提取关系
        for source in data_sources:
            if source.get('type') == 'structured':
                struct_relations = self._extract_structured_relations(
                    source['data'],
                    nodes
                )
                relations.extend(struct_relations)

        return relations

    def _extract_structured_relations(self,
                                     data: Dict[str, Any],
                                     nodes: List[KnowledgeNode]) -> List[Dict[str, Any]]:
        """从结构化数据提取关系"""
        relations = []

        # 项目参与关系
        if 'project_participants' in data:
            for participant in data['project_participants']:
                source_id = self._find_node_id(nodes, participant['person'], NodeType.PERSON)
                target_id = self._find_node_id(nodes, participant['project'], NodeType.PROJECT)

                if source_id and target_id:
                    relations.append({
                        'type': RelationType.PARTICIPATES,
                        'source_id': source_id,
                        'target_id': target_id,
                        'properties': {
                            'role': participant.get('role', ''),
                            'duration': participant.get('duration', '')
                        }
                    })

        # 技术依赖关系
        if 'dependencies' in data:
            for dep in data['dependencies']:
                source_id = self._find_node_id(nodes, dep['source'], NodeType.TECHNOLOGY)
                target_id = self._find_node_id(nodes, dep['target'], NodeType.TECHNOLOGY)

                if source_id and target_id:
                    relations.append({
                        'type': RelationType.DEPENDS_ON,
                        'source_id': source_id,
                        'target_id': target_id,
                        'properties': {
                            'version': dep.get('version', ''),
                            'type': dep.get('dependency_type', '')
                        }
                    })

        return relations

    def _find_node_id(self,
                     nodes: List[KnowledgeNode],
                     name: str,
                     node_type: NodeType) -> Optional[str]:
        """查找节点ID"""
        for node in nodes:
            if node.name == name and node.node_type == node_type:
                return node.node_id
        return None

    def _create_relations(self, relation_data: List[Dict[str, Any]]) -> List[KnowledgeRelation]:
        """创建关系"""
        relations = []

        for data in relation_data:
            relation = KnowledgeRelation(
                relation_id=str(uuid.uuid4()),
                relation_type=data['type'],
                source_node_id=data['source_id'],
                target_node_id=data['target_id'],
                properties=data.get('properties', {}),
                confidence=data.get('confidence', 1.0)
            )
            relations.append(relation)

        return relations

    def _compute_embeddings(self, nodes: List[KnowledgeNode]) -> None:
        """计算节点嵌入"""
        for node in nodes:
            # 构建节点文本表示
            text = f"{node.name} {' '.join(str(v) for v in node.properties.values())}"

            # 计算嵌入向量
            node.embeddings = self.embedder.embed(text)

    def _infer_relations(self, graph: KnowledgeGraph) -> List[KnowledgeRelation]:
        """知识推理"""
        inferred_relations = []

        # 基于规则的推理
        rule_based = self._rule_based_inference(graph)
        inferred_relations.extend(rule_based)

        # 基于嵌入的推理
        embedding_based = self._embedding_based_inference(graph)
        inferred_relations.extend(embedding_based)

        # 基于路径的推理
        path_based = self._path_based_inference(graph)
        inferred_relations.extend(path_based)

        return inferred_relations

    def _rule_based_inference(self, graph: KnowledgeGraph) -> List[KnowledgeRelation]:
        """基于规则的推理"""
        inferred = []

        # 规则1: 传递性关系
        # 如果 A 属于 B，B 属于 C，则 A 属于 C
        belongs_to_relations = [
            r for r in graph.relations
            if r.relation_type == RelationType.BELONGS_TO
        ]

        for r1 in belongs_to_relations:
            for r2 in belongs_to_relations:
                if r1.target_node_id == r2.source_node_id:
                    # 检查是否已存在直接关系
                    exists = any(
                        r.source_node_id == r1.source_node_id and
                        r.target_node_id == r2.target_node_id
                        for r in graph.relations
                    )

                    if not exists:
                        inferred.append(KnowledgeRelation(
                            relation_id=str(uuid.uuid4()),
                            relation_type=RelationType.BELONGS_TO,
                            source_node_id=r1.source_node_id,
                            target_node_id=r2.target_node_id,
                            properties={'inferred': True, 'rule': 'transitivity'},
                            confidence=0.8
                        ))

        return inferred

    def _embedding_based_inference(self, graph: KnowledgeGraph) -> List[KnowledgeRelation]:
        """基于嵌入的推理"""
        inferred = []

        # 计算节点相似度
        nodes_with_embeddings = [n for n in graph.nodes if n.embeddings is not None]

        for i, node1 in enumerate(nodes_with_embeddings):
            for node2 in nodes_with_embeddings[i+1:]:
                # 计算余弦相似度
                similarity = cosine_similarity(
                    node1.embeddings.reshape(1, -1),
                    node2.embeddings.reshape(1, -1)
                )[0, 0]

                # 高相似度则推断相似关系
                if similarity > 0.85:
                    # 检查是否已存在关系
                    exists = any(
                        (r.source_node_id == node1.node_id and
                         r.target_node_id == node2.node_id) or
                        (r.source_node_id == node2.node_id and
                         r.target_node_id == node1.node_id)
                        for r in graph.relations
                    )

                    if not exists:
                        inferred.append(KnowledgeRelation(
                            relation_id=str(uuid.uuid4()),
                            relation_type=RelationType.SIMILAR_TO,
                            source_node_id=node1.node_id,
                            target_node_id=node2.node_id,
                            properties={
                                'inferred': True,
                                'method': 'embedding_similarity',
                                'similarity': float(similarity)
                            },
                            confidence=float(similarity)
                        ))

        return inferred

    def _path_based_inference(self, graph: KnowledgeGraph) -> List[KnowledgeRelation]:
        """基于路径的推理"""
        # 构建NetworkX图
        nx_graph = self._build_networkx_graph(graph)

        inferred = []

        # 寻找隐含关系
        for node1 in graph.nodes:
            for node2 in graph.nodes:
                if node1.node_id == node2.node_id:
                    continue

                # 检查是否存在路径但没有直接关系
                try:
                    path = nx.shortest_path(nx_graph, node1.node_id, node2.node_id)

                    if len(path) == 3:  # 二度关系
                        # 检查是否已有直接关系
                        has_direct = nx_graph.has_edge(node1.node_id, node2.node_id)

                        if not has_direct:
                            # 基于路径模式推断关系类型
                            relation_type = self._infer_relation_type_from_path(
                                graph, path
                            )

                            if relation_type:
                                inferred.append(KnowledgeRelation(
                                    relation_id=str(uuid.uuid4()),
                                    relation_type=relation_type,
                                    source_node_id=node1.node_id,
                                    target_node_id=node2.node_id,
                                    properties={
                                        'inferred': True,
                                        'method': 'path_based',
                                        'path': path
                                    },
                                    confidence=0.7
                                ))
                except nx.NetworkXNoPath:
                    continue

        return inferred

    def _build_networkx_graph(self, graph: KnowledgeGraph) -> nx.Graph:
        """构建NetworkX图"""
        nx_graph = nx.Graph()

        # 添加节点
        for node in graph.nodes:
            nx_graph.add_node(node.node_id, data=node)

        # 添加边
        for relation in graph.relations:
            nx_graph.add_edge(
                relation.source_node_id,
                relation.target_node_id,
                data=relation
            )

        return nx_graph

    def _infer_relation_type_from_path(self,
                                      graph: KnowledgeGraph,
                                      path: List[str]) -> Optional[RelationType]:
        """基于路径推断关系类型"""
        # 简化的推断规则
        # 实际应该基于路径上的关系类型模式
        return RelationType.SIMILAR_TO

    def _save_to_neo4j(self, graph: KnowledgeGraph) -> None:
        """保存到Neo4j数据库"""
        with self.driver.session() as session:
            try:
                # 保存节点
                for node in graph.nodes:
                    session.run(
                        """
                        MERGE (n:Node {node_id: $node_id})
                        SET n.name = $name,
                            n.type = $type,
                            n.properties = $properties,
                            n.updated_at = $updated_at
                        """,
                        node_id=node.node_id,
                        name=node.name,
                        type=node.node_type.value,
                        properties=json.dumps(node.properties),
                        updated_at=node.updated_at
                    )

                # 保存关系
                for relation in graph.relations:
                    session.run(
                        """
                        MATCH (a:Node {node_id: $source_id})
                        MATCH (b:Node {node_id: $target_id})
                        MERGE (a)-[r:RELATION {relation_id: $relation_id}]->(b)
                        SET r.type = $type,
                            r.properties = $properties,
                            r.confidence = $confidence,
                            r.created_at = $created_at
                        """,
                        source_id=relation.source_node_id,
                        target_id=relation.target_node_id,
                        relation_id=relation.relation_id,
                        type=relation.relation_type.value,
                        properties=json.dumps(relation.properties),
                        confidence=relation.confidence,
                        created_at=relation.created_at
                    )

                self.logger.info(f"保存知识图谱成功: {len(graph.nodes)}个节点, {len(graph.relations)}个关系")

            except Neo4jError as e:
                self.logger.error(f"Neo4j保存失败: {str(e)}")
                raise

    def close(self):
        """关闭数据库连接"""
        self.driver.close()
```

## 4. 实体提取器

```python
class EntityExtractor:
    """实体提取器"""

    def __init__(self):
        # 加载NER模型
        self.ner_pipeline = pipeline("ner", model="bert-base-chinese")
        self.nlp = spacy.load("zh_core_web_sm")
        self.logger = logging.getLogger(__name__)

    def extract(self, text: str) -> List[Dict[str, Any]]:
        """
        从文本中提取实体

        Args:
            text: 输入文本

        Returns:
            实体列表
        """
        entities = []

        # 使用BERT进行NER
        bert_entities = self._extract_with_bert(text)
        entities.extend(bert_entities)

        # 使用SpaCy进行NER
        spacy_entities = self._extract_with_spacy(text)
        entities.extend(spacy_entities)

        # 使用规则提取
        rule_entities = self._extract_with_rules(text)
        entities.extend(rule_entities)

        # 实体去重和合并
        entities = self._merge_entities(entities)

        return entities

    def _extract_with_bert(self, text: str) -> List[Dict[str, Any]]:
        """使用BERT模型提取实体"""
        entities = []

        try:
            # 运行NER pipeline
            ner_results = self.ner_pipeline(text)

            for entity in ner_results:
                entity_type = self._map_bert_entity_type(entity['entity'])
                if entity_type:
                    entities.append({
                        'name': entity['word'],
                        'type': entity_type,
                        'confidence': entity['score'],
                        'start': entity['start'],
                        'end': entity['end']
                    })

        except Exception as e:
            self.logger.error(f"BERT实体提取失败: {str(e)}")

        return entities

    def _map_bert_entity_type(self, bert_type: str) -> Optional[NodeType]:
        """映射BERT实体类型到节点类型"""
        mapping = {
            'PER': NodeType.PERSON,
            'ORG': NodeType.ORGANIZATION,
            'LOC': None,  # 位置暂不映射
            'MISC': NodeType.TECHNOLOGY
        }
        return mapping.get(bert_type)

    def _extract_with_spacy(self, text: str) -> List[Dict[str, Any]]:
        """使用SpaCy提取实体"""
        entities = []

        try:
            doc = self.nlp(text)

            for ent in doc.ents:
                entity_type = self._map_spacy_entity_type(ent.label_)
                if entity_type:
                    entities.append({
                        'name': ent.text,
                        'type': entity_type,
                        'confidence': 0.8,  # SpaCy没有置信度，使用默认值
                        'start': ent.start_char,
                        'end': ent.end_char
                    })

        except Exception as e:
            self.logger.error(f"SpaCy实体提取失败: {str(e)}")

        return entities

    def _map_spacy_entity_type(self, spacy_type: str) -> Optional[NodeType]:
        """映射SpaCy实体类型"""
        mapping = {
            'PERSON': NodeType.PERSON,
            'ORG': NodeType.ORGANIZATION,
            'PRODUCT': NodeType.PRODUCT,
            'WORK_OF_ART': NodeType.PROJECT
        }
        return mapping.get(spacy_type)

    def _extract_with_rules(self, text: str) -> List[Dict[str, Any]]:
        """基于规则提取实体"""
        entities = []

        # 项目名称模式
        project_patterns = [
            r'《([^》]+)》',
            r'"([^"]+)"项目',
            r'([^\s]+)工程'
        ]

        for pattern in project_patterns:
            import re
            matches = re.findall(pattern, text)
            for match in matches:
                entities.append({
                    'name': match,
                    'type': NodeType.PROJECT,
                    'confidence': 0.7,
                    'method': 'rule_based'
                })

        # 技术关键词
        tech_keywords = ['Python', 'Java', 'AI', '机器学习', '深度学习', 'Docker', 'Kubernetes']
        for keyword in tech_keywords:
            if keyword in text:
                entities.append({
                    'name': keyword,
                    'type': NodeType.TECHNOLOGY,
                    'confidence': 0.9,
                    'method': 'keyword_match'
                })

        return entities

    def _merge_entities(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """合并重复实体"""
        merged = {}

        for entity in entities:
            key = f"{entity['name']}_{entity['type']}"

            if key not in merged:
                merged[key] = entity
            else:
                # 保留置信度更高的
                if entity.get('confidence', 0) > merged[key].get('confidence', 0):
                    merged[key] = entity

        return list(merged.values())
```

## 5. 关系提取器

```python
class RelationExtractor:
    """关系提取器"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def extract(self,
               text: str,
               entities: List[KnowledgeNode]) -> List[Dict[str, Any]]:
        """
        从文本中提取实体间关系

        Args:
            text: 输入文本
            entities: 实体列表

        Returns:
            关系列表
        """
        relations = []

        # 基于模式的关系提取
        pattern_relations = self._extract_by_patterns(text, entities)
        relations.extend(pattern_relations)

        # 基于依存句法的关系提取
        dependency_relations = self._extract_by_dependency(text, entities)
        relations.extend(dependency_relations)

        # 基于共现的关系推断
        cooccurrence_relations = self._extract_by_cooccurrence(text, entities)
        relations.extend(cooccurrence_relations)

        return relations

    def _extract_by_patterns(self,
                            text: str,
                            entities: List[KnowledgeNode]) -> List[Dict[str, Any]]:
        """基于模式的关系提取"""
        relations = []

        # 定义关系模式
        patterns = [
            {
                'pattern': r'{entity1}[的的]?(.{0,5})[负责|管理|领导]{entity2}',
                'relation': RelationType.OWNS,
                'entity1_type': NodeType.PERSON,
                'entity2_type': NodeType.PROJECT
            },
            {
                'pattern': r'{entity1}[参与|加入|负责]{entity2}',
                'relation': RelationType.PARTICIPATES,
                'entity1_type': NodeType.PERSON,
                'entity2_type': NodeType.PROJECT
            },
            {
                'pattern': r'{entity1}[使用|采用|基于]{entity2}',
                'relation': RelationType.USES,
                'entity1_type': NodeType.PROJECT,
                'entity2_type': NodeType.TECHNOLOGY
            }
        ]

        # 应用模式匹配
        for pattern_def in patterns:
            matched_relations = self._match_pattern(
                text,
                entities,
                pattern_def
            )
            relations.extend(matched_relations)

        return relations

    def _match_pattern(self,
                      text: str,
                      entities: List[KnowledgeNode],
                      pattern_def: Dict) -> List[Dict[str, Any]]:
        """匹配单个模式"""
        relations = []
        # 实际实现应该更复杂
        return relations

    def _extract_by_dependency(self,
                              text: str,
                              entities: List[KnowledgeNode]) -> List[Dict[str, Any]]:
        """基于依存句法的关系提取"""
        # 简化实现
        return []

    def _extract_by_cooccurrence(self,
                                text: str,
                                entities: List[KnowledgeNode]) -> List[Dict[str, Any]]:
        """基于共现的关系推断"""
        relations = []

        # 计算实体在文本中的位置
        entity_positions = {}
        for entity in entities:
            positions = []
            start = 0
            while True:
                pos = text.find(entity.name, start)
                if pos == -1:
                    break
                positions.append(pos)
                start = pos + 1
            entity_positions[entity.node_id] = positions

        # 基于距离推断关系
        window_size = 50  # 字符窗口大小

        for i, entity1 in enumerate(entities):
            for entity2 in entities[i+1:]:
                # 计算最小距离
                min_distance = float('inf')

                for pos1 in entity_positions.get(entity1.node_id, []):
                    for pos2 in entity_positions.get(entity2.node_id, []):
                        distance = abs(pos1 - pos2)
                        min_distance = min(min_distance, distance)

                # 如果距离很近，推断存在关系
                if min_distance < window_size:
                    confidence = 1.0 - (min_distance / window_size)
                    relations.append({
                        'type': RelationType.SIMILAR_TO,
                        'source_id': entity1.node_id,
                        'target_id': entity2.node_id,
                        'confidence': confidence,
                        'properties': {
                            'method': 'cooccurrence',
                            'distance': min_distance
                        }
                    })

        return relations
```

## 6. 知识嵌入器

```python
class KnowledgeEmbedder:
    """知识嵌入器"""

    def __init__(self):
        # 加载预训练模型
        self.model = AutoModel.from_pretrained('bert-base-chinese')
        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')
        self.logger = logging.getLogger(__name__)

    def embed(self, text: str) -> np.ndarray:
        """
        计算文本嵌入

        Args:
            text: 输入文本

        Returns:
            嵌入向量
        """
        try:
            # 分词
            inputs = self.tokenizer(
                text,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            )

            # 获取BERT输出
            with torch.no_grad():
                outputs = self.model(**inputs)

            # 使用[CLS]标记的输出作为句子嵌入
            embeddings = outputs.last_hidden_state[:, 0, :].numpy()

            return embeddings.squeeze()

        except Exception as e:
            self.logger.error(f"嵌入计算失败: {str(e)}")
            return np.zeros(768)  # 返回零向量
```

## 7. 知识图谱查询接口

```python
class KnowledgeGraphQuerier:
    """知识图谱查询接口"""

    def __init__(self, neo4j_driver):
        self.driver = neo4j_driver
        self.logger = logging.getLogger(__name__)

    def find_shortest_path(self,
                          start_node_id: str,
                          end_node_id: str) -> Optional[List[str]]:
        """查找最短路径"""
        with self.driver.session() as session:
            result = session.run(
                """
                MATCH path = shortestPath((a:Node {node_id: $start})-[*]-(b:Node {node_id: $end}))
                RETURN [node IN nodes(path) | node.node_id] AS path
                """,
                start=start_node_id,
                end=end_node_id
            )

            record = result.single()
            if record:
                return record['path']
            return None

    def find_neighbors(self,
                      node_id: str,
                      depth: int = 1) -> List[KnowledgeNode]:
        """查找邻居节点"""
        with self.driver.session() as session:
            result = session.run(
                """
                MATCH (n:Node {node_id: $node_id})-[*1..$depth]-(neighbor:Node)
                RETURN DISTINCT neighbor
                """,
                node_id=node_id,
                depth=depth
            )

            neighbors = []
            for record in result:
                node_data = record['neighbor']
                node = KnowledgeNode(
                    node_id=node_data['node_id'],
                    node_type=NodeType[node_data['type']],
                    name=node_data['name'],
                    properties=json.loads(node_data.get('properties', '{}'))
                )
                neighbors.append(node)

            return neighbors

    def search_by_name(self, name_pattern: str) -> List[KnowledgeNode]:
        """按名称搜索节点"""
        with self.driver.session() as session:
            result = session.run(
                """
                MATCH (n:Node)
                WHERE n.name CONTAINS $pattern
                RETURN n
                """,
                pattern=name_pattern
            )

            nodes = []
            for record in result:
                node_data = record['n']
                node = KnowledgeNode(
                    node_id=node_data['node_id'],
                    node_type=NodeType[node_data['type']],
                    name=node_data['name'],
                    properties=json.loads(node_data.get('properties', '{}'))
                )
                nodes.append(node)

            return nodes
```

## 8. 异常处理

```python
class GraphBuildError(Exception):
    """图谱构建异常"""
    pass

class EntityExtractionError(Exception):
    """实体提取异常"""
    pass

class RelationExtractionError(Exception):
    """关系提取异常"""
    pass
```

## 9. 使用示例

```python
async def main():
    """主程序入口"""
    # 初始化知识图谱构建器
    builder = KnowledgeGraphBuilder(
        neo4j_uri="bolt://localhost:7687",
        neo4j_user="neo4j",
        neo4j_password="password"
    )

    # 准备数据源
    data_sources = [
        {
            'type': 'structured',
            'data': {
                'organization': {
                    'name': '科技有限公司',
                    'industry': '软件开发',
                    'scale': '500人'
                },
                'projects': [
                    {
                        'name': '智能标书系统',
                        'amount': 5000000,
                        'start_date': '2024-01-01',
                        'status': 'completed'
                    }
                ],
                'personnel': [
                    {
                        'name': '张三',
                        'role': '项目经理',
                        'experience': '10年',
                        'skills': ['项目管理', 'Java', 'Python']
                    }
                ]
            }
        },
        {
            'type': 'text',
            'data': '张三负责智能标书系统的开发，该系统使用了Python和机器学习技术。'
        }
    ]

    try:
        # 构建知识图谱
        graph = builder.build_graph(data_sources)

        print(f"知识图谱构建成功:")
        print(f"- 节点数: {len(graph.nodes)}")
        print(f"- 关系数: {len(graph.relations)}")

        # 查询示例
        querier = KnowledgeGraphQuerier(builder.driver)

        # 查找节点
        nodes = querier.search_by_name('张三')
        if nodes:
            print(f"\n找到节点: {nodes[0].name}")

            # 查找邻居
            neighbors = querier.find_neighbors(nodes[0].node_id, depth=2)
            print(f"邻居节点数: {len(neighbors)}")

    except GraphBuildError as e:
        print(f"构建失败: {e}")
    finally:
        builder.close()

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 修改历史

| 日期 | 版本 | 修改者 | 修改内容概要 |
|------|------|--------|-------------|
| 2025-11-30 13:25 | 1.0 | claude-opus-4-1-20250805 | 创建知识图谱构建算法实现代码 |